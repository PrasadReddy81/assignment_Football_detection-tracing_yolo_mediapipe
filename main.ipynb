{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2, time\n",
    "\n",
    "def yolo_pose_estimation(video_path, model_path):\n",
    "    model = YOLO(model_path)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < 30:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot()\n",
    "            cv2.imshow(\"YOLOv8 Pose\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# from mmpose.apis import init_model, inference_topdown\n",
    "# from mmpose.structures import merge_data_samples_vis\n",
    "from new.mmpose.mmpose.apis import init_model,inference_topdown\n",
    "from new.mmpose.mmpose.structures import merge_data_samples\n",
    "import cv2, time\n",
    "\n",
    "def rtmpose_estimation(video_path, config_file, checkpoint_file, device='cuda:0'):\n",
    "    model = init_model(config_file, checkpoint_file, device=device)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < 30:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        person_results = [{'bbox': [0, 0, frame.shape[1], frame.shape[0]]}]  # Assuming full frame\n",
    "        result = inference_topdown(model, frame_rgb, person_results)\n",
    "        vis_frame = merge_data_samples(result, frame)\n",
    "\n",
    "        cv2.imshow(\"RTMPose\", vis_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2, time\n",
    "\n",
    "def mediapipe_pose_estimation(video_path):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    pose = mp_pose.Pose()\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < 30:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow(\"MediaPipe Pose\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "\n",
    "\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\Subject_B.MP4\"\n",
    "yolo_model = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "rtmpose_config = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\rtmpose_config.py\"\n",
    "rtmpose_checkpoint = \"your_rtmpose_model.pth\"\n",
    "\n",
    "# Call the desired method\n",
    "# yolo_pose_estimation(video_path, yolo_model)\n",
    "rtmpose_estimation(video_path, rtmpose_config, rtmpose_checkpoint)\n",
    "# mediapipe_pose_estimation(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0bca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vaibh\\\\OneDrive\\\\Desktop\\\\New folder\\\\Folder Python\\\\Folder ML\\\\opencv_example'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c5dd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading RTMPose checkpoint...\n",
      "❌ Download failed with status code: 401\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://huggingface.co/openmmlab/rtmpose-s/resolve/main/rtmpose-s_simcc-body7_8xb256-420e_coco-640x640.pth\"\n",
    "output_path = \"rtmpose-s_simcc-body7_8xb256-420e_coco-640x640.pth\"\n",
    "\n",
    "print(\"Downloading RTMPose checkpoint...\")\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"✅ Download complete:\", output_path)\n",
    "else:\n",
    "    print(\"❌ Download failed with status code:\", r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d9ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1212 lines of output]\n",
      "      C:\\Users\\vaibh\\AppData\\Local\\Temp\\pip-install-gu0qxmqt\\mmcv_77ff93de8120444980ff89420cd07dc8\\setup.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "        from pkg_resources import DistributionNotFound, get_distribution, parse_version\n",
      "      Compiling mmcv._ext only with CPU\n",
      "      running bdist_wheel\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\_distutils\\cmd.py:111: SetuptoolsDeprecationWarning: bdist_wheel.universal is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              With Python 2.7 end-of-life, support for building universal wheels\n",
      "              (i.e., wheels that support both Python 2 and Python 3)\n",
      "              is being obviated.\n",
      "              Please discontinue using this option, or if you still need it,\n",
      "              file an issue with pypa/setuptools describing your use case.\n",
      "      \n",
      "              By 2025-Aug-30, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self.finalize_options()\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\utils\\cpp_extension.py:529: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "        warnings.warn(msg.format('we could not find ninja.'))\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\n",
      "      copying mmcv\\version.py -> build\\lib.win-amd64-cpython-39\\mmcv\n",
      "      copying mmcv\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\arraymisc\n",
      "      copying mmcv\\arraymisc\\quantization.py -> build\\lib.win-amd64-cpython-39\\mmcv\\arraymisc\n",
      "      copying mmcv\\arraymisc\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\arraymisc\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\cnn\n",
      "      copying mmcv\\cnn\\alexnet.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\n",
      "      copying mmcv\\cnn\\resnet.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\n",
      "      copying mmcv\\cnn\\vgg.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\n",
      "      copying mmcv\\cnn\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\colorspace.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\geometric.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\io.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\misc.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\photometric.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      copying mmcv\\image\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\image\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\active_rotated_filter.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\assign_score_withk.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\ball_query.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\bbox.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\bezier_align.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\bias_act.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\border_align.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\box_iou_quadri.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\box_iou_rotated.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\carafe.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\cc_attention.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\chamfer_distance.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\contour_expand.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\conv2d_gradfix.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\convex_iou.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\corner_pool.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\correlation.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\deform_conv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\deform_roi_pool.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\deprecated_wrappers.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\diff_iou_rotated.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\filtered_lrelu.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\focal_loss.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\furthest_point_sample.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\fused_bias_leakyrelu.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\gather_points.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\group_points.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\info.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\iou3d.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\knn.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\masked_conv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\merge_cells.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\min_area_polygons.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\modulated_deform_conv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\multi_scale_deform_attn.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\nms.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\pixel_group.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\points_in_boxes.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\points_in_polygons.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\points_sampler.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\point_sample.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\prroi_pool.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\psa_mask.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\riroi_align_rotated.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\roiaware_pool3d.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\roipoint_pool3d.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\roi_align.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\roi_align_rotated.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\roi_pool.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\rotated_feature_align.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\saconv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\scatter_points.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_conv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_functional.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_modules.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_ops.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_pool.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sparse_structure.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\sync_bn.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\three_interpolate.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\three_nn.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\tin_shift.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\upfirdn2d.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\voxelize.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      copying mmcv\\ops\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\base.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\builder.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\formatting.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\loading.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\processing.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\utils.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\wrappers.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      copying mmcv\\transforms\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\transforms\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      copying mmcv\\utils\\device_type.py -> build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      copying mmcv\\utils\\env.py -> build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      copying mmcv\\utils\\ext_loader.py -> build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      copying mmcv\\utils\\parrots_jit.py -> build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      copying mmcv\\utils\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\utils\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\video\n",
      "      copying mmcv\\video\\io.py -> build\\lib.win-amd64-cpython-39\\mmcv\\video\n",
      "      copying mmcv\\video\\optflow.py -> build\\lib.win-amd64-cpython-39\\mmcv\\video\n",
      "      copying mmcv\\video\\processing.py -> build\\lib.win-amd64-cpython-39\\mmcv\\video\n",
      "      copying mmcv\\video\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\video\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\visualization\n",
      "      copying mmcv\\visualization\\color.py -> build\\lib.win-amd64-cpython-39\\mmcv\\visualization\n",
      "      copying mmcv\\visualization\\image.py -> build\\lib.win-amd64-cpython-39\\mmcv\\visualization\n",
      "      copying mmcv\\visualization\\optflow.py -> build\\lib.win-amd64-cpython-39\\mmcv\\visualization\n",
      "      copying mmcv\\visualization\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\visualization\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\activation.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\context_block.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\conv.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\conv2d_adaptive_padding.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\conv_module.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\conv_ws.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\depthwise_separable_conv_module.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\drop.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\generalized_attention.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\hsigmoid.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\hswish.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\non_local.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\norm.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\padding.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\plugin.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\scale.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\swish.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\transformer.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\upsample.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\wrappers.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      copying mmcv\\cnn\\bricks\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\bricks\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\rfsearch\n",
      "      copying mmcv\\cnn\\rfsearch\\operator.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\rfsearch\n",
      "      copying mmcv\\cnn\\rfsearch\\search.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\rfsearch\n",
      "      copying mmcv\\cnn\\rfsearch\\utils.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\rfsearch\n",
      "      copying mmcv\\cnn\\rfsearch\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\rfsearch\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\utils\n",
      "      copying mmcv\\cnn\\utils\\flops_counter.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\utils\n",
      "      copying mmcv\\cnn\\utils\\fuse_conv_bn.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\utils\n",
      "      copying mmcv\\cnn\\utils\\__init__.py -> build\\lib.win-amd64-cpython-39\\mmcv\\cnn\\utils\n",
      "      running egg_info\n",
      "      writing mmcv.egg-info\\PKG-INFO\n",
      "      writing dependency_links to mmcv.egg-info\\dependency_links.txt\n",
      "      writing requirements to mmcv.egg-info\\requires.txt\n",
      "      writing top-level names to mmcv.egg-info\\top_level.txt\n",
      "      reading manifest file 'mmcv.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      adding license file 'LICENSE'\n",
      "      adding license file 'LICENSES.md'\n",
      "      writing manifest file 'mmcv.egg-info\\SOURCES.txt'\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.cuda' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.cuda' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.cuda' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.cuda' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.cuda' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.cuda.spconv' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.cuda.spconv' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.cuda.spconv' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.cuda.spconv' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.cuda.spconv' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.mlu' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.mlu' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.mlu' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.mlu' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.mlu' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.mps' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.mps' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.mps' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.mps' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.mps' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.utils.spconv' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.utils.spconv' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.utils.spconv' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.utils.spconv' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.utils.spconv' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.utils.spconv.spconv' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.utils.spconv.spconv' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.utils.spconv.spconv' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.utils.spconv.spconv' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.utils.spconv.spconv' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.common.utils.spconv.tensorview' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.common.utils.spconv.tensorview' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.common.utils.spconv.tensorview' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.common.utils.spconv.tensorview' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.common.utils.spconv.tensorview' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.parrots' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.parrots' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.parrots' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.parrots' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.parrots' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch.cpu' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch.cpu' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch.cpu' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch.cpu' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch.cpu' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch.cuda' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch.cuda' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch.cuda' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch.cuda' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch.cuda' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch.mlu' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch.mlu' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch.mlu' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch.mlu' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch.mlu' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch.mps' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch.mps' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch.mps' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch.mps' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch.mps' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'mmcv.ops.csrc.pytorch.npu' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'mmcv.ops.csrc.pytorch.npu' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'mmcv.ops.csrc.pytorch.npu' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'mmcv.ops.csrc.pytorch.npu' to be distributed and are\n",
      "              already explicitly excluding 'mmcv.ops.csrc.pytorch.npu' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\box_iou_rotated_utils.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\parrots_cpp_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\parrots_cuda_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_cpp_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_cuda_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_device_registry.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_mlu_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_npu_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      copying mmcv\\ops\\csrc\\common\\pytorch_npu_util.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\active_rotated_filter_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\assign_score_withk_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\ball_query_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\bbox_overlaps_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\bezier_align_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\border_align_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\box_iou_quadri_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\box_iou_rotated_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\carafe_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\carafe_naive_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\chamfer_distance_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\common_cuda_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\convex_iou_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\correlation_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\deform_conv_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\deform_roi_pool_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\diff_iou_rotated_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\furthest_point_sample_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\gather_points_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\group_points_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\iou3d_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\knn_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\masked_conv2d_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\min_area_polygons_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\modulated_deform_conv_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\ms_deform_attn_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\nms_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\nms_quadri_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\nms_rotated_cuda.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\parrots_cudawarpfunction.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\points_in_boxes_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\points_in_polygons_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\prroi_pool_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\psamask_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\riroi_align_rotated_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\roi_align_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\roi_align_rotated_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\roi_pool_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\roiaware_pool3d_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\roipoint_pool3d_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\rotated_feature_align_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\scatter_points_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\sigmoid_focal_loss_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\softmax_focal_loss_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\stack_ball_query_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\stack_group_points_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\sync_bn_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\three_interpolate_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\three_nn_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\tin_shift_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\voxelization_cuda_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\spconv\\indice.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\cuda\\spconv\\reordering.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\cuda\\spconv\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mlu\n",
      "      copying mmcv\\ops\\csrc\\common\\mlu\\common_mlu_helper.hpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mlu\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      copying mmcv\\ops\\csrc\\common\\mps\\MPSDevice.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      copying mmcv\\ops\\csrc\\common\\mps\\MPSLibrary.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      copying mmcv\\ops\\csrc\\common\\mps\\MPSLibrary.mm -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      copying mmcv\\ops\\csrc\\common\\mps\\MPSStream.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      copying mmcv\\ops\\csrc\\common\\mps\\MPSUtils.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\mps\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\paramsgrid.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\prettyprint.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\pybind11_utils.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\geometry.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\indice.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\maxpool.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\mp_helper.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\point2voxel.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\\reordering.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\spconv\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\\helper_kernel.cuh -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\\helper_launch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\n",
      "      copying mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\\tensorview.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\common\\utils\\spconv\\tensorview\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\active_rotated_filter.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\active_rotated_filter_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\active_rotated_filter_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\assign_score_withk.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\assign_score_withk_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\assign_score_withk_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\ball_query._parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\ball_query.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\ball_query_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\bbox_overlaps.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\bbox_overlaps_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\bbox_overlaps_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\border_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\border_align_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\border_align_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\box_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\box_iou_rotated_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\box_iou_rotated_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe_naive.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe_naive_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe_naive_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\carafe_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\chamfer_distance.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\chamfer_distance_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\chamfer_distance_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\contour_expand.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\contour_expand_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\contour_expand_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\convex_iou.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\convex_iou_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\convex_iou_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\correlation.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\correlation_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\correlation_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\cudabind.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_conv_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_conv_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_roi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_roi_pool_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\deform_roi_pool_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\diff_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\diff_iou_rotated_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\diff_iou_rotated_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\focal_loss.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\focal_loss_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\focal_loss_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\furthest_point_sample.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\furthest_point_sample_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\furthest_point_sample_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\fused_bias_leakyrelu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\fused_bias_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\gather_points.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\gather_points_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\gather_points_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\group_points.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\group_points_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\group_points_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\info.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\iou3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\iou3d_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\iou3d_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\knn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\knn_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\knn_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\masked_conv2d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\masked_conv2d_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\masked_conv2d_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\min_area_polygons.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\min_area_polygons_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\min_area_polygons_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\modulated_deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\modulated_deform_conv_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\modulated_deform_conv_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\ms_deform_attn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\ms_deform_attn_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\nms.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\nms_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\nms_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\nms_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\pixel_group.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\pixel_group_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\pixel_group_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_boxes.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_boxes_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_boxes_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_polygons.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_polygons_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\points_in_polygons_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\prroi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\prroi_pool_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\prroi_pool_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\psamask.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\psamask_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\psamask_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\riroi_align_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\riroi_align_rotated_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\riroi_align_rotated_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align_rotated_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_align_rotated_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_pool_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roi_pool_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roiaware_pool3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roiaware_pool3d_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roiaware_pool3d_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roipoint_pool3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roipoint_pool3d_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\roipoint_pool3d_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\rotated_feature_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\rotated_feature_align_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\rotated_feature_align_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\sync_bn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\sync_bn_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\sync_bn_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_interpolate.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_interpolate_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_interpolate_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_nn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_nn_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\three_nn_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\tin_shift.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\tin_shift_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\tin_shift_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\upfirdn2d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\upfirdn2d_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\voxelization.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\voxelization_parrots.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      copying mmcv\\ops\\csrc\\parrots\\voxelization_pytorch.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\parrots\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\active_rotated_filter.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\assign_score_withk.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\ball_query.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\bbox_overlaps.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\bezier_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\bias_act.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\border_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\box_iou_quadri.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\box_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\carafe.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\carafe_naive.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\chamfer_distance.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\contour_expand.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\convex_iou.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\correlation.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\deform_roi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\diff_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\filtered_lrelu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\focal_loss.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\furthest_point_sample.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\fused_bias_leakyrelu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\fused_spconv_ops.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\gather_points.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\group_points.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\info.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\iou3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\knn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\masked_conv2d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\min_area_polygons.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\modulated_deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\ms_deform_attn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\nms.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\nms_quadri.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\nms_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\pixel_group.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\points_in_boxes.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\points_in_polygons.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\prroi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\psamask.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\pybind.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\riroi_align_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\roi_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\roi_align_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\roi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\roiaware_pool3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\roipoint_pool3d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\rotated_feature_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\scatter_points.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\sparse_pool_ops.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\spconv_ops.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\spconv_utils.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\sync_bn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\three_interpolate.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\three_nn.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\tin_shift.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\upfirdn2d.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\voxelization.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\active_rotated_filter.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\bbox_overlaps_cpu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\bezier_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\box_iou_quadri.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\box_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\modulated_deform_conv.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\nms.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\nms_quadri.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\nms_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\pixel_group.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\points_in_boxes.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\psamask.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\roi_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\roi_align_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\rotated_feature_align.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\sparse_indice.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\sparse_maxpool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\sparse_reordering.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cpu\\voxelization.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cpu\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\active_rotated_filter_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\assign_score_withk_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\ball_query_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\bbox_overlaps_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\bezier_align_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\bias_act_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\border_align_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\box_iou_quadri_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\box_iou_rotated_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\carafe_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\carafe_naive_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\chamfer_distance_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\convex_iou.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\correlation_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\cudabind.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\deform_conv_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\deform_roi_pool_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\diff_iou_rotated_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\filtered_lrelu.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\focal_loss_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\furthest_point_sample_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\fused_bias_leakyrelu_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\fused_spconv_ops_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\gather_points_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\group_points_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\iou3d_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\knn_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\masked_conv2d_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\min_area_polygons.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\modulated_deform_conv_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\ms_deform_attn_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\nms_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\nms_quadri_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\nms_rotated_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\points_in_boxes_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\points_in_polygons_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\prroi_pool_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\psamask_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\riroi_align_rotated_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\roi_align_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\roi_align_rotated_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\roi_pool_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\roiaware_pool3d_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\roipoint_pool3d_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\rotated_feature_align_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\scatter_points_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\sparse_indice.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\sparse_maxpool.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\sparse_pool_ops_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\sparse_reordering.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\spconv_ops_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\stack_ball_query_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\stack_group_points_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\sync_bn_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\three_interpolate_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\three_nn_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\tin_shift_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\upfirdn2d_kernel.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\cuda\\voxelization_cuda.cu -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\cuda\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\ball_query_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\bbox_overlaps_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\box_iou_rotated.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\carafe_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\deform_roi_pool_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\diff_iou_rotated_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\focal_loss_sigmoid_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\iou3d_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\masked_conv2d_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\mlu_common_helper.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\mlu_common_helper.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\ms_deform_attn_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\nms_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\nms_rotated_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\psamask_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\roi_align_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\roi_align_rotated_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\roi_pool_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\roiaware_pool3d_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\roipoint_pool3d_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\rotated_feature_align_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\scatter_points_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\sparse_conv_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\three_nn_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\tin_shift_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mlu\\voxelization_mlu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mlu\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mps\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\mps\\bbox_overlaps_mps.mm -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\mps\n",
      "      creating build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\active_rotated_filter_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\ball_query_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\bbox_overlaps_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\box_iou_rotated_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\chamfer_distance_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\common_util.h -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\deform_roi_pool.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\focal_loss_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\fused_bias_leakyrelu_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\gather_points_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\group_points_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\ms_deform_attn_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\nms_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\nms_rotated_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\points_in_polygons_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\psa_mask_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\roi_align_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\roi_align_rotated_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\roi_pool_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\rotated_feature_align_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\stack_ball_query_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\stack_group_points_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\three_interpolate_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      copying mmcv\\ops\\csrc\\pytorch\\npu\\voxelization_npu.cpp -> build\\lib.win-amd64-cpython-39\\mmcv\\ops\\csrc\\pytorch\\npu\n",
      "      running build_ext\n",
      "      c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\utils\\cpp_extension.py:414: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "        warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "      building 'mmcv._ext' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for mmcv\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (mmcv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cpu/torch2.4/index.html, https://qaihub-public-python-wheels.s3.us-west-2.amazonaws.com/index.html\n",
      "Collecting torch==2.4.1\n",
      "  Downloading torch-2.4.1-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting qai-hub-models[rtmpose-body2d]\n",
      "  Downloading qai_hub_models-0.33.0-py3-none-any.whl.metadata (54 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from torch==2.4.1) (2024.12.0)\n",
      "Requirement already satisfied: Pillow<12,>10 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (11.1.0)\n",
      "Collecting gdown==4.7.1 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gitpython==3.1.42 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.1 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ipython==8.12.3 (from qai-hub-models[rtmpose-body2d])\n",
      "  Using cached ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (1.26.4)\n",
      "Collecting onnx>=1.16.1 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading onnx-1.18.0-cp39-cp39-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting onnxruntime>=1.19 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: opencv-python<5,>4 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (4.11.0.86)\n",
      "Requirement already satisfied: pandas<2.3,>2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (2.2.3)\n",
      "Collecting prettytable==3.11.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading prettytable-3.11.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests-toolbelt==1.0.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting schema==0.7.5 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tabulate==0.9.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting torchvision<0.21,>=0.16 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading torchvision-0.20.1-cp39-cp39-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.66 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (4.67.1)\n",
      "Collecting pyarrow==19.0.1 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading pyarrow-19.0.1-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting qai-hub<0.32.0,>=0.31.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading qai_hub-0.31.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting datasets==2.17.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ruamel-yaml==0.18.10 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub-models[rtmpose-body2d]) (2.11.7)\n",
      "Collecting pydantic-yaml==1.4.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading pydantic_yaml-1.4.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting chumpy==0.71 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading https://qaihub-public-python-wheels.s3.us-west-2.amazonaws.com/chumpy-0.71-py3-none-any.whl (60 kB)\n",
      "Collecting mmdet==3.3.0+mmcv220 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading https://qaihub-public-python-wheels.s3.us-west-2.amazonaws.com/mmdet-3.3.0%2Bmmcv220-py3-none-any.whl (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     --------- ------------------------------ 0.5/2.2 MB 89.7 kB/s eta 0:00:20\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     -------------- ------------------------- 0.8/2.2 MB 93.2 kB/s eta 0:00:16\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ------------------ --------------------- 1.0/2.2 MB 101.1 kB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 1.3/2.2 MB 114.7 kB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 1.3/2.2 MB 114.7 kB/s eta 0:00:09\n",
      "     ----------------------- ---------------- 1.3/2.2 MB 114.7 kB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 133.4 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 133.4 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 133.4 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 133.4 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 1.6/2.2 MB 133.4 kB/s eta 0:00:05\n",
      "     -------------------------------- ------- 1.8/2.2 MB 147.0 kB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.1/2.2 MB 166.1 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.1/2.2 MB 166.1 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.2/2.2 MB 173.2 kB/s eta 0:00:00\n",
      "Collecting mmpose==1.2.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading mmpose-1.2.0-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mmcv==2.2.0 (from qai-hub-models[rtmpose-body2d])\n",
      "  Using cached mmcv-2.2.0.tar.gz (479 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting matplotlib==3.7.3 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading matplotlib-3.7.3-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scipy>=0.13.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from chumpy==0.71->qai-hub-models[rtmpose-body2d]) (1.12.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from chumpy==0.71->qai-hub-models[rtmpose-body2d]) (1.17.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (2.32.3)\n",
      "Collecting xxhash (from datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading multiprocess-0.70.18-py39-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec (from torch==2.4.1)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (3.11.11)\n",
      "Requirement already satisfied: packaging in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from gdown==4.7.1->qai-hub-models[rtmpose-body2d]) (4.13.4)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython==3.1.42->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting backcall (from ipython==8.12.3->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (6.5.2)\n",
      "Collecting addict (from mmcv==2.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting mmengine>=0.3.0 (from mmcv==2.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached mmengine-0.10.7-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting yapf (from mmcv==2.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (2024.11.6)\n",
      "Collecting pycocotools (from mmdet==3.3.0+mmcv220->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading pycocotools-2.0.10-cp39-cp39-win_amd64.whl.metadata (1.3 kB)\n",
      "Collecting shapely (from mmdet==3.3.0+mmcv220->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting terminaltables (from mmdet==3.3.0+mmcv220->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting json-tricks (from mmpose==1.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached json_tricks-3.17.3-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting munkres (from mmpose==1.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\n",
      "Collecting xtcocotools>=1.12 (from mmpose==1.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached xtcocotools-1.14.3-cp39-cp39-win_amd64.whl.metadata (376 bytes)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from prettytable==3.11.0->qai-hub-models[rtmpose-body2d]) (0.2.13)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml==0.18.10->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp39-cp39-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting contextlib2>=0.5.5 (from schema==0.7.5->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from onnx>=1.16.1->qai-hub-models[rtmpose-body2d]) (4.25.8)\n",
      "Collecting coloredlogs (from onnxruntime>=1.19->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from onnxruntime>=1.19->qai-hub-models[rtmpose-body2d]) (25.2.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas<2.3,>2->qai-hub-models[rtmpose-body2d]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas<2.3,>2->qai-hub-models[rtmpose-body2d]) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=2->qai-hub-models[rtmpose-body2d]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=2->qai-hub-models[rtmpose-body2d]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pydantic<3,>=2->qai-hub-models[rtmpose-body2d]) (0.4.1)\n",
      "Collecting backoff>=2.2 (from qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting deprecation (from qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: h5py<4,>=2.10.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d]) (3.13.0)\n",
      "INFO: pip is looking at multiple versions of qai-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting onnxruntime>=1.19 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading onnxruntime-1.19.0-cp39-cp39-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting onnx>=1.16.1 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading onnx-1.17.0-cp39-cp39-win_amd64.whl.metadata (16 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.16.1->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl.metadata (699 bytes)\n",
      "Collecting s3transfer<0.11,>=0.10.3 (from qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting semver>=3.0 (from qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision<0.21,>=0.16 (from qai-hub-models[rtmpose-body2d])\n",
      "  Downloading torchvision-0.20.0-cp39-cp39-win_amd64.whl.metadata (6.2 kB)\n",
      "  Downloading torchvision-0.19.1-cp39-cp39-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from sympy->torch==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from aiohttp->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (1.18.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython==3.1.42->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.3->qai-hub-models[rtmpose-body2d]) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from jedi>=0.16->ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.8.4)\n",
      "Requirement already satisfied: rich in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from mmengine>=0.3.0->mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (13.9.4)\n",
      "Requirement already satisfied: termcolor in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from mmengine>=0.3.0->mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0->qai-hub-models[rtmpose-body2d]) (2024.12.14)\n",
      "Collecting botocore<2.0a.0,>=1.33.2 (from s3transfer<0.11,>=0.10.3->qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading botocore-1.39.17-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from xtcocotools>=1.12->mmpose==1.2.0->qai-hub-models[rtmpose-body2d]) (75.1.0)\n",
      "Collecting cython>=0.27.3 (from xtcocotools>=1.12->mmpose==1.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached cython-3.1.2-cp39-cp39-win_amd64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from beautifulsoup4->gdown==4.7.1->qai-hub-models[rtmpose-body2d]) (2.7)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown==4.7.1->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from stack-data->ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from stack-data->ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from stack-data->ipython==8.12.3->qai-hub-models[rtmpose-body2d]) (0.2.3)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from yapf->mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (4.3.6)\n",
      "Collecting tomli>=2.0.1 (from yapf->mmcv==2.2.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai-hub<0.32.0,>=0.31.0->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->datasets==2.17.0->qai-hub-models[rtmpose-body2d])\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.19->qai-hub-models[rtmpose-body2d])\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from rich->mmengine>=0.3.0->mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.2.0->qai-hub-models[rtmpose-body2d]) (0.1.2)\n",
      "Downloading torch-2.4.1-cp39-cp39-win_amd64.whl (199.3 MB)\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/199.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/199.3 MB 493.7 kB/s eta 0:06:43\n",
      "   ---------------------------------------- 0.5/199.3 MB 493.7 kB/s eta 0:06:43\n",
      "   ---------------------------------------- 0.5/199.3 MB 493.7 kB/s eta 0:06:43\n",
      "   ---------------------------------------- 0.5/199.3 MB 493.7 kB/s eta 0:06:43\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 0.8/199.3 MB 424.9 kB/s eta 0:07:48\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.0/199.3 MB 233.0 kB/s eta 0:14:11\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.3/199.3 MB 144.3 kB/s eta 0:22:53\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.6/199.3 MB 144.4 kB/s eta 0:22:50\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 1.8/199.3 MB 147.0 kB/s eta 0:22:24\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.1/199.3 MB 148.8 kB/s eta 0:22:06\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "   ---------------------------------------- 2.4/199.3 MB 148.3 kB/s eta 0:22:09\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.6/199.3 MB 147.7 kB/s eta 0:22:12\n",
      "    --------------------------------------- 2.9/199.3 MB 148.3 kB/s eta 0:22:05\n",
      "    --------------------------------------- 2.9/199.3 MB 148.3 kB/s eta 0:22:05\n",
      "    --------------------------------------- 2.9/199.3 MB 148.3 kB/s eta 0:22:05\n",
      "    --------------------------------------- 2.9/199.3 MB 148.3 kB/s eta 0:22:05\n",
      "    --------------------------------------- 2.9/199.3 MB 148.3 kB/s eta 0:22:05\n",
      "    --------------------------------------- 3.1/199.3 MB 153.5 kB/s eta 0:21:18\n",
      "    --------------------------------------- 3.1/199.3 MB 153.5 kB/s eta 0:21:18\n",
      "    --------------------------------------- 3.1/199.3 MB 153.5 kB/s eta 0:21:18\n",
      "    --------------------------------------- 3.4/199.3 MB 162.4 kB/s eta 0:20:07\n",
      "    --------------------------------------- 3.4/199.3 MB 162.4 kB/s eta 0:20:07\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.7/199.3 MB 173.1 kB/s eta 0:18:51\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 3.9/199.3 MB 160.2 kB/s eta 0:20:20\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.2/199.3 MB 158.8 kB/s eta 0:20:30\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.5/199.3 MB 155.9 kB/s eta 0:20:51\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 4.7/199.3 MB 155.3 kB/s eta 0:20:54\n",
      "    --------------------------------------- 5.0/199.3 MB 149.9 kB/s eta 0:21:37\n",
      "    --------------------------------------- 5.0/199.3 MB 149.9 kB/s eta 0:21:37\n",
      "    --------------------------------------- 5.0/199.3 MB 149.9 kB/s eta 0:21:37\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.2/199.3 MB 150.7 kB/s eta 0:21:29\n",
      "   - -------------------------------------- 5.5/199.3 MB 152.8 kB/s eta 0:21:09\n",
      "   - -------------------------------------- 5.5/199.3 MB 152.8 kB/s eta 0:21:09\n",
      "   - -------------------------------------- 5.5/199.3 MB 152.8 kB/s eta 0:21:09\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 5.8/199.3 MB 158.4 kB/s eta 0:20:22\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.0/199.3 MB 173.6 kB/s eta 0:18:34\n",
      "   - -------------------------------------- 6.3/199.3 MB 173.6 kB/s eta 0:18:32\n",
      "   - -------------------------------------- 6.3/199.3 MB 173.6 kB/s eta 0:18:32\n",
      "   - -------------------------------------- 6.3/199.3 MB 173.6 kB/s eta 0:18:32\n",
      "   - -------------------------------------- 6.3/199.3 MB 173.6 kB/s eta 0:18:32\n",
      "   - -------------------------------------- 6.6/199.3 MB 178.3 kB/s eta 0:18:02\n",
      "   - -------------------------------------- 6.8/199.3 MB 184.6 kB/s eta 0:17:24\n",
      "   - -------------------------------------- 6.8/199.3 MB 184.6 kB/s eta 0:17:24\n",
      "   - -------------------------------------- 6.8/199.3 MB 184.6 kB/s eta 0:17:24\n",
      "   - -------------------------------------- 6.8/199.3 MB 184.6 kB/s eta 0:17:24\n",
      "   - -------------------------------------- 7.1/199.3 MB 191.8 kB/s eta 0:16:43\n",
      "   - -------------------------------------- 7.1/199.3 MB 191.8 kB/s eta 0:16:43\n",
      "   - -------------------------------------- 7.1/199.3 MB 191.8 kB/s eta 0:16:43\n",
      "   - -------------------------------------- 7.3/199.3 MB 195.9 kB/s eta 0:16:21\n",
      "   - -------------------------------------- 7.6/199.3 MB 203.4 kB/s eta 0:15:43\n",
      "   - -------------------------------------- 7.9/199.3 MB 211.4 kB/s eta 0:15:06\n",
      "   - -------------------------------------- 8.4/199.3 MB 230.2 kB/s eta 0:13:50\n",
      "   - -------------------------------------- 8.7/199.3 MB 237.7 kB/s eta 0:13:23\n",
      "   - -------------------------------------- 8.7/199.3 MB 237.7 kB/s eta 0:13:23\n",
      "   - -------------------------------------- 8.9/199.3 MB 243.7 kB/s eta 0:13:02\n",
      "   - -------------------------------------- 8.9/199.3 MB 243.7 kB/s eta 0:13:02\n",
      "   - -------------------------------------- 8.9/199.3 MB 243.7 kB/s eta 0:13:02\n",
      "   - -------------------------------------- 8.9/199.3 MB 243.7 kB/s eta 0:13:02\n",
      "   - -------------------------------------- 9.2/199.3 MB 245.7 kB/s eta 0:12:54\n",
      "   - -------------------------------------- 9.2/199.3 MB 245.7 kB/s eta 0:12:54\n",
      "   - -------------------------------------- 9.2/199.3 MB 245.7 kB/s eta 0:12:54\n",
      "   - -------------------------------------- 9.2/199.3 MB 245.7 kB/s eta 0:12:54\n",
      "   - -------------------------------------- 9.4/199.3 MB 250.7 kB/s eta 0:12:38\n",
      "   - -------------------------------------- 9.7/199.3 MB 258.8 kB/s eta 0:12:13\n",
      "   - -------------------------------------- 9.7/199.3 MB 258.8 kB/s eta 0:12:13\n",
      "   - -------------------------------------- 9.7/199.3 MB 258.8 kB/s eta 0:12:13\n",
      "   - -------------------------------------- 9.7/199.3 MB 258.8 kB/s eta 0:12:13\n",
      "   - ------------------------------------- 10.0/199.3 MB 268.2 kB/s eta 0:11:47\n",
      "   - ------------------------------------- 10.0/199.3 MB 268.2 kB/s eta 0:11:47\n",
      "   -- ------------------------------------ 10.2/199.3 MB 271.5 kB/s eta 0:11:37\n",
      "   -- ------------------------------------ 10.2/199.3 MB 271.5 kB/s eta 0:11:37\n",
      "   -- ------------------------------------ 10.2/199.3 MB 271.5 kB/s eta 0:11:37\n",
      "   -- ------------------------------------ 10.2/199.3 MB 271.5 kB/s eta 0:11:37\n",
      "   -- ------------------------------------ 10.2/199.3 MB 271.5 kB/s eta 0:11:37\n",
      "   -- ------------------------------------ 10.5/199.3 MB 272.6 kB/s eta 0:11:33\n",
      "   -- ------------------------------------ 10.7/199.3 MB 286.1 kB/s eta 0:11:00\n",
      "   -- ------------------------------------ 11.0/199.3 MB 293.1 kB/s eta 0:10:43\n",
      "   -- ------------------------------------ 11.3/199.3 MB 300.9 kB/s eta 0:10:26\n",
      "   -- ------------------------------------ 11.5/199.3 MB 308.2 kB/s eta 0:10:10\n",
      "   -- ------------------------------------ 12.1/199.3 MB 322.6 kB/s eta 0:09:41\n",
      "   -- ------------------------------------ 12.3/199.3 MB 330.4 kB/s eta 0:09:27\n",
      "   -- ------------------------------------ 12.6/199.3 MB 336.8 kB/s eta 0:09:15\n",
      "   -- ------------------------------------ 12.8/199.3 MB 342.8 kB/s eta 0:09:05\n",
      "   -- ------------------------------------ 13.4/199.3 MB 370.2 kB/s eta 0:08:23\n",
      "   -- ------------------------------------ 13.6/199.3 MB 375.7 kB/s eta 0:08:15\n",
      "   -- ------------------------------------ 13.6/199.3 MB 375.7 kB/s eta 0:08:15\n",
      "   -- ------------------------------------ 13.9/199.3 MB 381.1 kB/s eta 0:08:07\n",
      "   -- ------------------------------------ 13.9/199.3 MB 381.1 kB/s eta 0:08:07\n",
      "   -- ------------------------------------ 14.2/199.3 MB 382.7 kB/s eta 0:08:04\n",
      "   -- ------------------------------------ 14.7/199.3 MB 397.6 kB/s eta 0:07:45\n",
      "   -- ------------------------------------ 14.9/199.3 MB 404.1 kB/s eta 0:07:37\n",
      "   --- ----------------------------------- 15.5/199.3 MB 425.5 kB/s eta 0:07:13\n",
      "   --- ----------------------------------- 16.0/199.3 MB 441.0 kB/s eta 0:06:56\n",
      "   --- ----------------------------------- 16.3/199.3 MB 445.7 kB/s eta 0:06:51\n",
      "   --- ----------------------------------- 16.8/199.3 MB 459.9 kB/s eta 0:06:37\n",
      "   --- ----------------------------------- 17.0/199.3 MB 466.8 kB/s eta 0:06:31\n",
      "   --- ----------------------------------- 17.6/199.3 MB 481.1 kB/s eta 0:06:18\n",
      "   --- ----------------------------------- 18.1/199.3 MB 494.5 kB/s eta 0:06:07\n",
      "   --- ----------------------------------- 18.1/199.3 MB 494.5 kB/s eta 0:06:07\n",
      "   --- ----------------------------------- 18.4/199.3 MB 494.2 kB/s eta 0:06:07\n",
      "   --- ----------------------------------- 18.6/199.3 MB 498.6 kB/s eta 0:06:03\n",
      "   --- ----------------------------------- 18.6/199.3 MB 498.6 kB/s eta 0:06:03\n",
      "   --- ----------------------------------- 18.9/199.3 MB 551.5 kB/s eta 0:05:28\n",
      "   --- ----------------------------------- 19.1/199.3 MB 555.4 kB/s eta 0:05:25\n",
      "   --- ----------------------------------- 19.4/199.3 MB 561.1 kB/s eta 0:05:21\n",
      "   --- ----------------------------------- 19.7/199.3 MB 566.2 kB/s eta 0:05:18\n",
      "   --- ----------------------------------- 20.2/199.3 MB 578.8 kB/s eta 0:05:10\n",
      "   --- ----------------------------------- 20.2/199.3 MB 578.8 kB/s eta 0:05:10\n",
      "   ---- ---------------------------------- 20.4/199.3 MB 582.7 kB/s eta 0:05:08\n",
      "   ---- ---------------------------------- 20.7/199.3 MB 587.1 kB/s eta 0:05:05\n",
      "   ---- ---------------------------------- 21.0/199.3 MB 590.1 kB/s eta 0:05:03\n",
      "   ---- ---------------------------------- 21.2/199.3 MB 594.0 kB/s eta 0:05:00\n",
      "   ---- ---------------------------------- 21.2/199.3 MB 594.0 kB/s eta 0:05:00\n",
      "   ---- ---------------------------------- 21.5/199.3 MB 596.6 kB/s eta 0:04:59\n",
      "   ---- ---------------------------------- 22.0/199.3 MB 607.7 kB/s eta 0:04:52\n",
      "   ---- ---------------------------------- 22.3/199.3 MB 613.3 kB/s eta 0:04:49\n",
      "   ---- ---------------------------------- 22.3/199.3 MB 613.3 kB/s eta 0:04:49\n",
      "   ---- ---------------------------------- 22.3/199.3 MB 613.3 kB/s eta 0:04:49\n",
      "   ---- ---------------------------------- 22.5/199.3 MB 639.3 kB/s eta 0:04:37\n",
      "   ---- ---------------------------------- 22.8/199.3 MB 644.6 kB/s eta 0:04:34\n",
      "   ---- ---------------------------------- 23.1/199.3 MB 648.4 kB/s eta 0:04:32\n",
      "   ---- ---------------------------------- 23.3/199.3 MB 653.9 kB/s eta 0:04:30\n",
      "   ---- ---------------------------------- 23.6/199.3 MB 657.9 kB/s eta 0:04:28\n",
      "   ---- ---------------------------------- 24.1/199.3 MB 670.0 kB/s eta 0:04:22\n",
      "   ---- ---------------------------------- 24.6/199.3 MB 724.1 kB/s eta 0:04:02\n",
      "   ---- ---------------------------------- 24.6/199.3 MB 724.1 kB/s eta 0:04:02\n",
      "   ---- ---------------------------------- 25.2/199.3 MB 733.9 kB/s eta 0:03:58\n",
      "   ----- --------------------------------- 25.7/199.3 MB 744.2 kB/s eta 0:03:54\n",
      "   ----- --------------------------------- 25.7/199.3 MB 744.2 kB/s eta 0:03:54\n",
      "   ----- --------------------------------- 26.0/199.3 MB 745.7 kB/s eta 0:03:53\n",
      "   ----- --------------------------------- 26.2/199.3 MB 749.5 kB/s eta 0:03:51\n",
      "   ----- --------------------------------- 26.5/199.3 MB 754.0 kB/s eta 0:03:50\n",
      "   ----- --------------------------------- 27.3/199.3 MB 770.6 kB/s eta 0:03:44\n",
      "   ----- --------------------------------- 27.5/199.3 MB 776.2 kB/s eta 0:03:42\n",
      "   ----- --------------------------------- 27.5/199.3 MB 776.2 kB/s eta 0:03:42\n",
      "   ----- --------------------------------- 27.8/199.3 MB 814.8 kB/s eta 0:03:31\n",
      "   ----- --------------------------------- 28.0/199.3 MB 817.3 kB/s eta 0:03:30\n",
      "   ----- --------------------------------- 28.3/199.3 MB 819.7 kB/s eta 0:03:29\n",
      "   ----- --------------------------------- 28.6/199.3 MB 823.9 kB/s eta 0:03:28\n",
      "   ----- --------------------------------- 28.8/199.3 MB 828.1 kB/s eta 0:03:26\n",
      "   ----- --------------------------------- 29.4/199.3 MB 836.2 kB/s eta 0:03:24\n",
      "   ----- --------------------------------- 29.6/199.3 MB 841.1 kB/s eta 0:03:22\n",
      "   ----- --------------------------------- 29.9/199.3 MB 845.5 kB/s eta 0:03:21\n",
      "   ----- --------------------------------- 30.4/199.3 MB 890.3 kB/s eta 0:03:10\n",
      "   ------ -------------------------------- 30.7/199.3 MB 894.1 kB/s eta 0:03:09\n",
      "   ------ -------------------------------- 31.2/199.3 MB 904.4 kB/s eta 0:03:06\n",
      "   ------ -------------------------------- 31.5/199.3 MB 905.2 kB/s eta 0:03:06\n",
      "   ------ -------------------------------- 31.7/199.3 MB 909.8 kB/s eta 0:03:05\n",
      "   ------ -------------------------------- 32.0/199.3 MB 913.9 kB/s eta 0:03:04\n",
      "   ------ -------------------------------- 32.2/199.3 MB 915.0 kB/s eta 0:03:03\n",
      "   ------ -------------------------------- 32.2/199.3 MB 915.0 kB/s eta 0:03:03\n",
      "   ------ -------------------------------- 32.5/199.3 MB 920.3 kB/s eta 0:03:02\n",
      "   ------ -------------------------------- 32.8/199.3 MB 919.9 kB/s eta 0:03:02\n",
      "   ------ -------------------------------- 33.0/199.3 MB 969.0 kB/s eta 0:02:52\n",
      "   ------ -------------------------------- 33.6/199.3 MB 978.8 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 33.6/199.3 MB 978.8 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 33.8/199.3 MB 978.4 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 33.8/199.3 MB 978.4 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 33.8/199.3 MB 978.4 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 33.8/199.3 MB 978.4 kB/s eta 0:02:50\n",
      "   ------ -------------------------------- 34.1/199.3 MB 954.9 kB/s eta 0:02:54\n",
      "   ------ -------------------------------- 34.1/199.3 MB 954.9 kB/s eta 0:02:54\n",
      "   ------ -------------------------------- 34.3/199.3 MB 966.0 kB/s eta 0:02:51\n",
      "   ------ -------------------------------- 34.3/199.3 MB 966.0 kB/s eta 0:02:51\n",
      "   ------ -------------------------------- 34.3/199.3 MB 966.0 kB/s eta 0:02:51\n",
      "   ------ -------------------------------- 34.6/199.3 MB 985.3 kB/s eta 0:02:48\n",
      "   ------ -------------------------------- 34.9/199.3 MB 986.4 kB/s eta 0:02:47\n",
      "   ------ -------------------------------- 35.1/199.3 MB 986.9 kB/s eta 0:02:47\n",
      "   ------ -------------------------------- 35.1/199.3 MB 986.9 kB/s eta 0:02:47\n",
      "   ------ -------------------------------- 35.4/199.3 MB 983.8 kB/s eta 0:02:47\n",
      "   ------ -------------------------------- 35.4/199.3 MB 983.8 kB/s eta 0:02:47\n",
      "   ------- -------------------------------- 35.7/199.3 MB 1.0 MB/s eta 0:02:41\n",
      "   ------- -------------------------------- 36.2/199.3 MB 1.0 MB/s eta 0:02:39\n",
      "   ------- -------------------------------- 36.7/199.3 MB 1.0 MB/s eta 0:02:37\n",
      "   ------- -------------------------------- 37.0/199.3 MB 1.0 MB/s eta 0:02:37\n",
      "   ------- -------------------------------- 37.2/199.3 MB 1.0 MB/s eta 0:02:36\n",
      "   ------- -------------------------------- 37.2/199.3 MB 1.0 MB/s eta 0:02:36\n",
      "   ------- -------------------------------- 37.5/199.3 MB 1.1 MB/s eta 0:02:34\n",
      "   ------- -------------------------------- 38.0/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.0/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.0/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.0/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.0/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.3/199.3 MB 1.1 MB/s eta 0:02:33\n",
      "   ------- -------------------------------- 38.8/199.3 MB 1.1 MB/s eta 0:02:32\n",
      "   ------- -------------------------------- 39.3/199.3 MB 1.1 MB/s eta 0:02:27\n",
      "   ------- -------------------------------- 39.6/199.3 MB 1.1 MB/s eta 0:02:27\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   ------- -------------------------------- 39.8/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   -------- ------------------------------- 40.1/199.3 MB 1.1 MB/s eta 0:02:31\n",
      "   -------- ------------------------------- 40.4/199.3 MB 1.1 MB/s eta 0:02:30\n",
      "   -------- ------------------------------- 40.9/199.3 MB 1.1 MB/s eta 0:02:29\n",
      "   -------- ------------------------------- 40.9/199.3 MB 1.1 MB/s eta 0:02:29\n",
      "   -------- ------------------------------- 41.2/199.3 MB 1.1 MB/s eta 0:02:25\n",
      "   -------- ------------------------------- 41.4/199.3 MB 1.1 MB/s eta 0:02:24\n",
      "   -------- ------------------------------- 41.4/199.3 MB 1.1 MB/s eta 0:02:24\n",
      "   -------- ------------------------------- 41.7/199.3 MB 1.1 MB/s eta 0:02:26\n",
      "   -------- ------------------------------- 41.9/199.3 MB 1.1 MB/s eta 0:02:25\n",
      "   -------- ------------------------------- 42.2/199.3 MB 1.1 MB/s eta 0:02:25\n",
      "   -------- ------------------------------- 42.5/199.3 MB 1.1 MB/s eta 0:02:22\n",
      "   -------- ------------------------------- 42.7/199.3 MB 1.1 MB/s eta 0:02:22\n",
      "   -------- ------------------------------- 43.3/199.3 MB 1.1 MB/s eta 0:02:20\n",
      "   -------- ------------------------------- 43.5/199.3 MB 1.1 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 43.8/199.3 MB 1.1 MB/s eta 0:02:18\n",
      "   -------- ------------------------------- 44.0/199.3 MB 1.1 MB/s eta 0:02:17\n",
      "   -------- ------------------------------- 44.3/199.3 MB 1.2 MB/s eta 0:02:14\n",
      "   -------- ------------------------------- 44.6/199.3 MB 1.2 MB/s eta 0:02:14\n",
      "   --------- ------------------------------ 45.1/199.3 MB 1.2 MB/s eta 0:02:12\n",
      "   --------- ------------------------------ 45.9/199.3 MB 1.2 MB/s eta 0:02:10\n",
      "   --------- ------------------------------ 46.1/199.3 MB 1.2 MB/s eta 0:02:09\n",
      "   --------- ------------------------------ 46.4/199.3 MB 1.2 MB/s eta 0:02:08\n",
      "   --------- ------------------------------ 46.9/199.3 MB 1.2 MB/s eta 0:02:07\n",
      "   --------- ------------------------------ 47.2/199.3 MB 1.2 MB/s eta 0:02:07\n",
      "   --------- ------------------------------ 47.7/199.3 MB 1.2 MB/s eta 0:02:06\n",
      "   --------- ------------------------------ 48.2/199.3 MB 1.2 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 48.5/199.3 MB 1.2 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 48.8/199.3 MB 1.2 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 49.0/199.3 MB 1.2 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 49.3/199.3 MB 1.2 MB/s eta 0:02:05\n",
      "   --------- ------------------------------ 49.8/199.3 MB 1.2 MB/s eta 0:02:04\n",
      "   ---------- ----------------------------- 50.1/199.3 MB 1.2 MB/s eta 0:02:03\n",
      "   ---------- ----------------------------- 50.3/199.3 MB 1.2 MB/s eta 0:02:02\n",
      "   ---------- ----------------------------- 50.6/199.3 MB 1.2 MB/s eta 0:02:01\n",
      "   ---------- ----------------------------- 51.1/199.3 MB 1.2 MB/s eta 0:02:00\n",
      "   ---------- ----------------------------- 51.9/199.3 MB 1.3 MB/s eta 0:01:58\n",
      "   ---------- ----------------------------- 52.2/199.3 MB 1.2 MB/s eta 0:01:59\n",
      "   ---------- ----------------------------- 52.4/199.3 MB 1.2 MB/s eta 0:01:58\n",
      "   ---------- ----------------------------- 52.7/199.3 MB 1.2 MB/s eta 0:02:00\n",
      "   ---------- ----------------------------- 53.0/199.3 MB 1.2 MB/s eta 0:01:59\n",
      "   ---------- ----------------------------- 53.5/199.3 MB 1.2 MB/s eta 0:01:59\n",
      "   ---------- ----------------------------- 53.7/199.3 MB 1.2 MB/s eta 0:01:59\n",
      "   ---------- ----------------------------- 54.5/199.3 MB 1.2 MB/s eta 0:01:58\n",
      "   ---------- ----------------------------- 54.8/199.3 MB 1.2 MB/s eta 0:01:58\n",
      "   ---------- ----------------------------- 54.8/199.3 MB 1.2 MB/s eta 0:01:58\n",
      "   ----------- ---------------------------- 55.3/199.3 MB 1.2 MB/s eta 0:01:57\n",
      "   ----------- ---------------------------- 55.6/199.3 MB 1.2 MB/s eta 0:01:57\n",
      "   ----------- ---------------------------- 55.8/199.3 MB 1.2 MB/s eta 0:01:56\n",
      "   ----------- ---------------------------- 56.1/199.3 MB 1.2 MB/s eta 0:01:56\n",
      "   ----------- ---------------------------- 56.6/199.3 MB 1.3 MB/s eta 0:01:54\n",
      "   ----------- ---------------------------- 56.9/199.3 MB 1.3 MB/s eta 0:01:54\n",
      "   ----------- ---------------------------- 57.4/199.3 MB 1.3 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 57.7/199.3 MB 1.3 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 57.9/199.3 MB 1.3 MB/s eta 0:01:53\n",
      "   ----------- ---------------------------- 58.5/199.3 MB 1.3 MB/s eta 0:01:52\n",
      "   ----------- ---------------------------- 58.7/199.3 MB 1.3 MB/s eta 0:01:51\n",
      "   ----------- ---------------------------- 59.2/199.3 MB 1.3 MB/s eta 0:01:50\n",
      "   ----------- ---------------------------- 59.8/199.3 MB 1.3 MB/s eta 0:01:49\n",
      "   ------------ --------------------------- 60.0/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 60.6/199.3 MB 1.3 MB/s eta 0:01:47\n",
      "   ------------ --------------------------- 60.8/199.3 MB 1.3 MB/s eta 0:01:47\n",
      "   ------------ --------------------------- 61.1/199.3 MB 1.3 MB/s eta 0:01:47\n",
      "   ------------ --------------------------- 61.3/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 61.6/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 61.9/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 62.1/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 62.4/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 62.7/199.3 MB 1.3 MB/s eta 0:01:45\n",
      "   ------------ --------------------------- 62.9/199.3 MB 1.3 MB/s eta 0:01:44\n",
      "   ------------ --------------------------- 62.9/199.3 MB 1.3 MB/s eta 0:01:44\n",
      "   ------------ --------------------------- 63.2/199.3 MB 1.3 MB/s eta 0:01:46\n",
      "   ------------ --------------------------- 63.2/199.3 MB 1.3 MB/s eta 0:01:46\n",
      "   ------------ --------------------------- 63.2/199.3 MB 1.3 MB/s eta 0:01:46\n",
      "   ------------ --------------------------- 63.4/199.3 MB 1.3 MB/s eta 0:01:47\n",
      "   ------------ --------------------------- 63.7/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 63.7/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 64.0/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 64.2/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 64.2/199.3 MB 1.3 MB/s eta 0:01:48\n",
      "   ------------ --------------------------- 64.5/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------ --------------------------- 64.7/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------ --------------------------- 64.7/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 65.0/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 65.3/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 65.5/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 65.5/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 65.8/199.3 MB 1.2 MB/s eta 0:01:49\n",
      "   ------------- -------------------------- 66.1/199.3 MB 1.2 MB/s eta 0:01:50\n",
      "   ------------- -------------------------- 66.1/199.3 MB 1.2 MB/s eta 0:01:50\n",
      "   ------------- -------------------------- 66.1/199.3 MB 1.2 MB/s eta 0:01:50\n",
      "   ------------- -------------------------- 66.3/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 66.3/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 66.6/199.3 MB 1.2 MB/s eta 0:01:53\n",
      "   ------------- -------------------------- 66.8/199.3 MB 1.2 MB/s eta 0:01:53\n",
      "   ------------- -------------------------- 67.1/199.3 MB 1.2 MB/s eta 0:01:53\n",
      "   ------------- -------------------------- 67.4/199.3 MB 1.2 MB/s eta 0:01:53\n",
      "   ------------- -------------------------- 67.6/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 67.6/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 67.9/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 67.9/199.3 MB 1.2 MB/s eta 0:01:52\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.2/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.4/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.4/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.4/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.4/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.4/199.3 MB 1.2 MB/s eta 0:01:54\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.7/199.3 MB 1.1 MB/s eta 0:01:55\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 68.9/199.3 MB 1.1 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 69.2/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 69.2/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 69.2/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 69.5/199.3 MB 1.1 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 69.5/199.3 MB 1.1 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 69.5/199.3 MB 1.1 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 69.7/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 69.7/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 69.7/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 70.0/199.3 MB 1.0 MB/s eta 0:02:07\n",
      "   -------------- ------------------------- 70.0/199.3 MB 1.0 MB/s eta 0:02:07\n",
      "   -------------- ------------------------- 70.0/199.3 MB 1.0 MB/s eta 0:02:07\n",
      "   -------------- ------------------------- 70.3/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 70.3/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 70.3/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 70.3/199.3 MB 1.1 MB/s eta 0:02:03\n",
      "   -------------- ------------------------- 70.5/199.3 MB 1.0 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 70.5/199.3 MB 1.0 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 70.8/199.3 MB 1.0 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 70.8/199.3 MB 1.0 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 70.8/199.3 MB 1.0 MB/s eta 0:02:06\n",
      "   -------------- ------------------------- 71.0/199.3 MB 1.0 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 71.0/199.3 MB 1.0 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 71.3/199.3 MB 1.0 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 71.3/199.3 MB 1.0 MB/s eta 0:02:08\n",
      "   -------------- ------------------------ 71.6/199.3 MB 999.8 kB/s eta 0:02:08\n",
      "   -------------- ------------------------ 71.6/199.3 MB 999.8 kB/s eta 0:02:08\n",
      "   -------------- ------------------------ 71.8/199.3 MB 988.4 kB/s eta 0:02:09\n",
      "   -------------- ------------------------ 71.8/199.3 MB 988.4 kB/s eta 0:02:09\n",
      "   -------------- ------------------------ 71.8/199.3 MB 988.4 kB/s eta 0:02:09\n",
      "   -------------- ------------------------ 72.1/199.3 MB 961.2 kB/s eta 0:02:13\n",
      "   -------------- ------------------------ 72.1/199.3 MB 961.2 kB/s eta 0:02:13\n",
      "   -------------- ------------------------ 72.1/199.3 MB 961.2 kB/s eta 0:02:13\n",
      "   -------------- ------------------------ 72.1/199.3 MB 961.2 kB/s eta 0:02:13\n",
      "   -------------- ------------------------ 72.4/199.3 MB 929.6 kB/s eta 0:02:17\n",
      "   -------------- ------------------------ 72.4/199.3 MB 929.6 kB/s eta 0:02:17\n",
      "   -------------- ------------------------ 72.4/199.3 MB 929.6 kB/s eta 0:02:17\n",
      "   -------------- ------------------------ 72.6/199.3 MB 901.0 kB/s eta 0:02:21\n",
      "   -------------- ------------------------ 72.6/199.3 MB 901.0 kB/s eta 0:02:21\n",
      "   -------------- ------------------------ 72.9/199.3 MB 875.2 kB/s eta 0:02:25\n",
      "   -------------- ------------------------ 72.9/199.3 MB 875.2 kB/s eta 0:02:25\n",
      "   -------------- ------------------------ 72.9/199.3 MB 875.2 kB/s eta 0:02:25\n",
      "   -------------- ------------------------ 72.9/199.3 MB 875.2 kB/s eta 0:02:25\n",
      "   -------------- ------------------------ 72.9/199.3 MB 875.2 kB/s eta 0:02:25\n",
      "   -------------- ------------------------ 73.1/199.3 MB 816.5 kB/s eta 0:02:35\n",
      "   -------------- ------------------------ 73.1/199.3 MB 816.5 kB/s eta 0:02:35\n",
      "   -------------- ------------------------ 73.1/199.3 MB 816.5 kB/s eta 0:02:35\n",
      "   -------------- ------------------------ 73.1/199.3 MB 816.5 kB/s eta 0:02:35\n",
      "   -------------- ------------------------ 73.4/199.3 MB 790.1 kB/s eta 0:02:40\n",
      "   -------------- ------------------------ 73.4/199.3 MB 790.1 kB/s eta 0:02:40\n",
      "   -------------- ------------------------ 73.4/199.3 MB 790.1 kB/s eta 0:02:40\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.7/199.3 MB 761.0 kB/s eta 0:02:46\n",
      "   -------------- ------------------------ 73.9/199.3 MB 683.0 kB/s eta 0:03:04\n",
      "   -------------- ------------------------ 73.9/199.3 MB 683.0 kB/s eta 0:03:04\n",
      "   -------------- ------------------------ 73.9/199.3 MB 683.0 kB/s eta 0:03:04\n",
      "   -------------- ------------------------ 74.2/199.3 MB 644.3 kB/s eta 0:03:15\n",
      "   -------------- ------------------------ 74.2/199.3 MB 644.3 kB/s eta 0:03:15\n",
      "   -------------- ------------------------ 74.4/199.3 MB 646.6 kB/s eta 0:03:14\n",
      "   -------------- ------------------------ 74.7/199.3 MB 640.2 kB/s eta 0:03:15\n",
      "   -------------- ------------------------ 74.7/199.3 MB 640.2 kB/s eta 0:03:15\n",
      "   -------------- ------------------------ 75.0/199.3 MB 622.7 kB/s eta 0:03:20\n",
      "   -------------- ------------------------ 75.0/199.3 MB 622.7 kB/s eta 0:03:20\n",
      "   -------------- ------------------------ 75.2/199.3 MB 606.4 kB/s eta 0:03:25\n",
      "   -------------- ------------------------ 75.2/199.3 MB 606.4 kB/s eta 0:03:25\n",
      "   -------------- ------------------------ 75.2/199.3 MB 606.4 kB/s eta 0:03:25\n",
      "   -------------- ------------------------ 75.5/199.3 MB 579.1 kB/s eta 0:03:34\n",
      "   -------------- ------------------------ 75.5/199.3 MB 579.1 kB/s eta 0:03:34\n",
      "   -------------- ------------------------ 75.5/199.3 MB 579.1 kB/s eta 0:03:34\n",
      "   -------------- ------------------------ 75.8/199.3 MB 560.7 kB/s eta 0:03:41\n",
      "   -------------- ------------------------ 75.8/199.3 MB 560.7 kB/s eta 0:03:41\n",
      "   -------------- ------------------------ 75.8/199.3 MB 560.7 kB/s eta 0:03:41\n",
      "   -------------- ------------------------ 75.8/199.3 MB 560.7 kB/s eta 0:03:41\n",
      "   -------------- ------------------------ 76.0/199.3 MB 509.2 kB/s eta 0:04:03\n",
      "   -------------- ------------------------ 76.0/199.3 MB 509.2 kB/s eta 0:04:03\n",
      "   -------------- ------------------------ 76.3/199.3 MB 499.1 kB/s eta 0:04:07\n",
      "   -------------- ------------------------ 76.3/199.3 MB 499.1 kB/s eta 0:04:07\n",
      "   -------------- ------------------------ 76.3/199.3 MB 499.1 kB/s eta 0:04:07\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   -------------- ------------------------ 76.5/199.3 MB 482.4 kB/s eta 0:04:15\n",
      "   --------------- ----------------------- 76.8/199.3 MB 450.3 kB/s eta 0:04:33\n",
      "   --------------- ----------------------- 76.8/199.3 MB 450.3 kB/s eta 0:04:33\n",
      "   --------------- ----------------------- 76.8/199.3 MB 450.3 kB/s eta 0:04:33\n",
      "   --------------- ----------------------- 76.8/199.3 MB 450.3 kB/s eta 0:04:33\n",
      "   --------------- ----------------------- 76.8/199.3 MB 450.3 kB/s eta 0:04:33\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.1/199.3 MB 437.1 kB/s eta 0:04:40\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.3/199.3 MB 385.9 kB/s eta 0:05:17\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.6/199.3 MB 314.7 kB/s eta 0:06:27\n",
      "   --------------- ----------------------- 77.9/199.3 MB 306.5 kB/s eta 0:06:37\n",
      "   --------------- ----------------------- 77.9/199.3 MB 306.5 kB/s eta 0:06:37\n",
      "   --------------- ----------------------- 78.1/199.3 MB 311.3 kB/s eta 0:06:30\n",
      "   --------------- ----------------------- 78.4/199.3 MB 316.6 kB/s eta 0:06:23\n",
      "   --------------- ----------------------- 78.4/199.3 MB 316.6 kB/s eta 0:06:23\n",
      "   --------------- ----------------------- 78.4/199.3 MB 316.6 kB/s eta 0:06:23\n",
      "   --------------- ----------------------- 78.6/199.3 MB 322.8 kB/s eta 0:06:14\n",
      "   --------------- ----------------------- 78.6/199.3 MB 322.8 kB/s eta 0:06:14\n",
      "   --------------- ----------------------- 78.6/199.3 MB 322.8 kB/s eta 0:06:14\n",
      "   --------------- ----------------------- 78.6/199.3 MB 322.8 kB/s eta 0:06:14\n",
      "   --------------- ----------------------- 78.9/199.3 MB 320.6 kB/s eta 0:06:16\n",
      "   --------------- ----------------------- 79.4/199.3 MB 335.2 kB/s eta 0:05:58\n",
      "   --------------- ----------------------- 79.4/199.3 MB 335.2 kB/s eta 0:05:58\n",
      "   --------------- ----------------------- 79.7/199.3 MB 337.7 kB/s eta 0:05:55\n",
      "   --------------- ----------------------- 79.7/199.3 MB 337.7 kB/s eta 0:05:55\n",
      "   --------------- ----------------------- 80.0/199.3 MB 343.1 kB/s eta 0:05:48\n",
      "   --------------- ----------------------- 80.0/199.3 MB 343.1 kB/s eta 0:05:48\n",
      "   --------------- ----------------------- 80.2/199.3 MB 345.1 kB/s eta 0:05:46\n",
      "   --------------- ----------------------- 80.2/199.3 MB 345.1 kB/s eta 0:05:46\n",
      "   --------------- ----------------------- 80.2/199.3 MB 345.1 kB/s eta 0:05:46\n",
      "   --------------- ----------------------- 80.5/199.3 MB 344.9 kB/s eta 0:05:45\n",
      "   --------------- ----------------------- 80.5/199.3 MB 344.9 kB/s eta 0:05:45\n",
      "   --------------- ----------------------- 80.7/199.3 MB 350.8 kB/s eta 0:05:39\n",
      "   --------------- ----------------------- 81.0/199.3 MB 357.2 kB/s eta 0:05:32\n",
      "   --------------- ----------------------- 81.0/199.3 MB 357.2 kB/s eta 0:05:32\n",
      "   ---------------- ---------------------- 82.1/199.3 MB 386.5 kB/s eta 0:05:04\n",
      "   ---------------- ---------------------- 83.1/199.3 MB 415.0 kB/s eta 0:04:41\n",
      "   ---------------- ---------------------- 83.9/199.3 MB 438.3 kB/s eta 0:04:24\n",
      "   ---------------- ---------------------- 84.9/199.3 MB 472.7 kB/s eta 0:04:02\n",
      "   ---------------- ---------------------- 85.7/199.3 MB 495.8 kB/s eta 0:03:50\n",
      "   ---------------- ---------------------- 86.0/199.3 MB 503.6 kB/s eta 0:03:46\n",
      "   ---------------- ---------------------- 86.0/199.3 MB 503.6 kB/s eta 0:03:46\n",
      "   ---------------- ---------------------- 86.0/199.3 MB 503.6 kB/s eta 0:03:46\n",
      "   ---------------- ---------------------- 86.5/199.3 MB 507.3 kB/s eta 0:03:43\n",
      "   ----------------- --------------------- 87.3/199.3 MB 527.0 kB/s eta 0:03:33\n",
      "   ----------------- --------------------- 87.8/199.3 MB 539.5 kB/s eta 0:03:27\n",
      "   ----------------- --------------------- 88.9/199.3 MB 570.4 kB/s eta 0:03:14\n",
      "   ----------------- --------------------- 89.4/199.3 MB 589.9 kB/s eta 0:03:07\n",
      "   ----------------- --------------------- 89.7/199.3 MB 597.0 kB/s eta 0:03:04\n",
      "   ----------------- --------------------- 89.9/199.3 MB 599.5 kB/s eta 0:03:03\n",
      "   ----------------- --------------------- 90.7/199.3 MB 629.4 kB/s eta 0:02:53\n",
      "   ----------------- --------------------- 91.5/199.3 MB 652.2 kB/s eta 0:02:46\n",
      "   ------------------ -------------------- 92.5/199.3 MB 682.4 kB/s eta 0:02:37\n",
      "   ------------------ -------------------- 93.3/199.3 MB 705.3 kB/s eta 0:02:31\n",
      "   ------------------ -------------------- 93.8/199.3 MB 719.9 kB/s eta 0:02:27\n",
      "   ------------------ -------------------- 94.9/199.3 MB 749.8 kB/s eta 0:02:20\n",
      "   ------------------ -------------------- 95.9/199.3 MB 779.3 kB/s eta 0:02:13\n",
      "   ------------------ -------------------- 96.7/199.3 MB 806.5 kB/s eta 0:02:08\n",
      "   ------------------- ------------------- 97.5/199.3 MB 828.3 kB/s eta 0:02:03\n",
      "   ------------------- ------------------- 98.6/199.3 MB 857.2 kB/s eta 0:01:58\n",
      "   ------------------- ------------------- 99.6/199.3 MB 908.6 kB/s eta 0:01:50\n",
      "   ------------------- ------------------ 100.7/199.3 MB 938.0 kB/s eta 0:01:46\n",
      "   ------------------- ------------------ 101.7/199.3 MB 967.1 kB/s eta 0:01:41\n",
      "   ------------------- ------------------ 102.8/199.3 MB 994.1 kB/s eta 0:01:38\n",
      "   -------------------- ------------------- 103.0/199.3 MB 1.0 MB/s eta 0:01:37\n",
      "   -------------------- ------------------- 104.1/199.3 MB 1.0 MB/s eta 0:01:32\n",
      "   --------------------- ------------------ 105.1/199.3 MB 1.1 MB/s eta 0:01:29\n",
      "   --------------------- ------------------ 106.2/199.3 MB 1.1 MB/s eta 0:01:26\n",
      "   --------------------- ------------------ 107.0/199.3 MB 1.1 MB/s eta 0:01:22\n",
      "   --------------------- ------------------ 107.5/199.3 MB 1.1 MB/s eta 0:01:21\n",
      "   --------------------- ------------------ 108.3/199.3 MB 1.2 MB/s eta 0:01:19\n",
      "   --------------------- ------------------ 109.3/199.3 MB 1.2 MB/s eta 0:01:16\n",
      "   ---------------------- ----------------- 110.4/199.3 MB 1.3 MB/s eta 0:01:11\n",
      "   ---------------------- ----------------- 111.7/199.3 MB 1.3 MB/s eta 0:01:08\n",
      "   ---------------------- ----------------- 113.0/199.3 MB 1.3 MB/s eta 0:01:05\n",
      "   ---------------------- ----------------- 114.0/199.3 MB 1.4 MB/s eta 0:01:03\n",
      "   ----------------------- ---------------- 115.3/199.3 MB 1.4 MB/s eta 0:01:01\n",
      "   ----------------------- ---------------- 116.4/199.3 MB 1.4 MB/s eta 0:00:59\n",
      "   ----------------------- ---------------- 117.2/199.3 MB 1.5 MB/s eta 0:00:57\n",
      "   ----------------------- ---------------- 118.0/199.3 MB 1.5 MB/s eta 0:00:55\n",
      "   ----------------------- ---------------- 119.0/199.3 MB 1.5 MB/s eta 0:00:54\n",
      "   ------------------------ --------------- 119.8/199.3 MB 1.5 MB/s eta 0:00:53\n",
      "   ------------------------ --------------- 120.6/199.3 MB 1.5 MB/s eta 0:00:52\n",
      "   ------------------------ --------------- 121.4/199.3 MB 1.6 MB/s eta 0:00:50\n",
      "   ------------------------ --------------- 122.4/199.3 MB 1.6 MB/s eta 0:00:49\n",
      "   ------------------------ --------------- 123.2/199.3 MB 1.6 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 124.3/199.3 MB 1.7 MB/s eta 0:00:46\n",
      "   ------------------------- -------------- 125.0/199.3 MB 1.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 125.8/199.3 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------- -------------- 126.9/199.3 MB 1.7 MB/s eta 0:00:42\n",
      "   ------------------------- -------------- 127.9/199.3 MB 1.8 MB/s eta 0:00:41\n",
      "   ------------------------- -------------- 128.7/199.3 MB 1.8 MB/s eta 0:00:40\n",
      "   ------------------------- -------------- 129.5/199.3 MB 1.8 MB/s eta 0:00:39\n",
      "   -------------------------- ------------- 130.5/199.3 MB 1.8 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 131.6/199.3 MB 1.9 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 132.1/199.3 MB 1.9 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 133.2/199.3 MB 1.9 MB/s eta 0:00:35\n",
      "   -------------------------- ------------- 134.0/199.3 MB 1.9 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 135.0/199.3 MB 2.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 135.8/199.3 MB 2.0 MB/s eta 0:00:32\n",
      "   --------------------------- ------------ 136.8/199.3 MB 2.0 MB/s eta 0:00:31\n",
      "   --------------------------- ------------ 137.6/199.3 MB 2.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 138.4/199.3 MB 2.1 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 139.2/199.3 MB 2.2 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 140.2/199.3 MB 2.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 141.0/199.3 MB 2.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 142.1/199.3 MB 2.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 142.9/199.3 MB 2.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 143.9/199.3 MB 2.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 145.0/199.3 MB 2.3 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 145.8/199.3 MB 2.3 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 146.8/199.3 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 147.3/199.3 MB 2.4 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 148.1/199.3 MB 2.4 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 148.9/199.3 MB 2.5 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 149.7/199.3 MB 2.6 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 150.5/199.3 MB 2.6 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 151.3/199.3 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 151.8/199.3 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 152.6/199.3 MB 2.6 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 153.4/199.3 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 154.4/199.3 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 154.9/199.3 MB 2.6 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 155.2/199.3 MB 2.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 155.2/199.3 MB 2.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 155.2/199.3 MB 2.6 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 155.5/199.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.5/199.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.5/199.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.5/199.3 MB 2.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 155.7/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.0/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.0/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.2/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.2/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.5/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 156.8/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.0/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.0/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.3/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.5/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.5/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.5/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.5/199.3 MB 2.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.8/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 157.8/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 158.3/199.3 MB 2.7 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 159.1/199.3 MB 2.7 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 159.6/199.3 MB 2.7 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 160.7/199.3 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 161.5/199.3 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 162.5/199.3 MB 2.8 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 163.3/199.3 MB 2.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 164.1/199.3 MB 2.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 164.9/199.3 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 165.7/199.3 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 166.5/199.3 MB 2.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 167.0/199.3 MB 2.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 167.5/199.3 MB 2.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 167.8/199.3 MB 2.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 168.8/199.3 MB 3.0 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 169.6/199.3 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 170.4/199.3 MB 3.0 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 171.2/199.3 MB 3.1 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 172.0/199.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 173.0/199.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 173.8/199.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 174.6/199.3 MB 3.1 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 175.4/199.3 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 176.2/199.3 MB 3.2 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 177.2/199.3 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.7/199.3 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 178.5/199.3 MB 3.2 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 179.3/199.3 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 180.1/199.3 MB 3.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 180.9/199.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 181.9/199.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.0/199.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 183.8/199.3 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 184.5/199.3 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 185.1/199.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 185.9/199.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 186.4/199.3 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 187.2/199.3 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 187.7/199.3 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 188.7/199.3 MB 3.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 189.5/199.3 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 190.3/199.3 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 191.1/199.3 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 191.9/199.3 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 192.7/199.3 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.5/199.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  194.5/199.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  195.3/199.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  196.3/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.4/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.2/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.3/199.3 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.6/536.6 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Using cached ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "Downloading matplotlib-3.7.3-cp39-cp39-win_amd64.whl (7.5 MB)\n",
      "   ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.5 MB 2.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.6/7.5 MB 873.8 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.1/7.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.6/7.5 MB 782.3 kB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.5 MB 913.7 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.4/7.5 MB 639.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.2/7.5 MB 758.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 5.0/7.5 MB 731.2 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.5 MB 760.8 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 5.8/7.5 MB 693.6 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.5 MB 740.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 7.1/7.5 MB 690.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  7.3/7.5 MB 711.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.5/7.5 MB 710.1 kB/s eta 0:00:00\n",
      "Downloading mmpose-1.2.0-py2.py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 882.8 kB/s eta 0:00:00\n",
      "Downloading prettytable-3.11.0-py3-none-any.whl (28 kB)\n",
      "Downloading pyarrow-19.0.1-cp39-cp39-win_amd64.whl (25.5 MB)\n",
      "   ---------------------------------------- 0.0/25.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.5 MB 4.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/25.5 MB 3.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/25.5 MB 3.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.1/25.5 MB 2.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.1/25.5 MB 2.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.1/25.5 MB 2.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.1/25.5 MB 2.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.1/25.5 MB 2.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 2.9/25.5 MB 1.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 3.7/25.5 MB 1.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.5/25.5 MB 1.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 5.0/25.5 MB 1.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.0/25.5 MB 2.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.3/25.5 MB 2.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 6.3/25.5 MB 2.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.6/25.5 MB 1.9 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.3/25.5 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.9/25.5 MB 2.0 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.7/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 8.9/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.5 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.5/25.5 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.7/25.5 MB 1.5 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 11.5/25.5 MB 1.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 12.3/25.5 MB 1.6 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 13.4/25.5 MB 1.7 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 13.9/25.5 MB 1.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 14.9/25.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.5/25.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 16.3/25.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.8/25.5 MB 1.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.3/25.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 18.1/25.5 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.4/25.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.2/25.5 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 21.0/25.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.8/25.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.3/25.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.8/25.5 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.9/25.5 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.5/25.5 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_yaml-1.4.0-py3-none-any.whl (17 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "   ---------------------------------------- 0.0/558.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 558.8/558.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading onnx-1.17.0-cp39-cp39-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.5 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.3/14.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 2.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.9/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.7/14.5 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.5/14.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.1/14.5 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.9/14.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.9/14.5 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.0/14.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 4.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/11.1 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/11.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading qai_hub-0.31.0-py3-none-any.whl (108 kB)\n",
      "Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "   ---------------------------------------- 0.0/904.2 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/904.2 kB ? eta -:--:--\n",
      "   ---------------------- --------------- 524.3/904.2 kB 840.2 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 524.3/904.2 kB 840.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 904.2/904.2 kB 894.2 kB/s eta 0:00:00\n",
      "Downloading torchvision-0.19.1-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 68.4 MB/s eta 0:00:00\n",
      "Downloading qai_hub_models-0.33.0-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 645.3 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 860.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 978.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 674.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 702.7 kB/s eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached mmengine-0.10.7-py3-none-any.whl (452 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp39-cp39-win_amd64.whl (118 kB)\n",
      "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Using cached xtcocotools-1.14.3-cp39-cp39-win_amd64.whl (88 kB)\n",
      "Using cached addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Using cached munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Downloading pycocotools-2.0.10-cp39-cp39-win_amd64.whl (80 kB)\n",
      "Downloading shapely-2.0.7-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Using cached yapf-0.43.0-py3-none-any.whl (256 kB)\n",
      "Downloading botocore-1.39.17-py3-none-any.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.9 MB 1.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.3/13.9 MB 2.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/13.9 MB 2.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.4/13.9 MB 2.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.9/13.9 MB 2.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.4/13.9 MB 2.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.4/13.9 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.9/13.9 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.5/13.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 4.7/13.9 MB 2.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 5.2/13.9 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 5.8/13.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.6/13.9 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 7.3/13.9 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.3/13.9 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.6/13.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.9/13.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.1/13.9 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.4/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.7/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.9/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.4/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.4/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.4/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.4/13.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.7/13.9 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.7/13.9 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.0/13.9 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.0/13.9 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 10.2/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.5/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.7/13.9 MB 1.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 11.5/13.9 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.6/13.9 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.4/13.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 1.8 MB/s eta 0:00:00\n",
      "Using cached cython-3.1.2-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py): started\n",
      "  Building wheel for mmcv (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for mmcv\n",
      "Failed to build mmcv\n"
     ]
    }
   ],
   "source": [
    "pip install \"qai-hub-models[rtmpose-body2d]\" torch==2.4.1 -f https://download.openmmlab.com/mmcv/dist/cpu/torch2.4/index.html -f https://qaihub-public-python-wheels.s3.us-west-2.amazonaws.com/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e8baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running YOLOv8 Pose Estimation...\n",
      "\n",
      "0: 384x640 1 person, 138.2ms\n",
      "Speed: 3.6ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.2ms\n",
      "Speed: 3.3ms preprocess, 113.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.0ms\n",
      "Speed: 2.9ms preprocess, 113.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.0ms\n",
      "Speed: 3.4ms preprocess, 114.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.9ms\n",
      "Speed: 3.1ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.4ms\n",
      "Speed: 2.5ms preprocess, 114.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.6ms\n",
      "Speed: 3.1ms preprocess, 112.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.1ms\n",
      "Speed: 2.9ms preprocess, 110.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.1ms\n",
      "Speed: 2.8ms preprocess, 103.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.2ms\n",
      "Speed: 1.8ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.5ms\n",
      "Speed: 2.1ms preprocess, 66.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 1.6ms preprocess, 74.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 1.8ms preprocess, 63.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 1.6ms preprocess, 60.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 2.2ms preprocess, 76.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 1.8ms preprocess, 66.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 1.7ms preprocess, 65.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 1.6ms preprocess, 57.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 1.6ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 2.2ms preprocess, 68.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.8ms\n",
      "Speed: 2.0ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.6ms\n",
      "Speed: 2.3ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.8ms\n",
      "Speed: 1.8ms preprocess, 57.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.2ms\n",
      "Speed: 1.9ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.7ms\n",
      "Speed: 1.8ms preprocess, 59.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.4ms\n",
      "Speed: 1.8ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Speed: 1.8ms preprocess, 59.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.5ms\n",
      "Speed: 1.9ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.6ms\n",
      "Speed: 1.8ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.0ms\n",
      "Speed: 1.8ms preprocess, 60.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.6ms\n",
      "Speed: 1.7ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 2.4ms preprocess, 64.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.8ms\n",
      "Speed: 1.8ms preprocess, 59.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.6ms\n",
      "Speed: 1.6ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.0ms\n",
      "Speed: 1.6ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.9ms\n",
      "Speed: 1.8ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.6ms\n",
      "Speed: 1.6ms preprocess, 54.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.9ms\n",
      "Speed: 1.8ms preprocess, 60.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.5ms\n",
      "Speed: 1.7ms preprocess, 68.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 2.1ms preprocess, 65.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 1.7ms preprocess, 66.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.3ms\n",
      "Speed: 2.1ms preprocess, 84.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.9ms\n",
      "Speed: 3.1ms preprocess, 116.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.7ms\n",
      "Speed: 3.4ms preprocess, 91.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.2ms\n",
      "Speed: 3.1ms preprocess, 85.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.0ms\n",
      "Speed: 3.7ms preprocess, 80.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 1.9ms preprocess, 81.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.4ms preprocess, 68.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.3ms\n",
      "Speed: 3.3ms preprocess, 78.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.1ms\n",
      "Speed: 2.1ms preprocess, 58.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.3ms\n",
      "Speed: 2.6ms preprocess, 87.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 2.0ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 1.7ms preprocess, 76.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.9ms\n",
      "Speed: 3.2ms preprocess, 71.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.4ms\n",
      "Speed: 2.8ms preprocess, 65.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.1ms\n",
      "Speed: 1.9ms preprocess, 68.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 2.8ms preprocess, 76.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.8ms\n",
      "Speed: 1.6ms preprocess, 58.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "Speed: 1.9ms preprocess, 62.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 1.8ms preprocess, 60.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 2.4ms preprocess, 67.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 2.1ms preprocess, 60.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 1.7ms preprocess, 65.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.2ms\n",
      "Speed: 1.8ms preprocess, 81.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 2.3ms preprocess, 74.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.8ms\n",
      "Speed: 2.5ms preprocess, 70.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 2.0ms preprocess, 73.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.3ms\n",
      "Speed: 2.1ms preprocess, 68.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 1.9ms preprocess, 70.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.6ms\n",
      "Speed: 1.8ms preprocess, 72.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 1.8ms preprocess, 65.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 1.8ms preprocess, 73.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 2.2ms preprocess, 63.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.0ms\n",
      "Speed: 1.8ms preprocess, 61.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.7ms\n",
      "Speed: 2.4ms preprocess, 69.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "Speed: 2.1ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.5ms\n",
      "Speed: 1.8ms preprocess, 62.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 1.9ms preprocess, 57.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.6ms\n",
      "Speed: 1.9ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 1.8ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.0ms\n",
      "Speed: 1.6ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.6ms\n",
      "Speed: 1.6ms preprocess, 67.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 1.8ms preprocess, 71.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.7ms\n",
      "Speed: 2.0ms preprocess, 63.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.0ms\n",
      "Speed: 1.9ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.1ms\n",
      "Speed: 1.6ms preprocess, 62.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 2.0ms preprocess, 63.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 1.6ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 1.9ms preprocess, 59.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.0ms\n",
      "Speed: 1.9ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.1ms\n",
      "Speed: 1.6ms preprocess, 53.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.0ms\n",
      "Speed: 1.8ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.8ms\n",
      "Speed: 2.1ms preprocess, 53.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.4ms\n",
      "Speed: 1.6ms preprocess, 57.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.1ms\n",
      "Speed: 1.6ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.6ms\n",
      "Speed: 1.7ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.9ms\n",
      "Speed: 1.8ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.2ms\n",
      "Speed: 1.7ms preprocess, 56.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.3ms\n",
      "Speed: 1.9ms preprocess, 71.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.3ms\n",
      "Speed: 2.1ms preprocess, 61.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.5ms\n",
      "Speed: 1.8ms preprocess, 58.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.2ms\n",
      "Speed: 1.6ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 2.7ms preprocess, 62.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 1.7ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.2ms\n",
      "Speed: 2.1ms preprocess, 58.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Speed: 1.8ms preprocess, 63.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.3ms\n",
      "Speed: 1.6ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Speed: 1.7ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.7ms\n",
      "Speed: 1.6ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.4ms\n",
      "Speed: 1.8ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.0ms\n",
      "Speed: 1.5ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Speed: 1.6ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.6ms\n",
      "Speed: 1.7ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Speed: 1.8ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.9ms\n",
      "Speed: 1.7ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.3ms\n",
      "Speed: 1.8ms preprocess, 61.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.5ms\n",
      "Speed: 1.7ms preprocess, 61.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.8ms preprocess, 59.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.3ms\n",
      "Speed: 2.3ms preprocess, 58.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.4ms\n",
      "Speed: 1.5ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 1.9ms preprocess, 59.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 2.2ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.4ms\n",
      "Speed: 2.1ms preprocess, 57.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.6ms\n",
      "Speed: 1.7ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.1ms\n",
      "Speed: 2.1ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.0ms\n",
      "Speed: 1.9ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.2ms\n",
      "Speed: 1.9ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.4ms\n",
      "Speed: 1.6ms preprocess, 55.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.3ms\n",
      "Speed: 1.8ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.7ms\n",
      "Speed: 2.3ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 1.5ms preprocess, 71.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.8ms\n",
      "Speed: 1.7ms preprocess, 59.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.5ms\n",
      "Speed: 1.7ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.6ms\n",
      "Speed: 1.7ms preprocess, 54.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 1.9ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.3ms\n",
      "Speed: 1.8ms preprocess, 60.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.7ms\n",
      "Speed: 1.8ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 1.8ms preprocess, 55.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Speed: 2.0ms preprocess, 65.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.8ms\n",
      "Speed: 1.8ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Speed: 1.5ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.8ms\n",
      "Speed: 1.7ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.0ms\n",
      "Speed: 1.7ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.8ms\n",
      "Speed: 1.5ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.0ms\n",
      "Speed: 1.4ms preprocess, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.9ms\n",
      "Speed: 2.0ms preprocess, 58.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Speed: 2.3ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.8ms\n",
      "Speed: 1.9ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Speed: 1.7ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 1.8ms preprocess, 65.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.5ms\n",
      "Speed: 2.0ms preprocess, 59.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.0ms\n",
      "Speed: 1.7ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.6ms\n",
      "Speed: 1.8ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.9ms\n",
      "Speed: 2.0ms preprocess, 60.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 2.1ms preprocess, 62.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.3ms\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.5ms\n",
      "Speed: 1.9ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.7ms\n",
      "Speed: 1.6ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.8ms\n",
      "Speed: 1.9ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.3ms\n",
      "Speed: 2.0ms preprocess, 49.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.6ms\n",
      "Speed: 2.0ms preprocess, 61.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.7ms\n",
      "Speed: 2.1ms preprocess, 56.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.6ms\n",
      "Speed: 2.2ms preprocess, 56.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 1.5ms preprocess, 66.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 2.1ms preprocess, 69.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.0ms\n",
      "Speed: 1.9ms preprocess, 62.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.3ms\n",
      "Speed: 1.8ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 1.8ms preprocess, 59.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 1.8ms preprocess, 64.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 1.5ms preprocess, 62.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.4ms\n",
      "Speed: 1.9ms preprocess, 59.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.3ms\n",
      "Speed: 2.0ms preprocess, 50.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.1ms\n",
      "Speed: 2.1ms preprocess, 57.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.4ms\n",
      "Speed: 1.8ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.0ms\n",
      "Speed: 1.8ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.6ms\n",
      "Speed: 1.7ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.0ms\n",
      "Speed: 1.6ms preprocess, 59.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.0ms\n",
      "Speed: 1.8ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.4ms\n",
      "Speed: 2.3ms preprocess, 65.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.5ms\n",
      "Speed: 1.9ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.8ms\n",
      "Speed: 1.8ms preprocess, 78.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 1.6ms preprocess, 63.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.4ms\n",
      "Speed: 1.9ms preprocess, 60.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.9ms\n",
      "Speed: 1.7ms preprocess, 73.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 1.6ms preprocess, 68.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.5ms\n",
      "Speed: 2.0ms preprocess, 59.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 2.4ms preprocess, 59.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.4ms\n",
      "Speed: 1.6ms preprocess, 60.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.2ms\n",
      "Speed: 1.7ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.1ms\n",
      "Speed: 1.8ms preprocess, 57.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.7ms\n",
      "Speed: 1.8ms preprocess, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 1.8ms preprocess, 64.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 2.0ms preprocess, 59.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 1.6ms preprocess, 62.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.1ms\n",
      "Speed: 2.0ms preprocess, 61.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.3ms\n",
      "Speed: 1.9ms preprocess, 68.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 2.3ms preprocess, 60.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.0ms\n",
      "Speed: 1.8ms preprocess, 57.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.4ms\n",
      "Speed: 1.6ms preprocess, 62.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.4ms\n",
      "Speed: 2.1ms preprocess, 65.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 1.6ms preprocess, 73.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 1.5ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 1.6ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 1.7ms preprocess, 60.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 1.8ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.5ms\n",
      "Speed: 1.9ms preprocess, 66.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.9ms\n",
      "Speed: 3.6ms preprocess, 75.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 2.2ms preprocess, 66.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.7ms\n",
      "Speed: 2.0ms preprocess, 69.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.2ms\n",
      "Speed: 1.8ms preprocess, 75.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.1ms\n",
      "Speed: 2.1ms preprocess, 61.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.9ms\n",
      "Speed: 1.7ms preprocess, 64.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.7ms\n",
      "Speed: 1.8ms preprocess, 77.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Speed: 2.4ms preprocess, 70.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 1.8ms preprocess, 59.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.6ms\n",
      "Speed: 1.6ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 2.2ms preprocess, 62.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 2.7ms preprocess, 66.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.1ms\n",
      "Speed: 2.0ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.0ms\n",
      "Speed: 1.8ms preprocess, 65.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 2.3ms preprocess, 60.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.4ms\n",
      "Speed: 1.9ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Speed: 1.8ms preprocess, 67.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 1.7ms preprocess, 63.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.3ms\n",
      "Speed: 2.7ms preprocess, 86.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.7ms\n",
      "Speed: 2.8ms preprocess, 61.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 1.7ms preprocess, 62.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.7ms\n",
      "Speed: 2.9ms preprocess, 87.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.0ms\n",
      "Speed: 2.1ms preprocess, 61.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.1ms\n",
      "Speed: 2.0ms preprocess, 58.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.6ms\n",
      "Speed: 2.1ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.5ms\n",
      "Speed: 1.6ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.2ms\n",
      "Speed: 2.0ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.0ms\n",
      "Speed: 1.7ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.3ms\n",
      "Speed: 1.9ms preprocess, 61.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.3ms\n",
      "Speed: 1.6ms preprocess, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 1.7ms preprocess, 71.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.9ms preprocess, 64.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.2ms\n",
      "Speed: 1.7ms preprocess, 130.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.0ms\n",
      "Speed: 2.7ms preprocess, 121.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.5ms\n",
      "Speed: 3.8ms preprocess, 122.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 154.9ms\n",
      "Speed: 2.8ms preprocess, 154.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.7ms\n",
      "Speed: 3.8ms preprocess, 93.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.8ms\n",
      "Speed: 4.4ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 213.2ms\n",
      "Speed: 4.5ms preprocess, 213.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.8ms\n",
      "Speed: 5.3ms preprocess, 125.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.8ms\n",
      "Speed: 4.2ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.2ms\n",
      "Speed: 3.0ms preprocess, 114.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 152.6ms\n",
      "Speed: 3.2ms preprocess, 152.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.6ms\n",
      "Speed: 4.6ms preprocess, 121.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.2ms\n",
      "Speed: 4.9ms preprocess, 128.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 150.9ms\n",
      "Speed: 4.4ms preprocess, 150.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 196.9ms\n",
      "Speed: 4.1ms preprocess, 196.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 136.0ms\n",
      "Speed: 3.1ms preprocess, 136.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Running MediaPipe Pose Estimation...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "def yolo_pose_estimation(video_path, model_path, output_path=\"yolo_output.avi\"):\n",
    "    model = YOLO(model_path)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # VideoWriter to save output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot()\n",
    "            out.write(annotated_frame)\n",
    "            cv2.imshow(\"YOLOv8 Pose\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def mediapipe_pose_estimation(video_path, output_path=\"mediapipe_output.avi\"):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    pose = mp_pose.Pose()\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # VideoWriter to save output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"MediaPipe Pose\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "\n",
    "\n",
    "# === INPUT PATHS ===\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "yolo_model = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "\n",
    "# === RUN POSE ESTIMATION METHODS ===\n",
    "print(\"Running YOLOv8 Pose Estimation...\")\n",
    "yolo_pose_estimation(video_path, yolo_model)\n",
    "\n",
    "print(\"Running MediaPipe Pose Estimation...\")\n",
    "mediapipe_pose_estimation(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "def yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path=\"yolo_pose_football_output.avi\"):\n",
    "    pose_model = YOLO(pose_model_path)      # e.g. yolov8n-pose.pt\n",
    "    detect_model = YOLO(detect_model_path)  # e.g. yolov8n.pt (detection)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Save output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Run pose estimation\n",
    "        pose_results = pose_model(frame)\n",
    "        pose_frame = pose_results[0].plot()\n",
    "\n",
    "        # Run object detection for football (class 37 = sports ball)\n",
    "        detect_results = detect_model(frame)[0]\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            if cls_id == 37:  # 'sports ball' in COCO dataset\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(pose_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                cv2.putText(pose_frame, \"Football\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        # Display and save\n",
    "        out.write(pose_frame)\n",
    "        cv2.imshow(\"YOLOv8 Pose + Football Detection\", pose_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41745533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running YOLOv8 Pose + Football Detection...\n",
      "\n",
      "0: 384x640 1 person, 95.5ms\n",
      "Speed: 2.6ms preprocess, 95.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 139.3ms\n",
      "Speed: 2.1ms preprocess, 139.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.2ms\n",
      "Speed: 2.1ms preprocess, 83.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 100.0ms\n",
      "Speed: 1.9ms preprocess, 100.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 268.3ms\n",
      "Speed: 2.6ms preprocess, 268.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.4ms\n",
      "Speed: 1.9ms preprocess, 68.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.6ms\n",
      "Speed: 3.3ms preprocess, 88.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 108.9ms\n",
      "Speed: 2.0ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.9ms\n",
      "Speed: 2.5ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 104.2ms\n",
      "Speed: 2.0ms preprocess, 104.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 2.3ms preprocess, 99.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 123.8ms\n",
      "Speed: 2.2ms preprocess, 123.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 135.9ms\n",
      "Speed: 2.0ms preprocess, 135.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 137.0ms\n",
      "Speed: 2.0ms preprocess, 137.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 174.5ms\n",
      "Speed: 2.4ms preprocess, 174.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 118.5ms\n",
      "Speed: 1.9ms preprocess, 118.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.1ms\n",
      "Speed: 2.0ms preprocess, 105.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 105.9ms\n",
      "Speed: 2.0ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.8ms\n",
      "Speed: 2.0ms preprocess, 92.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 126.0ms\n",
      "Speed: 2.1ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 2.3ms preprocess, 84.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 68.3ms\n",
      "Speed: 2.2ms preprocess, 68.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.8ms\n",
      "Speed: 2.1ms preprocess, 83.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 99.0ms\n",
      "Speed: 1.7ms preprocess, 99.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.7ms\n",
      "Speed: 2.0ms preprocess, 107.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 96.0ms\n",
      "Speed: 2.4ms preprocess, 96.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.8ms\n",
      "Speed: 2.4ms preprocess, 110.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 96.6ms\n",
      "Speed: 3.6ms preprocess, 96.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 145.0ms\n",
      "Speed: 2.3ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 143.2ms\n",
      "Speed: 1.9ms preprocess, 143.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.8ms\n",
      "Speed: 2.4ms preprocess, 96.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 85.5ms\n",
      "Speed: 3.7ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.4ms\n",
      "Speed: 3.0ms preprocess, 88.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 95.4ms\n",
      "Speed: 1.8ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.3ms\n",
      "Speed: 2.6ms preprocess, 93.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 97.9ms\n",
      "Speed: 2.1ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.4ms\n",
      "Speed: 2.2ms preprocess, 84.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 129.3ms\n",
      "Speed: 1.8ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.5ms\n",
      "Speed: 3.0ms preprocess, 121.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 102.1ms\n",
      "Speed: 2.7ms preprocess, 102.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.2ms\n",
      "Speed: 3.8ms preprocess, 118.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 116.1ms\n",
      "Speed: 2.0ms preprocess, 116.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 142.0ms\n",
      "Speed: 2.2ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 111.1ms\n",
      "Speed: 1.9ms preprocess, 111.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.3ms\n",
      "Speed: 2.0ms preprocess, 128.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 117.2ms\n",
      "Speed: 2.0ms preprocess, 117.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.9ms\n",
      "Speed: 1.9ms preprocess, 91.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 74.6ms\n",
      "Speed: 2.4ms preprocess, 74.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 2.4ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.3ms\n",
      "Speed: 1.7ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.9ms\n",
      "Speed: 2.1ms preprocess, 70.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 161.8ms\n",
      "Speed: 1.9ms preprocess, 161.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.8ms preprocess, 76.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.6ms\n",
      "Speed: 3.0ms preprocess, 103.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.8ms\n",
      "Speed: 2.2ms preprocess, 100.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.6ms\n",
      "Speed: 2.3ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.9ms\n",
      "Speed: 2.6ms preprocess, 82.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.4ms\n",
      "Speed: 2.5ms preprocess, 67.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.9ms\n",
      "Speed: 2.8ms preprocess, 100.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 3.2ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.8ms\n",
      "Speed: 2.4ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.5ms\n",
      "Speed: 2.1ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.9ms\n",
      "Speed: 2.6ms preprocess, 81.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.4ms\n",
      "Speed: 1.8ms preprocess, 86.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.8ms\n",
      "Speed: 2.3ms preprocess, 84.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.5ms\n",
      "Speed: 1.9ms preprocess, 87.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 2.5ms preprocess, 84.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.7ms\n",
      "Speed: 2.2ms preprocess, 94.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 101.3ms\n",
      "Speed: 2.5ms preprocess, 101.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.0ms\n",
      "Speed: 3.2ms preprocess, 111.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 127.3ms\n",
      "Speed: 1.9ms preprocess, 127.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.0ms\n",
      "Speed: 3.8ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.2ms\n",
      "Speed: 2.2ms preprocess, 123.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.8ms\n",
      "Speed: 2.0ms preprocess, 96.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.4ms\n",
      "Speed: 7.1ms preprocess, 286.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.7ms\n",
      "Speed: 6.9ms preprocess, 261.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.0ms\n",
      "Speed: 7.0ms preprocess, 286.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 238.0ms\n",
      "Speed: 7.1ms preprocess, 238.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.9ms\n",
      "Speed: 6.0ms preprocess, 271.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.9ms\n",
      "Speed: 5.6ms preprocess, 255.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.1ms\n",
      "Speed: 7.8ms preprocess, 279.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.3ms\n",
      "Speed: 6.1ms preprocess, 241.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.2ms\n",
      "Speed: 6.4ms preprocess, 245.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.2ms\n",
      "Speed: 5.7ms preprocess, 231.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.0ms\n",
      "Speed: 6.6ms preprocess, 266.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 230.3ms\n",
      "Speed: 7.2ms preprocess, 230.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.9ms\n",
      "Speed: 6.5ms preprocess, 261.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.4ms\n",
      "Speed: 7.5ms preprocess, 250.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 287.2ms\n",
      "Speed: 6.6ms preprocess, 287.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.6ms\n",
      "Speed: 6.9ms preprocess, 262.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 281.3ms\n",
      "Speed: 6.9ms preprocess, 281.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.4ms\n",
      "Speed: 6.5ms preprocess, 250.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 273.8ms\n",
      "Speed: 7.0ms preprocess, 273.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.9ms\n",
      "Speed: 7.4ms preprocess, 262.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 297.7ms\n",
      "Speed: 7.1ms preprocess, 297.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.8ms\n",
      "Speed: 6.5ms preprocess, 260.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.8ms\n",
      "Speed: 7.8ms preprocess, 291.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.7ms\n",
      "Speed: 7.2ms preprocess, 256.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.5ms\n",
      "Speed: 6.5ms preprocess, 279.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 257.0ms\n",
      "Speed: 6.8ms preprocess, 257.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.9ms\n",
      "Speed: 6.9ms preprocess, 303.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 239.1ms\n",
      "Speed: 4.8ms preprocess, 239.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.1ms\n",
      "Speed: 7.1ms preprocess, 263.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 243.9ms\n",
      "Speed: 7.0ms preprocess, 243.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.9ms\n",
      "Speed: 15.8ms preprocess, 331.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.4ms\n",
      "Speed: 7.4ms preprocess, 255.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 293.0ms\n",
      "Speed: 6.3ms preprocess, 293.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.7ms\n",
      "Speed: 6.6ms preprocess, 248.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.4ms\n",
      "Speed: 7.3ms preprocess, 258.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.6ms\n",
      "Speed: 9.2ms preprocess, 255.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.5ms\n",
      "Speed: 7.7ms preprocess, 271.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 272.1ms\n",
      "Speed: 7.8ms preprocess, 272.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 287.3ms\n",
      "Speed: 6.9ms preprocess, 287.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.9ms\n",
      "Speed: 7.1ms preprocess, 286.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 292.1ms\n",
      "Speed: 7.3ms preprocess, 292.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.8ms\n",
      "Speed: 8.5ms preprocess, 283.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.7ms\n",
      "Speed: 7.3ms preprocess, 318.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 269.9ms\n",
      "Speed: 7.7ms preprocess, 269.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.6ms\n",
      "Speed: 9.0ms preprocess, 291.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 255.4ms\n",
      "Speed: 8.0ms preprocess, 255.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.3ms\n",
      "Speed: 6.5ms preprocess, 289.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 253.6ms\n",
      "Speed: 9.4ms preprocess, 253.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.7ms\n",
      "Speed: 6.3ms preprocess, 236.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 231.8ms\n",
      "Speed: 5.4ms preprocess, 231.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.5ms\n",
      "Speed: 9.5ms preprocess, 336.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 285.1ms\n",
      "Speed: 7.6ms preprocess, 285.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.4ms\n",
      "Speed: 8.4ms preprocess, 318.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 304.2ms\n",
      "Speed: 7.3ms preprocess, 304.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.3ms\n",
      "Speed: 6.0ms preprocess, 315.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 293.1ms\n",
      "Speed: 7.5ms preprocess, 293.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.0ms\n",
      "Speed: 7.8ms preprocess, 321.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.0ms\n",
      "Speed: 7.5ms preprocess, 289.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 426.9ms\n",
      "Speed: 8.6ms preprocess, 426.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 300.6ms\n",
      "Speed: 8.2ms preprocess, 300.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.8ms\n",
      "Speed: 7.5ms preprocess, 324.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 277.9ms\n",
      "Speed: 7.1ms preprocess, 277.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.6ms\n",
      "Speed: 9.0ms preprocess, 302.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.2ms\n",
      "Speed: 7.3ms preprocess, 278.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 304.0ms\n",
      "Speed: 8.0ms preprocess, 304.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.5ms\n",
      "Speed: 7.2ms preprocess, 256.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.1ms\n",
      "Speed: 8.0ms preprocess, 310.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 235.9ms\n",
      "Speed: 7.0ms preprocess, 235.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 272.3ms\n",
      "Speed: 7.6ms preprocess, 272.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 240.8ms\n",
      "Speed: 6.9ms preprocess, 240.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.9ms\n",
      "Speed: 11.8ms preprocess, 331.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 258.5ms\n",
      "Speed: 5.6ms preprocess, 258.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 294.4ms\n",
      "Speed: 7.0ms preprocess, 294.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.3ms\n",
      "Speed: 7.0ms preprocess, 277.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 286.3ms\n",
      "Speed: 7.4ms preprocess, 286.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 293.8ms\n",
      "Speed: 12.8ms preprocess, 293.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 292.3ms\n",
      "Speed: 7.6ms preprocess, 292.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 261.2ms\n",
      "Speed: 6.6ms preprocess, 261.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.2ms\n",
      "Speed: 7.4ms preprocess, 309.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.1ms\n",
      "Speed: 7.4ms preprocess, 277.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.9ms\n",
      "Speed: 4.3ms preprocess, 229.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.9ms\n",
      "Speed: 9.2ms preprocess, 231.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.1ms\n",
      "Speed: 7.0ms preprocess, 248.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 214.6ms\n",
      "Speed: 6.5ms preprocess, 214.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 243.8ms\n",
      "Speed: 6.2ms preprocess, 243.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 248.0ms\n",
      "Speed: 6.6ms preprocess, 248.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.4ms\n",
      "Speed: 8.1ms preprocess, 300.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 221.8ms\n",
      "Speed: 6.4ms preprocess, 221.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.3ms\n",
      "Speed: 7.9ms preprocess, 314.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.0ms\n",
      "Speed: 7.5ms preprocess, 274.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 293.4ms\n",
      "Speed: 6.8ms preprocess, 293.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 283.4ms\n",
      "Speed: 7.4ms preprocess, 283.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.2ms\n",
      "Speed: 9.2ms preprocess, 326.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 292.1ms\n",
      "Speed: 8.5ms preprocess, 292.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.9ms\n",
      "Speed: 7.0ms preprocess, 321.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 273.7ms\n",
      "Speed: 7.1ms preprocess, 273.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.9ms\n",
      "Speed: 7.3ms preprocess, 325.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 318.6ms\n",
      "Speed: 7.9ms preprocess, 318.6ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 357.4ms\n",
      "Speed: 8.0ms preprocess, 357.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 341.8ms\n",
      "Speed: 7.9ms preprocess, 341.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 346.3ms\n",
      "Speed: 8.6ms preprocess, 346.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 275.6ms\n",
      "Speed: 7.4ms preprocess, 275.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.1ms\n",
      "Speed: 7.3ms preprocess, 317.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 293.8ms\n",
      "Speed: 7.2ms preprocess, 293.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 306.8ms\n",
      "Speed: 7.2ms preprocess, 306.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 272.7ms\n",
      "Speed: 6.7ms preprocess, 272.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.9ms\n",
      "Speed: 7.4ms preprocess, 324.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 284.3ms\n",
      "Speed: 6.4ms preprocess, 284.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.0ms\n",
      "Speed: 7.6ms preprocess, 320.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 287.4ms\n",
      "Speed: 8.4ms preprocess, 287.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 327.9ms\n",
      "Speed: 10.8ms preprocess, 327.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 296.4ms\n",
      "Speed: 8.4ms preprocess, 296.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 428.5ms\n",
      "Speed: 7.8ms preprocess, 428.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.2ms\n",
      "Speed: 7.4ms preprocess, 299.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 332.1ms\n",
      "Speed: 10.3ms preprocess, 332.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 fire hydrant, 294.7ms\n",
      "Speed: 7.7ms preprocess, 294.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 287.9ms\n",
      "Speed: 7.7ms preprocess, 287.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.0ms\n",
      "Speed: 6.9ms preprocess, 256.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 292.5ms\n",
      "Speed: 7.4ms preprocess, 292.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 274.7ms\n",
      "Speed: 7.0ms preprocess, 274.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 7.3ms preprocess, 318.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.0ms\n",
      "Speed: 7.0ms preprocess, 258.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.0ms\n",
      "Speed: 7.5ms preprocess, 310.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 276.2ms\n",
      "Speed: 8.1ms preprocess, 276.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.4ms\n",
      "Speed: 7.8ms preprocess, 308.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 284.8ms\n",
      "Speed: 7.3ms preprocess, 284.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.6ms\n",
      "Speed: 7.9ms preprocess, 310.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.2ms\n",
      "Speed: 8.6ms preprocess, 277.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.4ms\n",
      "Speed: 8.1ms preprocess, 299.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 276.0ms\n",
      "Speed: 6.6ms preprocess, 276.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.7ms\n",
      "Speed: 7.4ms preprocess, 307.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 skateboard, 261.2ms\n",
      "Speed: 6.8ms preprocess, 261.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.0ms\n",
      "Speed: 7.2ms preprocess, 295.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 294.3ms\n",
      "Speed: 7.7ms preprocess, 294.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.1ms\n",
      "Speed: 6.7ms preprocess, 298.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 269.9ms\n",
      "Speed: 8.5ms preprocess, 269.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.3ms\n",
      "Speed: 8.3ms preprocess, 290.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 279.4ms\n",
      "Speed: 7.2ms preprocess, 279.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.2ms\n",
      "Speed: 6.6ms preprocess, 300.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 281.3ms\n",
      "Speed: 7.8ms preprocess, 281.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 352.0ms\n",
      "Speed: 8.2ms preprocess, 352.0ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 283.5ms\n",
      "Speed: 8.2ms preprocess, 283.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.9ms\n",
      "Speed: 7.9ms preprocess, 315.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 279.1ms\n",
      "Speed: 7.9ms preprocess, 279.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.1ms\n",
      "Speed: 6.9ms preprocess, 303.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 300.9ms\n",
      "Speed: 7.0ms preprocess, 300.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.8ms\n",
      "Speed: 7.0ms preprocess, 302.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 sports balls, 269.1ms\n",
      "Speed: 6.9ms preprocess, 269.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 304.7ms\n",
      "Speed: 6.6ms preprocess, 304.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 275.0ms\n",
      "Speed: 6.7ms preprocess, 275.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 297.7ms\n",
      "Speed: 7.9ms preprocess, 297.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 280.2ms\n",
      "Speed: 7.4ms preprocess, 280.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.3ms\n",
      "Speed: 6.7ms preprocess, 310.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 271.8ms\n",
      "Speed: 7.0ms preprocess, 271.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.7ms\n",
      "Speed: 7.5ms preprocess, 363.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 287.7ms\n",
      "Speed: 6.8ms preprocess, 287.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 297.5ms\n",
      "Speed: 7.4ms preprocess, 297.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 270.0ms\n",
      "Speed: 7.8ms preprocess, 270.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.0ms\n",
      "Speed: 7.0ms preprocess, 290.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.3ms\n",
      "Speed: 7.5ms preprocess, 277.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.1ms\n",
      "Speed: 7.7ms preprocess, 336.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 295.4ms\n",
      "Speed: 7.7ms preprocess, 295.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 297.9ms\n",
      "Speed: 7.7ms preprocess, 297.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 288.3ms\n",
      "Speed: 6.3ms preprocess, 288.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.1ms\n",
      "Speed: 7.9ms preprocess, 298.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 270.7ms\n",
      "Speed: 7.8ms preprocess, 270.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 427.5ms\n",
      "Speed: 7.3ms preprocess, 427.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 306.3ms\n",
      "Speed: 7.2ms preprocess, 306.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 348.3ms\n",
      "Speed: 7.2ms preprocess, 348.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 295.6ms\n",
      "Speed: 7.0ms preprocess, 295.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.1ms\n",
      "Speed: 6.9ms preprocess, 310.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 216.0ms\n",
      "Speed: 6.6ms preprocess, 216.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.5ms\n",
      "Speed: 7.6ms preprocess, 301.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.3ms\n",
      "Speed: 7.4ms preprocess, 279.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.0ms\n",
      "Speed: 9.9ms preprocess, 313.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 285.2ms\n",
      "Speed: 7.5ms preprocess, 285.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.2ms\n",
      "Speed: 7.2ms preprocess, 298.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.5ms\n",
      "Speed: 6.9ms preprocess, 277.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.9ms\n",
      "Speed: 7.6ms preprocess, 316.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 296.3ms\n",
      "Speed: 7.1ms preprocess, 296.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.8ms\n",
      "Speed: 8.2ms preprocess, 290.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 271.6ms\n",
      "Speed: 6.0ms preprocess, 271.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.4ms\n",
      "Speed: 7.8ms preprocess, 310.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 skateboards, 286.2ms\n",
      "Speed: 6.4ms preprocess, 286.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.2ms\n",
      "Speed: 8.9ms preprocess, 314.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 skateboards, 274.2ms\n",
      "Speed: 7.8ms preprocess, 274.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.4ms\n",
      "Speed: 7.5ms preprocess, 308.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 278.4ms\n",
      "Speed: 7.0ms preprocess, 278.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.5ms\n",
      "Speed: 8.2ms preprocess, 318.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 304.5ms\n",
      "Speed: 8.1ms preprocess, 304.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 294.5ms\n",
      "Speed: 7.7ms preprocess, 294.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.4ms\n",
      "Speed: 5.5ms preprocess, 275.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.4ms\n",
      "Speed: 5.5ms preprocess, 308.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 304.3ms\n",
      "Speed: 8.3ms preprocess, 304.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.8ms\n",
      "Speed: 6.8ms preprocess, 301.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 281.7ms\n",
      "Speed: 6.0ms preprocess, 281.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.3ms\n",
      "Speed: 7.7ms preprocess, 308.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 303.1ms\n",
      "Speed: 8.1ms preprocess, 303.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.0ms\n",
      "Speed: 6.4ms preprocess, 302.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.9ms\n",
      "Speed: 7.2ms preprocess, 260.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.4ms\n",
      "Speed: 7.6ms preprocess, 310.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.7ms\n",
      "Speed: 7.9ms preprocess, 279.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.0ms\n",
      "Speed: 7.6ms preprocess, 309.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.9ms\n",
      "Speed: 7.8ms preprocess, 289.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.8ms\n",
      "Speed: 7.6ms preprocess, 321.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.4ms\n",
      "Speed: 6.8ms preprocess, 264.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.6ms\n",
      "Speed: 6.7ms preprocess, 321.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.3ms\n",
      "Speed: 7.9ms preprocess, 295.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.8ms\n",
      "Speed: 7.7ms preprocess, 322.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.1ms\n",
      "Speed: 7.4ms preprocess, 266.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.5ms\n",
      "Speed: 6.8ms preprocess, 319.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 288.2ms\n",
      "Speed: 8.6ms preprocess, 288.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.3ms\n",
      "Speed: 7.3ms preprocess, 321.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.3ms\n",
      "Speed: 7.3ms preprocess, 298.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.4ms\n",
      "Speed: 8.1ms preprocess, 311.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 281.4ms\n",
      "Speed: 6.5ms preprocess, 281.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.7ms\n",
      "Speed: 9.2ms preprocess, 312.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.3ms\n",
      "Speed: 7.2ms preprocess, 289.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.6ms\n",
      "Speed: 8.8ms preprocess, 326.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 291.3ms\n",
      "Speed: 7.4ms preprocess, 291.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.5ms\n",
      "Speed: 8.6ms preprocess, 314.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 382.8ms\n",
      "Speed: 20.3ms preprocess, 382.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.6ms\n",
      "Speed: 8.3ms preprocess, 314.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 281.8ms\n",
      "Speed: 8.6ms preprocess, 281.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.2ms\n",
      "Speed: 5.2ms preprocess, 330.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 301.2ms\n",
      "Speed: 8.3ms preprocess, 301.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 364.7ms\n",
      "Speed: 8.1ms preprocess, 364.7ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 283.3ms\n",
      "Speed: 7.3ms preprocess, 283.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 454.0ms\n",
      "Speed: 7.7ms preprocess, 454.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.1ms\n",
      "Speed: 10.9ms preprocess, 307.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 334.7ms\n",
      "Speed: 8.1ms preprocess, 334.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.9ms\n",
      "Speed: 8.9ms preprocess, 301.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 371.9ms\n",
      "Speed: 7.0ms preprocess, 371.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 278.4ms\n",
      "Speed: 11.7ms preprocess, 278.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.1ms\n",
      "Speed: 4.8ms preprocess, 229.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 203.2ms\n",
      "Speed: 4.9ms preprocess, 203.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.8ms\n",
      "Speed: 7.2ms preprocess, 299.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.8ms\n",
      "Speed: 8.1ms preprocess, 248.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.4ms\n",
      "Speed: 6.8ms preprocess, 295.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 265.6ms\n",
      "Speed: 6.8ms preprocess, 265.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.1ms\n",
      "Speed: 7.5ms preprocess, 295.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 270.4ms\n",
      "Speed: 7.4ms preprocess, 270.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.4ms\n",
      "Speed: 6.7ms preprocess, 278.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 265.6ms\n",
      "Speed: 6.6ms preprocess, 265.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.0ms\n",
      "Speed: 7.3ms preprocess, 303.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 259.4ms\n",
      "Speed: 7.1ms preprocess, 259.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.4ms\n",
      "Speed: 7.9ms preprocess, 298.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 262.7ms\n",
      "Speed: 7.5ms preprocess, 262.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.3ms\n",
      "Speed: 7.3ms preprocess, 271.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.2ms\n",
      "Speed: 7.3ms preprocess, 253.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.7ms\n",
      "Speed: 6.8ms preprocess, 299.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 273.9ms\n",
      "Speed: 7.7ms preprocess, 273.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.4ms\n",
      "Speed: 6.8ms preprocess, 275.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 257.0ms\n",
      "Speed: 7.0ms preprocess, 257.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.7ms\n",
      "Speed: 6.8ms preprocess, 274.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 270.2ms\n",
      "Speed: 7.4ms preprocess, 270.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.9ms\n",
      "Speed: 7.3ms preprocess, 302.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.4ms\n",
      "Speed: 6.9ms preprocess, 258.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 282.6ms\n",
      "Speed: 7.1ms preprocess, 282.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.7ms\n",
      "Speed: 7.0ms preprocess, 255.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.0ms\n",
      "Speed: 7.3ms preprocess, 300.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 270.5ms\n",
      "Speed: 7.2ms preprocess, 270.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.9ms\n",
      "Speed: 7.4ms preprocess, 295.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.0ms\n",
      "Speed: 6.8ms preprocess, 275.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.2ms\n",
      "Speed: 6.7ms preprocess, 300.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.5ms\n",
      "Speed: 7.2ms preprocess, 262.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.7ms\n",
      "Speed: 7.4ms preprocess, 303.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 273.4ms\n",
      "Speed: 6.2ms preprocess, 273.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.8ms\n",
      "Speed: 6.8ms preprocess, 271.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 257.5ms\n",
      "Speed: 6.3ms preprocess, 257.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 282.9ms\n",
      "Speed: 6.2ms preprocess, 282.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.7ms\n",
      "Speed: 7.0ms preprocess, 262.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.0ms\n",
      "Speed: 7.0ms preprocess, 283.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 247.9ms\n",
      "Speed: 6.7ms preprocess, 247.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.0ms\n",
      "Speed: 6.7ms preprocess, 290.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 272.3ms\n",
      "Speed: 10.1ms preprocess, 272.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.6ms\n",
      "Speed: 7.1ms preprocess, 290.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.9ms\n",
      "Speed: 5.6ms preprocess, 245.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.8ms\n",
      "Speed: 6.6ms preprocess, 279.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.3ms\n",
      "Speed: 6.6ms preprocess, 245.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.5ms\n",
      "Speed: 8.0ms preprocess, 283.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.2ms\n",
      "Speed: 6.7ms preprocess, 253.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 296.5ms\n",
      "Speed: 7.1ms preprocess, 296.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.0ms\n",
      "Speed: 8.1ms preprocess, 262.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 272.1ms\n",
      "Speed: 6.3ms preprocess, 272.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 220.3ms\n",
      "Speed: 5.5ms preprocess, 220.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.6ms\n",
      "Speed: 7.5ms preprocess, 312.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 297.1ms\n",
      "Speed: 9.2ms preprocess, 297.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 292.3ms\n",
      "Speed: 7.3ms preprocess, 292.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.8ms\n",
      "Speed: 11.5ms preprocess, 244.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 306.3ms\n",
      "Speed: 6.2ms preprocess, 306.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.9ms\n",
      "Speed: 4.7ms preprocess, 274.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 338.2ms\n",
      "Speed: 11.3ms preprocess, 338.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 315.1ms\n",
      "Speed: 7.5ms preprocess, 315.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 394.4ms\n",
      "Speed: 7.0ms preprocess, 394.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.8ms\n",
      "Speed: 6.6ms preprocess, 295.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 321.0ms\n",
      "Speed: 7.9ms preprocess, 321.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.4ms\n",
      "Speed: 8.0ms preprocess, 291.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 322.2ms\n",
      "Speed: 6.8ms preprocess, 322.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.4ms\n",
      "Speed: 6.9ms preprocess, 252.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.5ms\n",
      "Speed: 9.6ms preprocess, 336.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 305.4ms\n",
      "Speed: 7.5ms preprocess, 305.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.8ms\n",
      "Speed: 7.5ms preprocess, 317.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 297.9ms\n",
      "Speed: 9.6ms preprocess, 297.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.0ms\n",
      "Speed: 6.7ms preprocess, 275.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 272.0ms\n",
      "Speed: 7.3ms preprocess, 272.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 343.3ms\n",
      "Speed: 9.7ms preprocess, 343.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 293.8ms\n",
      "Speed: 7.1ms preprocess, 293.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.4ms\n",
      "Speed: 7.2ms preprocess, 313.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 277.4ms\n",
      "Speed: 7.9ms preprocess, 277.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 314.5ms\n",
      "Speed: 7.1ms preprocess, 314.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 276.2ms\n",
      "Speed: 6.8ms preprocess, 276.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 327.5ms\n",
      "Speed: 8.0ms preprocess, 327.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 292.8ms\n",
      "Speed: 6.8ms preprocess, 292.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.9ms\n",
      "Speed: 7.7ms preprocess, 301.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 288.2ms\n",
      "Speed: 6.3ms preprocess, 288.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.4ms\n",
      "Speed: 6.7ms preprocess, 298.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 283.7ms\n",
      "Speed: 7.3ms preprocess, 283.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.8ms\n",
      "Speed: 7.4ms preprocess, 311.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 239.3ms\n",
      "Speed: 6.4ms preprocess, 239.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.8ms\n",
      "Speed: 7.4ms preprocess, 312.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 283.3ms\n",
      "Speed: 9.0ms preprocess, 283.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.6ms\n",
      "Speed: 7.0ms preprocess, 312.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 263.0ms\n",
      "Speed: 7.6ms preprocess, 263.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.3ms\n",
      "Speed: 6.8ms preprocess, 318.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 252.2ms\n",
      "Speed: 5.9ms preprocess, 252.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.0ms\n",
      "Speed: 7.3ms preprocess, 290.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 skateboards, 296.9ms\n",
      "Speed: 15.5ms preprocess, 296.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.3ms\n",
      "Speed: 8.2ms preprocess, 316.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 273.2ms\n",
      "Speed: 6.3ms preprocess, 273.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 285.5ms\n",
      "Speed: 10.1ms preprocess, 285.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 skateboards, 279.4ms\n",
      "Speed: 7.2ms preprocess, 279.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.0ms\n",
      "Speed: 7.5ms preprocess, 318.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 285.6ms\n",
      "Speed: 6.7ms preprocess, 285.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.9ms\n",
      "Speed: 7.8ms preprocess, 309.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 260.8ms\n",
      "Speed: 7.1ms preprocess, 260.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.0ms\n",
      "Speed: 7.9ms preprocess, 302.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 272.8ms\n",
      "Speed: 8.7ms preprocess, 272.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 290.2ms\n",
      "Speed: 7.6ms preprocess, 290.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.9ms\n",
      "Speed: 6.6ms preprocess, 255.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.9ms\n",
      "Speed: 7.9ms preprocess, 323.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.1ms\n",
      "Speed: 7.8ms preprocess, 279.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 318.0ms\n",
      "Speed: 8.6ms preprocess, 318.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 255.0ms\n",
      "Speed: 6.4ms preprocess, 255.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 274.8ms\n",
      "Speed: 6.4ms preprocess, 274.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 372.1ms\n",
      "Speed: 15.1ms preprocess, 372.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.0ms\n",
      "Speed: 4.4ms preprocess, 279.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 293.7ms\n",
      "Speed: 7.9ms preprocess, 293.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.6ms\n",
      "Speed: 10.0ms preprocess, 291.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.2ms\n",
      "Speed: 6.5ms preprocess, 234.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.1ms\n",
      "Speed: 7.0ms preprocess, 311.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.1ms\n",
      "Speed: 6.7ms preprocess, 278.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.6ms\n",
      "Speed: 7.8ms preprocess, 317.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 274.5ms\n",
      "Speed: 3.9ms preprocess, 274.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.1ms\n",
      "Speed: 7.2ms preprocess, 311.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 284.5ms\n",
      "Speed: 4.3ms preprocess, 284.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 334.0ms\n",
      "Speed: 8.7ms preprocess, 334.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.3ms\n",
      "Speed: 7.7ms preprocess, 291.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 301.9ms\n",
      "Speed: 8.2ms preprocess, 301.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.1ms\n",
      "Speed: 8.1ms preprocess, 246.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 307.4ms\n",
      "Speed: 7.6ms preprocess, 307.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 272.9ms\n",
      "Speed: 7.6ms preprocess, 272.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 305.4ms\n",
      "Speed: 6.6ms preprocess, 305.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.8ms\n",
      "Speed: 8.2ms preprocess, 275.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 331.7ms\n",
      "Speed: 8.7ms preprocess, 331.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 294.3ms\n",
      "Speed: 9.0ms preprocess, 294.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.9ms\n",
      "Speed: 7.9ms preprocess, 328.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 248.6ms\n",
      "Speed: 8.7ms preprocess, 248.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.2ms\n",
      "Speed: 6.9ms preprocess, 291.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 273.5ms\n",
      "Speed: 6.4ms preprocess, 273.5ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.7ms\n",
      "Speed: 6.8ms preprocess, 291.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 269.5ms\n",
      "Speed: 7.7ms preprocess, 269.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 359.5ms\n",
      "Speed: 9.7ms preprocess, 359.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 276.4ms\n",
      "Speed: 8.3ms preprocess, 276.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.0ms\n",
      "Speed: 8.0ms preprocess, 310.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.5ms\n",
      "Speed: 7.0ms preprocess, 256.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 312.0ms\n",
      "Speed: 8.2ms preprocess, 312.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 sports balls, 273.3ms\n",
      "Speed: 10.3ms preprocess, 273.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.3ms\n",
      "Speed: 6.9ms preprocess, 278.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 289.6ms\n",
      "Speed: 7.7ms preprocess, 289.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 302.9ms\n",
      "Speed: 6.7ms preprocess, 302.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 sports balls, 276.3ms\n",
      "Speed: 6.9ms preprocess, 276.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.2ms\n",
      "Speed: 5.7ms preprocess, 300.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 259.0ms\n",
      "Speed: 8.6ms preprocess, 259.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 308.7ms\n",
      "Speed: 7.5ms preprocess, 308.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.3ms\n",
      "Speed: 6.2ms preprocess, 271.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.7ms\n",
      "Speed: 6.5ms preprocess, 319.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 sports ball, 281.5ms\n",
      "Speed: 7.3ms preprocess, 281.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 291.5ms\n",
      "Speed: 7.9ms preprocess, 291.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.9ms\n",
      "Speed: 6.6ms preprocess, 279.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 298.9ms\n",
      "Speed: 7.7ms preprocess, 298.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 284.3ms\n",
      "Speed: 6.5ms preprocess, 284.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.8ms\n",
      "Speed: 8.3ms preprocess, 300.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 272.8ms\n",
      "Speed: 7.2ms preprocess, 272.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.7ms\n",
      "Speed: 7.0ms preprocess, 299.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.7ms\n",
      "Speed: 7.0ms preprocess, 255.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 384.2ms\n",
      "Speed: 6.8ms preprocess, 384.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 253.0ms\n",
      "Speed: 7.0ms preprocess, 253.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.4ms\n",
      "Speed: 7.1ms preprocess, 303.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 265.9ms\n",
      "Speed: 6.9ms preprocess, 265.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 303.0ms\n",
      "Speed: 7.2ms preprocess, 303.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 284.3ms\n",
      "Speed: 16.2ms preprocess, 284.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 306.7ms\n",
      "Speed: 7.5ms preprocess, 306.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 266.4ms\n",
      "Speed: 7.2ms preprocess, 266.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 333.5ms\n",
      "Speed: 7.3ms preprocess, 333.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 281.5ms\n",
      "Speed: 7.7ms preprocess, 281.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 305.7ms\n",
      "Speed: 7.7ms preprocess, 305.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 286.8ms\n",
      "Speed: 7.8ms preprocess, 286.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.3ms\n",
      "Speed: 5.7ms preprocess, 278.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 264.3ms\n",
      "Speed: 7.6ms preprocess, 264.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 297.7ms\n",
      "Speed: 6.4ms preprocess, 297.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 265.4ms\n",
      "Speed: 7.3ms preprocess, 265.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 295.9ms\n",
      "Speed: 8.0ms preprocess, 295.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 260.9ms\n",
      "Speed: 6.8ms preprocess, 260.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.5ms\n",
      "Speed: 7.2ms preprocess, 271.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 skateboards, 259.2ms\n",
      "Speed: 18.7ms preprocess, 259.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.6ms\n",
      "Speed: 7.6ms preprocess, 323.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.7ms\n",
      "Speed: 6.9ms preprocess, 254.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 305.7ms\n",
      "Speed: 6.5ms preprocess, 305.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 272.3ms\n",
      "Speed: 5.8ms preprocess, 272.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 458.8ms\n",
      "Speed: 7.3ms preprocess, 458.8ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 skateboard, 326.4ms\n",
      "Speed: 7.5ms preprocess, 326.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 430.6ms\n",
      "Speed: 7.2ms preprocess, 430.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.5ms\n",
      "Speed: 7.0ms preprocess, 309.5ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 378.5ms\n",
      "Speed: 23.5ms preprocess, 378.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 361.7ms\n",
      "Speed: 8.9ms preprocess, 361.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 355.8ms\n",
      "Speed: 9.1ms preprocess, 355.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.2ms\n",
      "Speed: 7.2ms preprocess, 309.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.6ms\n",
      "Speed: 8.2ms preprocess, 319.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.8ms\n",
      "Speed: 7.4ms preprocess, 266.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 282.2ms\n",
      "Speed: 6.6ms preprocess, 282.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.7ms\n",
      "Speed: 6.8ms preprocess, 236.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 300.3ms\n",
      "Speed: 6.3ms preprocess, 300.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 265.4ms\n",
      "Speed: 7.2ms preprocess, 265.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 280.9ms\n",
      "Speed: 5.9ms preprocess, 280.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 257.4ms\n",
      "Speed: 7.7ms preprocess, 257.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.0ms\n",
      "Speed: 7.3ms preprocess, 264.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.2ms\n",
      "Speed: 8.0ms preprocess, 241.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 275.4ms\n",
      "Speed: 6.2ms preprocess, 275.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.6ms\n",
      "Speed: 7.0ms preprocess, 261.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 271.9ms\n",
      "Speed: 7.0ms preprocess, 271.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.9ms\n",
      "Speed: 6.7ms preprocess, 246.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 294.1ms\n",
      "Speed: 6.5ms preprocess, 294.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# === Run the Function ===\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning YOLOv8 Pose + Football Detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[43myolo_pose_and_football_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpose_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetect_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m, in \u001b[0;36myolo_pose_and_football_detection\u001b[1;34m(video_path, pose_model_path, detect_model_path, output_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m pose_frame \u001b[38;5;241m=\u001b[39m pose_results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Run object detection for football (class 37 = sports ball)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m detect_results \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m detect_results\u001b[38;5;241m.\u001b[39mboxes:\n\u001b[0;32m     37\u001b[0m     cls_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(box\u001b[38;5;241m.\u001b[39mcls[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\model.py:185\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    158\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    159\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:644\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 644\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:318\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 318\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:318\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 318\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:495\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "def yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path=\"yolo_pose_football_output.avi\"):\n",
    "    pose_model = YOLO(pose_model_path)      # e.g. yolov8n-pose.pt\n",
    "    detect_model = YOLO(detect_model_path)  # e.g. yolov8n.pt (object detection)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Save output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Run pose estimation\n",
    "        pose_results = pose_model(frame)\n",
    "        pose_frame = pose_results[0].plot()\n",
    "\n",
    "        # Run object detection for football (class 37 = sports ball)\n",
    "        detect_results = detect_model(frame)[0]\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            if cls_id == 32:  # COCO class 37 = 'sports ball'\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(pose_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                cv2.putText(pose_frame, \"Football\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        # Display and save\n",
    "        out.write(pose_frame)\n",
    "        cv2.imshow(\"YOLOv8 Pose + Football Detection\", pose_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# === Initialization Section ===\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "\n",
    "pose_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n.pt\"\n",
    "\n",
    "output_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolo_pose_football_output.avi\"\n",
    "\n",
    "# === Run the Function ===\n",
    "print(\"Running YOLOv8 Pose + Football Detection...\")\n",
    "yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2304bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Running YOLOv8 Pose + Football Detection...\n",
      "\n",
      "0: 384x640 1 person, 113.0ms\n",
      "Speed: 3.1ms preprocess, 113.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 5 benchs, 3 sports balls, 1 baseball glove, 3 potted plants, 556.8ms\n",
      "Speed: 2.7ms preprocess, 556.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.0ms\n",
      "Speed: 3.1ms preprocess, 104.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 1 chair, 5 potted plants, 557.8ms\n",
      "Speed: 2.6ms preprocess, 557.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.6ms\n",
      "Speed: 3.7ms preprocess, 106.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 traffic light, 1 fire hydrant, 7 benchs, 3 sports balls, 1 baseball glove, 1 chair, 4 potted plants, 562.8ms\n",
      "Speed: 2.5ms preprocess, 562.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.9ms\n",
      "Speed: 2.9ms preprocess, 115.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 6 benchs, 3 sports balls, 1 baseball glove, 1 chair, 2 potted plants, 574.7ms\n",
      "Speed: 3.3ms preprocess, 574.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.0ms\n",
      "Speed: 3.6ms preprocess, 121.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 1 chair, 3 potted plants, 613.8ms\n",
      "Speed: 3.3ms preprocess, 613.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.8ms\n",
      "Speed: 2.7ms preprocess, 111.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 1 handbag, 3 sports balls, 1 baseball glove, 1 potted plant, 475.2ms\n",
      "Speed: 2.6ms preprocess, 475.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 2.0ms preprocess, 65.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 7 benchs, 3 sports balls, 1 baseball glove, 3 potted plants, 309.1ms\n",
      "Speed: 1.7ms preprocess, 309.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.6ms\n",
      "Speed: 1.9ms preprocess, 77.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 3 cars, 1 traffic light, 1 fire hydrant, 5 benchs, 3 sports balls, 1 baseball glove, 1 skateboard, 3 potted plants, 309.3ms\n",
      "Speed: 1.8ms preprocess, 309.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 1.7ms preprocess, 74.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 1 fire hydrant, 5 benchs, 1 handbag, 3 sports balls, 1 baseball glove, 2 potted plants, 313.5ms\n",
      "Speed: 1.7ms preprocess, 313.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 2.0ms preprocess, 59.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 3 cars, 7 benchs, 3 sports balls, 1 baseball glove, 1 chair, 1 potted plant, 306.5ms\n",
      "Speed: 1.7ms preprocess, 306.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.9ms\n",
      "Speed: 2.8ms preprocess, 106.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 7 benchs, 1 handbag, 3 sports balls, 1 baseball glove, 1 chair, 1 potted plant, 542.6ms\n",
      "Speed: 2.8ms preprocess, 542.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.8ms\n",
      "Speed: 2.5ms preprocess, 66.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 4 cars, 1 fire hydrant, 6 benchs, 1 handbag, 3 sports balls, 1 baseball glove, 3 potted plants, 313.9ms\n",
      "Speed: 1.9ms preprocess, 313.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.2ms\n",
      "Speed: 1.6ms preprocess, 81.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 6 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 3 potted plants, 327.1ms\n",
      "Speed: 1.6ms preprocess, 327.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 1.9ms preprocess, 63.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 3 cars, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 1 potted plant, 327.5ms\n",
      "Speed: 2.1ms preprocess, 327.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 2.2ms preprocess, 74.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 3 cars, 1 stop sign, 6 benchs, 3 sports balls, 1 baseball glove, 1 chair, 1 potted plant, 329.1ms\n",
      "Speed: 1.5ms preprocess, 329.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.9ms\n",
      "Speed: 4.1ms preprocess, 75.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 1 chair, 1 potted plant, 297.4ms\n",
      "Speed: 1.5ms preprocess, 297.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 3.3ms preprocess, 75.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 traffic light, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 345.1ms\n",
      "Speed: 1.5ms preprocess, 345.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 1.8ms preprocess, 67.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 stop sign, 6 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 1 potted plant, 316.6ms\n",
      "Speed: 1.5ms preprocess, 316.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 7 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 305.4ms\n",
      "Speed: 1.8ms preprocess, 305.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.4ms\n",
      "Speed: 1.8ms preprocess, 67.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 312.1ms\n",
      "Speed: 1.8ms preprocess, 312.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.8ms\n",
      "Speed: 1.6ms preprocess, 62.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 5 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 322.0ms\n",
      "Speed: 1.4ms preprocess, 322.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.9ms\n",
      "Speed: 1.9ms preprocess, 59.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 5 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 325.7ms\n",
      "Speed: 1.5ms preprocess, 325.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.4ms\n",
      "Speed: 1.8ms preprocess, 69.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 6 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 320.6ms\n",
      "Speed: 1.5ms preprocess, 320.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.7ms\n",
      "Speed: 1.7ms preprocess, 56.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 fire hydrant, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 320.0ms\n",
      "Speed: 1.4ms preprocess, 320.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.8ms\n",
      "Speed: 1.9ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 fire hydrant, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 305.3ms\n",
      "Speed: 1.5ms preprocess, 305.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.1ms\n",
      "Speed: 1.7ms preprocess, 61.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 fire hydrant, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 284.4ms\n",
      "Speed: 1.5ms preprocess, 284.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 2.0ms preprocess, 59.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 5 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 3 potted plants, 279.9ms\n",
      "Speed: 1.6ms preprocess, 279.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.3ms\n",
      "Speed: 1.8ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 1 stop sign, 6 benchs, 4 sports balls, 1 baseball glove, 2 potted plants, 318.2ms\n",
      "Speed: 1.7ms preprocess, 318.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.4ms\n",
      "Speed: 1.6ms preprocess, 68.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 stop sign, 5 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 345.1ms\n",
      "Speed: 1.5ms preprocess, 345.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.2ms\n",
      "Speed: 1.8ms preprocess, 63.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 5 benchs, 4 sports balls, 1 baseball glove, 310.4ms\n",
      "Speed: 1.5ms preprocess, 310.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.9ms\n",
      "Speed: 1.9ms preprocess, 57.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 traffic light, 1 stop sign, 5 benchs, 4 sports balls, 1 baseball glove, 305.4ms\n",
      "Speed: 1.5ms preprocess, 305.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.1ms\n",
      "Speed: 1.8ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 2 traffic lights, 1 stop sign, 6 benchs, 4 sports balls, 1 baseball glove, 2 potted plants, 305.0ms\n",
      "Speed: 1.4ms preprocess, 305.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.9ms\n",
      "Speed: 1.9ms preprocess, 69.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 stop sign, 6 benchs, 4 sports balls, 1 baseball glove, 306.7ms\n",
      "Speed: 1.7ms preprocess, 306.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.4ms\n",
      "Speed: 1.7ms preprocess, 60.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 6 benchs, 4 sports balls, 1 baseball glove, 4 potted plants, 292.0ms\n",
      "Speed: 1.5ms preprocess, 292.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.2ms\n",
      "Speed: 1.7ms preprocess, 60.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 6 cars, 1 traffic light, 1 stop sign, 6 benchs, 4 sports balls, 1 baseball glove, 4 potted plants, 298.0ms\n",
      "Speed: 1.5ms preprocess, 298.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.8ms\n",
      "Speed: 2.0ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 5 benchs, 4 sports balls, 1 baseball glove, 6 potted plants, 290.8ms\n",
      "Speed: 1.5ms preprocess, 290.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.7ms\n",
      "Speed: 1.7ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 3 potted plants, 296.9ms\n",
      "Speed: 1.4ms preprocess, 296.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.6ms\n",
      "Speed: 3.1ms preprocess, 75.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 4 benchs, 4 sports balls, 1 baseball glove, 2 potted plants, 321.0ms\n",
      "Speed: 1.5ms preprocess, 321.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.8ms\n",
      "Speed: 1.7ms preprocess, 59.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 7 cars, 1 fire hydrant, 4 benchs, 4 sports balls, 1 baseball glove, 3 potted plants, 292.4ms\n",
      "Speed: 1.5ms preprocess, 292.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 55.3ms\n",
      "Speed: 1.7ms preprocess, 55.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 7 cars, 1 fire hydrant, 5 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 322.0ms\n",
      "Speed: 1.5ms preprocess, 322.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.9ms\n",
      "Speed: 3.1ms preprocess, 58.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 290.7ms\n",
      "Speed: 1.6ms preprocess, 290.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 1.5ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 342.6ms\n",
      "Speed: 1.4ms preprocess, 342.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 340.4ms\n",
      "Speed: 1.9ms preprocess, 340.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.1ms\n",
      "Speed: 1.7ms preprocess, 75.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 300.5ms\n",
      "Speed: 1.5ms preprocess, 300.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.8ms\n",
      "Speed: 2.2ms preprocess, 71.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 fire hydrant, 7 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 332.3ms\n",
      "Speed: 1.4ms preprocess, 332.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.4ms\n",
      "Speed: 1.8ms preprocess, 77.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 330.9ms\n",
      "Speed: 1.5ms preprocess, 330.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.5ms\n",
      "Speed: 1.6ms preprocess, 69.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 2 traffic lights, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 322.8ms\n",
      "Speed: 1.6ms preprocess, 322.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 2.0ms preprocess, 64.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 2 traffic lights, 5 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 322.2ms\n",
      "Speed: 1.4ms preprocess, 322.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.7ms\n",
      "Speed: 1.7ms preprocess, 63.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 bicycles, 7 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 315.9ms\n",
      "Speed: 1.8ms preprocess, 315.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.9ms\n",
      "Speed: 1.9ms preprocess, 67.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 5 sports balls, 1 baseball glove, 3 potted plants, 329.1ms\n",
      "Speed: 1.5ms preprocess, 329.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.1ms preprocess, 65.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 fire hydrant, 6 benchs, 5 sports balls, 1 baseball glove, 4 potted plants, 332.8ms\n",
      "Speed: 1.8ms preprocess, 332.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 1.9ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 5 sports balls, 1 baseball glove, 2 potted plants, 319.9ms\n",
      "Speed: 1.5ms preprocess, 319.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.7ms\n",
      "Speed: 1.4ms preprocess, 109.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 5 sports balls, 1 baseball glove, 5 potted plants, 567.4ms\n",
      "Speed: 2.8ms preprocess, 567.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 132.0ms\n",
      "Speed: 3.7ms preprocess, 132.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 6 benchs, 4 sports balls, 1 baseball glove, 585.3ms\n",
      "Speed: 4.0ms preprocess, 585.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 137.1ms\n",
      "Speed: 2.8ms preprocess, 137.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 2 traffic lights, 6 benchs, 1 frisbee, 3 sports balls, 1 baseball glove, 647.3ms\n",
      "Speed: 2.9ms preprocess, 647.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.8ms\n",
      "Speed: 3.4ms preprocess, 124.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 bicycles, 5 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 631.2ms\n",
      "Speed: 2.7ms preprocess, 631.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.5ms\n",
      "Speed: 2.9ms preprocess, 108.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 bicycles, 5 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 608.7ms\n",
      "Speed: 2.5ms preprocess, 608.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.0ms\n",
      "Speed: 4.4ms preprocess, 95.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 3 traffic lights, 6 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 604.3ms\n",
      "Speed: 3.5ms preprocess, 604.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.7ms\n",
      "Speed: 2.5ms preprocess, 99.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 4 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 2 skateboards, 578.2ms\n",
      "Speed: 4.4ms preprocess, 578.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.3ms\n",
      "Speed: 2.8ms preprocess, 107.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 4 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 2 skateboards, 551.0ms\n",
      "Speed: 2.6ms preprocess, 551.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.7ms\n",
      "Speed: 4.0ms preprocess, 122.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 bicycles, 3 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 565.9ms\n",
      "Speed: 2.6ms preprocess, 565.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.2ms\n",
      "Speed: 3.6ms preprocess, 106.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 2 cars, 1 traffic light, 6 benchs, 4 sports balls, 504.1ms\n",
      "Speed: 3.0ms preprocess, 504.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.2ms\n",
      "Speed: 2.4ms preprocess, 102.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 traffic light, 6 benchs, 4 sports balls, 551.6ms\n",
      "Speed: 2.3ms preprocess, 551.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 2.5ms preprocess, 99.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 537.5ms\n",
      "Speed: 2.6ms preprocess, 537.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.7ms\n",
      "Speed: 2.7ms preprocess, 120.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 1 traffic light, 7 benchs, 4 sports balls, 1 baseball glove, 528.6ms\n",
      "Speed: 3.6ms preprocess, 528.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.4ms\n",
      "Speed: 3.2ms preprocess, 117.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 3 cars, 5 benchs, 4 sports balls, 1 baseball glove, 626.6ms\n",
      "Speed: 3.2ms preprocess, 626.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.5ms\n",
      "Speed: 4.9ms preprocess, 104.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 5 benchs, 3 sports balls, 1 baseball glove, 1 tennis racket, 1 apple, 552.0ms\n",
      "Speed: 3.1ms preprocess, 552.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.0ms\n",
      "Speed: 5.0ms preprocess, 123.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 4 benchs, 1 frisbee, 3 sports balls, 2 tennis rackets, 1 apple, 583.6ms\n",
      "Speed: 3.1ms preprocess, 583.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 143.6ms\n",
      "Speed: 3.6ms preprocess, 143.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 stop sign, 4 benchs, 5 sports balls, 1 baseball glove, 565.0ms\n",
      "Speed: 2.6ms preprocess, 565.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.1ms\n",
      "Speed: 2.5ms preprocess, 121.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 traffic light, 1 stop sign, 3 benchs, 4 sports balls, 609.5ms\n",
      "Speed: 3.9ms preprocess, 609.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.2ms\n",
      "Speed: 3.0ms preprocess, 110.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 1 stop sign, 3 benchs, 6 sports balls, 615.7ms\n",
      "Speed: 3.9ms preprocess, 615.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.3ms\n",
      "Speed: 2.8ms preprocess, 130.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 stop sign, 4 benchs, 3 sports balls, 2 skateboards, 1 chair, 583.8ms\n",
      "Speed: 2.8ms preprocess, 583.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.3ms\n",
      "Speed: 3.9ms preprocess, 144.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 stop sign, 3 benchs, 3 sports balls, 3 skateboards, 2 chairs, 660.6ms\n",
      "Speed: 2.7ms preprocess, 660.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.2ms\n",
      "Speed: 3.3ms preprocess, 106.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 1 stop sign, 4 benchs, 3 sports balls, 3 skateboards, 1 chair, 648.0ms\n",
      "Speed: 2.4ms preprocess, 648.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.0ms\n",
      "Speed: 2.8ms preprocess, 120.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 4 cars, 1 traffic light, 3 stop signs, 5 benchs, 3 sports balls, 3 skateboards, 2 chairs, 595.1ms\n",
      "Speed: 3.6ms preprocess, 595.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.9ms\n",
      "Speed: 5.8ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 2 cars, 1 traffic light, 2 stop signs, 6 benchs, 3 sports balls, 3 skateboards, 2 chairs, 599.6ms\n",
      "Speed: 3.4ms preprocess, 599.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.0ms\n",
      "Speed: 4.2ms preprocess, 144.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 2 cars, 1 traffic light, 2 stop signs, 5 benchs, 4 sports balls, 1 skateboard, 600.4ms\n",
      "Speed: 3.9ms preprocess, 600.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.6ms\n",
      "Speed: 2.5ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 2 stop signs, 6 benchs, 3 sports balls, 2 baseball gloves, 3 tennis rackets, 1 potted plant, 615.3ms\n",
      "Speed: 4.3ms preprocess, 615.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 132.7ms\n",
      "Speed: 4.9ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 stop sign, 5 benchs, 4 sports balls, 1 baseball glove, 2 tennis rackets, 1 potted plant, 651.4ms\n",
      "Speed: 3.8ms preprocess, 651.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.1ms\n",
      "Speed: 2.5ms preprocess, 109.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bicycles, 6 cars, 1 traffic light, 1 stop sign, 6 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 2 chairs, 1 potted plant, 585.8ms\n",
      "Speed: 3.4ms preprocess, 585.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 183.6ms\n",
      "Speed: 3.6ms preprocess, 183.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 6 cars, 5 benchs, 4 sports balls, 1 tennis racket, 2 chairs, 3 potted plants, 567.2ms\n",
      "Speed: 3.1ms preprocess, 567.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.1ms\n",
      "Speed: 4.0ms preprocess, 128.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 traffic light, 1 stop sign, 6 benchs, 4 sports balls, 1 bottle, 1 potted plant, 703.8ms\n",
      "Speed: 3.2ms preprocess, 703.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 149.6ms\n",
      "Speed: 3.6ms preprocess, 149.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 traffic light, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 3 tennis rackets, 1 bottle, 2 potted plants, 684.8ms\n",
      "Speed: 3.1ms preprocess, 684.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.5ms\n",
      "Speed: 3.1ms preprocess, 144.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 traffic light, 1 stop sign, 5 benchs, 3 sports balls, 1 baseball glove, 1 bottle, 1 potted plant, 584.5ms\n",
      "Speed: 4.7ms preprocess, 584.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.6ms\n",
      "Speed: 6.0ms preprocess, 144.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 1 tennis racket, 1 bottle, 3 potted plants, 588.1ms\n",
      "Speed: 2.9ms preprocess, 588.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 149.9ms\n",
      "Speed: 4.5ms preprocess, 149.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 2 traffic lights, 2 stop signs, 4 benchs, 3 sports balls, 1 baseball glove, 1 tennis racket, 1 bottle, 2 chairs, 2 potted plants, 593.7ms\n",
      "Speed: 3.0ms preprocess, 593.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.7ms\n",
      "Speed: 3.3ms preprocess, 115.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 2 traffic lights, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 bottle, 2 chairs, 2 potted plants, 636.2ms\n",
      "Speed: 7.0ms preprocess, 636.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.1ms\n",
      "Speed: 4.2ms preprocess, 129.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 9 cars, 2 traffic lights, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 bottle, 2 potted plants, 587.4ms\n",
      "Speed: 3.0ms preprocess, 587.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.4ms\n",
      "Speed: 9.6ms preprocess, 134.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 7 cars, 2 traffic lights, 2 stop signs, 4 benchs, 4 sports balls, 1 baseball glove, 1 bottle, 2 potted plants, 578.1ms\n",
      "Speed: 3.4ms preprocess, 578.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 158.9ms\n",
      "Speed: 2.5ms preprocess, 158.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 10 cars, 2 traffic lights, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 2 potted plants, 583.5ms\n",
      "Speed: 2.8ms preprocess, 583.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.3ms\n",
      "Speed: 2.9ms preprocess, 113.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 2 traffic lights, 1 stop sign, 3 benchs, 3 sports balls, 1 baseball glove, 6 tennis rackets, 2 potted plants, 592.3ms\n",
      "Speed: 2.8ms preprocess, 592.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.9ms\n",
      "Speed: 2.8ms preprocess, 103.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 2 traffic lights, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 2 potted plants, 573.5ms\n",
      "Speed: 3.7ms preprocess, 573.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 180.6ms\n",
      "Speed: 4.5ms preprocess, 180.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 3 tennis rackets, 1 potted plant, 575.8ms\n",
      "Speed: 2.7ms preprocess, 575.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.6ms\n",
      "Speed: 3.0ms preprocess, 112.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 2 traffic lights, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 558.4ms\n",
      "Speed: 2.7ms preprocess, 558.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.5ms\n",
      "Speed: 2.8ms preprocess, 107.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 traffic light, 1 stop sign, 4 benchs, 2 sports balls, 1 baseball glove, 1 tennis racket, 1 potted plant, 573.6ms\n",
      "Speed: 2.8ms preprocess, 573.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.1ms\n",
      "Speed: 2.3ms preprocess, 100.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 2 traffic lights, 1 stop sign, 4 benchs, 5 sports balls, 1 baseball glove, 3 skateboards, 1 tennis racket, 2 potted plants, 487.5ms\n",
      "Speed: 2.9ms preprocess, 487.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 3 tennis rackets, 2 potted plants, 561.2ms\n",
      "Speed: 2.9ms preprocess, 561.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.9ms\n",
      "Speed: 3.5ms preprocess, 112.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 3 cars, 1 traffic light, 1 stop sign, 3 benchs, 2 sports balls, 1 baseball glove, 3 potted plants, 569.6ms\n",
      "Speed: 2.9ms preprocess, 569.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.8ms\n",
      "Speed: 3.3ms preprocess, 106.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 536.3ms\n",
      "Speed: 2.6ms preprocess, 536.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.3ms\n",
      "Speed: 2.7ms preprocess, 104.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 stop sign, 3 benchs, 1 handbag, 4 sports balls, 1 baseball glove, 1 potted plant, 553.5ms\n",
      "Speed: 2.6ms preprocess, 553.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.5ms\n",
      "Speed: 2.7ms preprocess, 104.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 stop sign, 1 bench, 2 sports balls, 1 baseball glove, 1 potted plant, 540.1ms\n",
      "Speed: 2.3ms preprocess, 540.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.4ms\n",
      "Speed: 3.1ms preprocess, 138.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 stop sign, 3 sports balls, 1 baseball glove, 2 skateboards, 5 tennis rackets, 1 potted plant, 547.5ms\n",
      "Speed: 3.2ms preprocess, 547.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.9ms\n",
      "Speed: 2.7ms preprocess, 113.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 6 cars, 1 traffic light, 1 stop sign, 1 handbag, 3 sports balls, 1 baseball glove, 2 tennis rackets, 1 potted plant, 564.8ms\n",
      "Speed: 2.3ms preprocess, 564.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.3ms\n",
      "Speed: 2.5ms preprocess, 114.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 1 traffic light, 1 stop sign, 1 handbag, 4 sports balls, 1 baseball glove, 3 skateboards, 551.2ms\n",
      "Speed: 2.8ms preprocess, 551.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.4ms\n",
      "Speed: 2.9ms preprocess, 109.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 2 traffic lights, 1 stop sign, 1 handbag, 3 sports balls, 1 baseball glove, 3 skateboards, 501.7ms\n",
      "Speed: 2.7ms preprocess, 501.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.6ms\n",
      "Speed: 2.8ms preprocess, 107.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 2 traffic lights, 2 stop signs, 1 backpack, 3 sports balls, 1 baseball glove, 2 skateboards, 516.5ms\n",
      "Speed: 2.5ms preprocess, 516.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.5ms\n",
      "Speed: 2.6ms preprocess, 94.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 7 cars, 2 traffic lights, 1 stop sign, 3 sports balls, 2 baseball gloves, 600.0ms\n",
      "Speed: 2.2ms preprocess, 600.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.4ms\n",
      "Speed: 2.8ms preprocess, 104.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 1 traffic light, 1 stop sign, 1 bench, 4 sports balls, 2 baseball gloves, 563.2ms\n",
      "Speed: 2.7ms preprocess, 563.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.2ms\n",
      "Speed: 2.8ms preprocess, 107.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 6 cars, 4 benchs, 4 sports balls, 3 baseball gloves, 560.3ms\n",
      "Speed: 2.4ms preprocess, 560.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.3ms\n",
      "Speed: 3.1ms preprocess, 121.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 2 traffic lights, 5 benchs, 5 sports balls, 2 baseball gloves, 2 tennis rackets, 543.7ms\n",
      "Speed: 2.6ms preprocess, 543.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.5ms\n",
      "Speed: 3.0ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 6 cars, 5 benchs, 5 sports balls, 1 baseball glove, 3 tennis rackets, 582.5ms\n",
      "Speed: 4.0ms preprocess, 582.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.3ms\n",
      "Speed: 3.6ms preprocess, 109.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 5 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 556.2ms\n",
      "Speed: 2.5ms preprocess, 556.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 127.1ms\n",
      "Speed: 2.7ms preprocess, 127.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 3 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 591.7ms\n",
      "Speed: 2.8ms preprocess, 591.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.3ms\n",
      "Speed: 3.0ms preprocess, 124.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 4 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 568.9ms\n",
      "Speed: 2.9ms preprocess, 568.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.8ms\n",
      "Speed: 3.2ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 6 cars, 1 traffic light, 4 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 593.0ms\n",
      "Speed: 2.6ms preprocess, 593.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.1ms\n",
      "Speed: 2.7ms preprocess, 113.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 6 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 604.5ms\n",
      "Speed: 2.4ms preprocess, 604.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.9ms\n",
      "Speed: 3.2ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 traffic light, 5 benchs, 4 sports balls, 2 baseball gloves, 1 potted plant, 589.8ms\n",
      "Speed: 4.0ms preprocess, 589.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.4ms\n",
      "Speed: 4.6ms preprocess, 105.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 traffic light, 5 benchs, 3 sports balls, 3 baseball gloves, 1 potted plant, 591.2ms\n",
      "Speed: 2.4ms preprocess, 591.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.0ms\n",
      "Speed: 2.6ms preprocess, 100.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 traffic light, 5 benchs, 4 sports balls, 1 baseball bat, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 583.8ms\n",
      "Speed: 2.5ms preprocess, 583.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.0ms\n",
      "Speed: 3.5ms preprocess, 103.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 traffic light, 5 benchs, 3 sports balls, 2 baseball gloves, 4 tennis rackets, 2 potted plants, 644.1ms\n",
      "Speed: 3.8ms preprocess, 644.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.8ms\n",
      "Speed: 2.6ms preprocess, 128.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 4 benchs, 4 sports balls, 2 baseball gloves, 3 tennis rackets, 3 potted plants, 685.7ms\n",
      "Speed: 2.9ms preprocess, 685.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 185.9ms\n",
      "Speed: 2.7ms preprocess, 185.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 4 benchs, 4 sports balls, 1 baseball glove, 3 tennis rackets, 4 potted plants, 691.6ms\n",
      "Speed: 4.9ms preprocess, 691.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 155.3ms\n",
      "Speed: 4.4ms preprocess, 155.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 traffic light, 4 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 1 tennis racket, 1 potted plant, 603.2ms\n",
      "Speed: 3.4ms preprocess, 603.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 131.2ms\n",
      "Speed: 9.5ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 4 benchs, 3 sports balls, 2 baseball gloves, 1 potted plant, 615.0ms\n",
      "Speed: 2.6ms preprocess, 615.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.2ms\n",
      "Speed: 4.3ms preprocess, 136.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 4 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 582.1ms\n",
      "Speed: 2.7ms preprocess, 582.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 146.7ms\n",
      "Speed: 2.6ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 4 benchs, 3 sports balls, 2 baseball gloves, 3 tennis rackets, 1 potted plant, 665.2ms\n",
      "Speed: 2.7ms preprocess, 665.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.4ms\n",
      "Speed: 7.3ms preprocess, 122.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 4 benchs, 3 sports balls, 2 baseball gloves, 3 tennis rackets, 1 potted plant, 604.1ms\n",
      "Speed: 3.4ms preprocess, 604.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 137.6ms\n",
      "Speed: 3.8ms preprocess, 137.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 4 benchs, 3 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 598.2ms\n",
      "Speed: 6.4ms preprocess, 598.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.3ms\n",
      "Speed: 3.3ms preprocess, 122.3ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 4 benchs, 3 sports balls, 1 baseball glove, 1 skateboard, 2 potted plants, 660.7ms\n",
      "Speed: 4.9ms preprocess, 660.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.3ms\n",
      "Speed: 2.4ms preprocess, 110.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 4 benchs, 2 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 606.7ms\n",
      "Speed: 4.7ms preprocess, 606.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.3ms\n",
      "Speed: 2.6ms preprocess, 88.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 fire hydrant, 4 benchs, 3 sports balls, 1 baseball glove, 1 potted plant, 589.0ms\n",
      "Speed: 2.6ms preprocess, 589.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 148.3ms\n",
      "Speed: 4.2ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 1 fire hydrant, 3 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 590.2ms\n",
      "Speed: 2.5ms preprocess, 590.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.3ms\n",
      "Speed: 3.1ms preprocess, 110.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 cars, 1 fire hydrant, 3 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 518.7ms\n",
      "Speed: 3.2ms preprocess, 518.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.4ms\n",
      "Speed: 2.9ms preprocess, 116.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 1 fire hydrant, 3 benchs, 3 sports balls, 1 baseball glove, 3 tennis rackets, 1 potted plant, 551.7ms\n",
      "Speed: 3.8ms preprocess, 551.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.9ms\n",
      "Speed: 2.6ms preprocess, 106.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 3 benchs, 4 sports balls, 2 baseball gloves, 1 tennis racket, 1 potted plant, 572.1ms\n",
      "Speed: 3.2ms preprocess, 572.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.3ms\n",
      "Speed: 5.9ms preprocess, 138.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 3 benchs, 4 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 576.8ms\n",
      "Speed: 3.5ms preprocess, 576.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.6ms\n",
      "Speed: 2.9ms preprocess, 115.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 3 benchs, 5 sports balls, 2 baseball gloves, 1 potted plant, 586.7ms\n",
      "Speed: 3.5ms preprocess, 586.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.7ms\n",
      "Speed: 3.2ms preprocess, 123.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 2 benchs, 4 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 559.9ms\n",
      "Speed: 2.9ms preprocess, 559.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.1ms\n",
      "Speed: 3.2ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 2 benchs, 4 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 614.6ms\n",
      "Speed: 2.8ms preprocess, 614.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.0ms\n",
      "Speed: 2.4ms preprocess, 105.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 3 benchs, 4 sports balls, 2 baseball gloves, 1 tennis racket, 590.8ms\n",
      "Speed: 2.5ms preprocess, 590.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.7ms\n",
      "Speed: 2.5ms preprocess, 124.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 4 cars, 1 stop sign, 3 benchs, 4 sports balls, 2 baseball gloves, 543.5ms\n",
      "Speed: 2.7ms preprocess, 543.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.2ms\n",
      "Speed: 4.0ms preprocess, 136.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 5 cars, 1 stop sign, 3 benchs, 3 sports balls, 2 baseball gloves, 2 tennis rackets, 574.7ms\n",
      "Speed: 2.8ms preprocess, 574.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.4ms\n",
      "Speed: 2.9ms preprocess, 117.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 traffic light, 1 stop sign, 3 benchs, 3 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 571.4ms\n",
      "Speed: 2.8ms preprocess, 571.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.2ms\n",
      "Speed: 2.6ms preprocess, 125.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 traffic light, 1 stop sign, 2 benchs, 3 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 629.1ms\n",
      "Speed: 3.6ms preprocess, 629.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 119.1ms\n",
      "Speed: 6.6ms preprocess, 119.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cars, 1 traffic light, 1 stop sign, 2 benchs, 5 sports balls, 2 baseball gloves, 1 tennis racket, 2 potted plants, 584.1ms\n",
      "Speed: 2.7ms preprocess, 584.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.3ms\n",
      "Speed: 2.7ms preprocess, 115.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 2 benchs, 3 sports balls, 2 baseball gloves, 2 tennis rackets, 1 potted plant, 541.2ms\n",
      "Speed: 3.5ms preprocess, 541.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.2ms\n",
      "Speed: 2.5ms preprocess, 116.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 3 fire hydrants, 2 benchs, 3 sports balls, 1 baseball glove, 2 tennis rackets, 1 potted plant, 647.9ms\n",
      "Speed: 3.6ms preprocess, 647.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 137.0ms\n",
      "Speed: 3.1ms preprocess, 137.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 traffic light, 2 fire hydrants, 1 stop sign, 2 benchs, 1 frisbee, 3 sports balls, 1 baseball glove, 1 skateboard, 1 potted plant, 616.8ms\n",
      "Speed: 3.1ms preprocess, 616.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.9ms\n",
      "Speed: 2.6ms preprocess, 125.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 4 cars, 1 fire hydrant, 3 benchs, 3 sports balls, 1 baseball glove, 3 tennis rackets, 1 potted plant, 644.6ms\n",
      "Speed: 3.0ms preprocess, 644.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.2ms\n",
      "Speed: 3.9ms preprocess, 129.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 4 cars, 3 benchs, 3 sports balls, 1 baseball glove, 4 tennis rackets, 1 potted plant, 630.6ms\n",
      "Speed: 5.3ms preprocess, 630.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.8ms\n",
      "Speed: 3.4ms preprocess, 134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 fire hydrant, 3 benchs, 3 sports balls, 1 baseball glove, 1 skateboard, 1 tennis racket, 1 potted plant, 591.6ms\n",
      "Speed: 3.0ms preprocess, 591.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.9ms\n",
      "Speed: 3.0ms preprocess, 103.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 2 fire hydrants, 3 benchs, 5 sports balls, 3 baseball gloves, 2 tennis rackets, 650.1ms\n",
      "Speed: 4.5ms preprocess, 650.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 156.7ms\n",
      "Speed: 5.2ms preprocess, 156.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 fire hydrant, 3 benchs, 5 sports balls, 2 baseball gloves, 1 tennis racket, 1 potted plant, 606.4ms\n",
      "Speed: 2.7ms preprocess, 606.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.6ms\n",
      "Speed: 3.2ms preprocess, 123.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 fire hydrant, 3 benchs, 4 sports balls, 1 baseball glove, 624.8ms\n",
      "Speed: 3.6ms preprocess, 624.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.4ms\n",
      "Speed: 2.5ms preprocess, 129.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 3 benchs, 3 sports balls, 3 baseball gloves, 586.1ms\n",
      "Speed: 6.5ms preprocess, 586.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.3ms\n",
      "Speed: 3.5ms preprocess, 108.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 1 stop sign, 4 benchs, 3 sports balls, 2 baseball gloves, 1 potted plant, 593.4ms\n",
      "Speed: 3.1ms preprocess, 593.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 147.4ms\n",
      "Speed: 3.0ms preprocess, 147.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 709.2ms\n",
      "Speed: 3.0ms preprocess, 709.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.8ms\n",
      "Speed: 3.5ms preprocess, 126.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 5 cars, 2 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 598.5ms\n",
      "Speed: 2.9ms preprocess, 598.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.9ms\n",
      "Speed: 3.1ms preprocess, 103.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 4 benchs, 2 sports balls, 1 baseball glove, 3 skateboards, 593.8ms\n",
      "Speed: 3.4ms preprocess, 593.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.8ms\n",
      "Speed: 2.6ms preprocess, 103.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 3 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 584.3ms\n",
      "Speed: 5.6ms preprocess, 584.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 147.6ms\n",
      "Speed: 4.3ms preprocess, 147.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 2 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 616.9ms\n",
      "Speed: 2.7ms preprocess, 616.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 165.5ms\n",
      "Speed: 3.9ms preprocess, 165.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 2 benchs, 2 sports balls, 2 baseball gloves, 691.6ms\n",
      "Speed: 4.3ms preprocess, 691.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 133.4ms\n",
      "Speed: 4.2ms preprocess, 133.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball glove, 1 skateboard, 602.0ms\n",
      "Speed: 3.9ms preprocess, 602.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.7ms\n",
      "Speed: 4.5ms preprocess, 106.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball glove, 580.5ms\n",
      "Speed: 3.4ms preprocess, 580.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.8ms\n",
      "Speed: 3.6ms preprocess, 107.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 2 potted plants, 578.0ms\n",
      "Speed: 2.6ms preprocess, 578.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.3ms\n",
      "Speed: 3.6ms preprocess, 129.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball glove, 2 tennis rackets, 1 potted plant, 572.4ms\n",
      "Speed: 4.1ms preprocess, 572.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.5ms\n",
      "Speed: 2.9ms preprocess, 138.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 stop sign, 3 benchs, 4 sports balls, 3 baseball bats, 3 baseball gloves, 617.5ms\n",
      "Speed: 6.2ms preprocess, 617.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 131.5ms\n",
      "Speed: 2.9ms preprocess, 131.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 1 stop sign, 2 benchs, 3 sports balls, 3 baseball bats, 1 baseball glove, 548.2ms\n",
      "Speed: 2.5ms preprocess, 548.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.0ms\n",
      "Speed: 2.9ms preprocess, 113.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 stop sign, 3 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 571.0ms\n",
      "Speed: 4.1ms preprocess, 571.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.9ms\n",
      "Speed: 3.4ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball bat, 2 baseball gloves, 1 tennis racket, 567.3ms\n",
      "Speed: 3.0ms preprocess, 567.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.6ms\n",
      "Speed: 3.3ms preprocess, 129.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 stop sign, 3 benchs, 3 sports balls, 2 baseball bats, 3 baseball gloves, 1 tennis racket, 558.7ms\n",
      "Speed: 2.7ms preprocess, 558.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 160.1ms\n",
      "Speed: 2.8ms preprocess, 160.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 7 cars, 1 stop sign, 3 benchs, 3 sports balls, 2 baseball bats, 2 baseball gloves, 6 tennis rackets, 592.9ms\n",
      "Speed: 3.0ms preprocess, 592.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 145.3ms\n",
      "Speed: 3.2ms preprocess, 145.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 1 stop sign, 3 benchs, 2 backpacks, 3 sports balls, 1 baseball bat, 1 baseball glove, 2 tennis rackets, 556.0ms\n",
      "Speed: 2.9ms preprocess, 556.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.0ms\n",
      "Speed: 4.1ms preprocess, 121.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 1 stop sign, 3 benchs, 3 sports balls, 1 baseball glove, 1 tennis racket, 2 potted plants, 566.2ms\n",
      "Speed: 3.4ms preprocess, 566.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.1ms\n",
      "Speed: 3.1ms preprocess, 113.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 1 traffic light, 1 stop sign, 3 benchs, 3 sports balls, 1 baseball bat, 1 baseball glove, 1 skateboard, 1 potted plant, 622.3ms\n",
      "Speed: 4.8ms preprocess, 622.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.0ms\n",
      "Speed: 2.5ms preprocess, 116.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 3 benchs, 3 sports balls, 1 baseball bat, 1 baseball glove, 2 skateboards, 1 potted plant, 614.9ms\n",
      "Speed: 4.0ms preprocess, 614.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 172.1ms\n",
      "Speed: 2.4ms preprocess, 172.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 4 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 1 potted plant, 617.2ms\n",
      "Speed: 3.7ms preprocess, 617.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.9ms\n",
      "Speed: 5.2ms preprocess, 138.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 3 benchs, 2 sports balls, 2 baseball gloves, 2 skateboards, 1 potted plant, 679.1ms\n",
      "Speed: 3.2ms preprocess, 679.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.6ms\n",
      "Speed: 3.2ms preprocess, 109.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 5 benchs, 1 handbag, 2 sports balls, 1 baseball glove, 2 skateboards, 710.5ms\n",
      "Speed: 4.3ms preprocess, 710.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.0ms\n",
      "Speed: 3.2ms preprocess, 227.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 2 benchs, 1 backpack, 1 handbag, 2 sports balls, 1 baseball glove, 5 skateboards, 617.3ms\n",
      "Speed: 3.4ms preprocess, 617.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.7ms\n",
      "Speed: 5.3ms preprocess, 115.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 3 sports balls, 1 baseball glove, 2 skateboards, 662.0ms\n",
      "Speed: 3.5ms preprocess, 662.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.4ms\n",
      "Speed: 2.5ms preprocess, 102.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 traffic light, 1 fire hydrant, 3 sports balls, 1 baseball glove, 656.3ms\n",
      "Speed: 10.6ms preprocess, 656.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.1ms\n",
      "Speed: 2.7ms preprocess, 129.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 cars, 1 fire hydrant, 3 sports balls, 1 baseball glove, 638.9ms\n",
      "Speed: 2.9ms preprocess, 638.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 157.6ms\n",
      "Speed: 2.6ms preprocess, 157.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 3 sports balls, 1 baseball glove, 631.8ms\n",
      "Speed: 6.9ms preprocess, 631.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.0ms\n",
      "Speed: 3.4ms preprocess, 144.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 handbag, 3 sports balls, 1 baseball glove, 587.3ms\n",
      "Speed: 3.3ms preprocess, 587.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.5ms\n",
      "Speed: 3.7ms preprocess, 117.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 3 sports balls, 2 baseball gloves, 706.8ms\n",
      "Speed: 3.4ms preprocess, 706.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 142.1ms\n",
      "Speed: 5.5ms preprocess, 142.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 frisbee, 4 sports balls, 2 baseball gloves, 575.6ms\n",
      "Speed: 3.3ms preprocess, 575.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.6ms\n",
      "Speed: 3.1ms preprocess, 122.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 2 frisbees, 3 sports balls, 2 baseball gloves, 578.1ms\n",
      "Speed: 4.4ms preprocess, 578.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 135.2ms\n",
      "Speed: 5.5ms preprocess, 135.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 stop sign, 2 sports balls, 2 baseball gloves, 591.9ms\n",
      "Speed: 3.7ms preprocess, 591.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.3ms\n",
      "Speed: 5.2ms preprocess, 136.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 stop sign, 3 sports balls, 1 baseball bat, 2 baseball gloves, 615.8ms\n",
      "Speed: 3.8ms preprocess, 615.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 131.3ms\n",
      "Speed: 2.8ms preprocess, 131.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 2 cars, 1 stop sign, 4 benchs, 1 sports ball, 2 baseball gloves, 3 skateboards, 1 potted plant, 642.2ms\n",
      "Speed: 2.9ms preprocess, 642.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.5ms\n",
      "Speed: 3.9ms preprocess, 124.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 2 benchs, 1 sports ball, 1 baseball glove, 7 skateboards, 664.8ms\n",
      "Speed: 4.2ms preprocess, 664.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 150.4ms\n",
      "Speed: 4.5ms preprocess, 150.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 stop sign, 2 benchs, 1 sports ball, 1 baseball glove, 5 skateboards, 589.6ms\n",
      "Speed: 3.5ms preprocess, 589.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.3ms\n",
      "Speed: 2.9ms preprocess, 125.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 car, 3 benchs, 1 sports ball, 1 baseball glove, 3 skateboards, 649.3ms\n",
      "Speed: 4.9ms preprocess, 649.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.2ms\n",
      "Speed: 6.3ms preprocess, 144.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 3 benchs, 1 sports ball, 1 baseball glove, 7 skateboards, 621.4ms\n",
      "Speed: 3.6ms preprocess, 621.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 138.7ms\n",
      "Speed: 2.8ms preprocess, 138.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 3 benchs, 1 sports ball, 2 baseball gloves, 2 skateboards, 685.7ms\n",
      "Speed: 3.0ms preprocess, 685.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 142.3ms\n",
      "Speed: 4.2ms preprocess, 142.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 traffic light, 2 benchs, 3 sports balls, 1 baseball glove, 3 skateboards, 618.6ms\n",
      "Speed: 2.9ms preprocess, 618.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.9ms\n",
      "Speed: 2.5ms preprocess, 125.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 2 benchs, 3 sports balls, 1 baseball glove, 3 skateboards, 722.2ms\n",
      "Speed: 3.9ms preprocess, 722.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.6ms\n",
      "Speed: 2.7ms preprocess, 128.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 4 benchs, 2 sports balls, 2 baseball gloves, 2 skateboards, 666.0ms\n",
      "Speed: 2.7ms preprocess, 666.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.3ms\n",
      "Speed: 2.7ms preprocess, 112.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 2 fire hydrants, 4 benchs, 2 sports balls, 1 baseball glove, 5 skateboards, 1 potted plant, 622.0ms\n",
      "Speed: 3.0ms preprocess, 622.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 135.5ms\n",
      "Speed: 5.8ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 fire hydrant, 1 stop sign, 3 benchs, 2 sports balls, 2 baseball gloves, 1 potted plant, 604.0ms\n",
      "Speed: 2.5ms preprocess, 604.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.0ms\n",
      "Speed: 2.7ms preprocess, 136.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 2 sports balls, 2 baseball gloves, 584.9ms\n",
      "Speed: 2.6ms preprocess, 584.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 132.4ms\n",
      "Speed: 2.7ms preprocess, 132.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cars, 2 fire hydrants, 1 stop sign, 3 benchs, 3 sports balls, 2 baseball gloves, 642.0ms\n",
      "Speed: 2.9ms preprocess, 642.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.5ms\n",
      "Speed: 2.9ms preprocess, 117.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 2 fire hydrants, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 590.6ms\n",
      "Speed: 3.2ms preprocess, 590.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.1ms\n",
      "Speed: 3.0ms preprocess, 126.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cars, 4 benchs, 3 sports balls, 1 baseball glove, 573.7ms\n",
      "Speed: 4.0ms preprocess, 573.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 132.9ms\n",
      "Speed: 4.3ms preprocess, 132.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 1 traffic light, 4 benchs, 4 sports balls, 2 baseball gloves, 1 potted plant, 600.6ms\n",
      "Speed: 3.3ms preprocess, 600.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.0ms\n",
      "Speed: 3.2ms preprocess, 123.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 4 benchs, 3 sports balls, 4 baseball gloves, 1 potted plant, 588.7ms\n",
      "Speed: 3.2ms preprocess, 588.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.4ms\n",
      "Speed: 2.6ms preprocess, 115.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cars, 4 benchs, 4 sports balls, 2 baseball gloves, 593.8ms\n",
      "Speed: 3.2ms preprocess, 593.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.5ms\n",
      "Speed: 2.7ms preprocess, 114.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 4 benchs, 3 sports balls, 3 baseball gloves, 3 potted plants, 654.6ms\n",
      "Speed: 3.9ms preprocess, 654.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 148.2ms\n",
      "Speed: 3.1ms preprocess, 148.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 6 cars, 2 benchs, 3 sports balls, 2 baseball gloves, 1 potted plant, 652.2ms\n",
      "Speed: 2.8ms preprocess, 652.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 146.0ms\n",
      "Speed: 4.4ms preprocess, 146.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 bench, 3 sports balls, 1 baseball glove, 6 skateboards, 2 potted plants, 697.8ms\n",
      "Speed: 2.8ms preprocess, 697.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 139.4ms\n",
      "Speed: 2.9ms preprocess, 139.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 bench, 3 sports balls, 2 baseball gloves, 2 potted plants, 667.0ms\n",
      "Speed: 3.1ms preprocess, 667.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.3ms\n",
      "Speed: 4.2ms preprocess, 130.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 3 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 3 potted plants, 787.0ms\n",
      "Speed: 2.7ms preprocess, 787.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 158.6ms\n",
      "Speed: 4.1ms preprocess, 158.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 stop sign, 3 sports balls, 2 baseball gloves, 6 skateboards, 2 potted plants, 623.9ms\n",
      "Speed: 4.9ms preprocess, 623.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.0ms\n",
      "Speed: 2.6ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 fire hydrant, 1 stop sign, 2 sports balls, 2 baseball gloves, 5 skateboards, 2 potted plants, 728.6ms\n",
      "Speed: 4.7ms preprocess, 728.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.1ms\n",
      "Speed: 5.3ms preprocess, 125.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 stop sign, 3 sports balls, 2 baseball gloves, 2 skateboards, 3 potted plants, 592.7ms\n",
      "Speed: 3.4ms preprocess, 592.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 145.4ms\n",
      "Speed: 4.1ms preprocess, 145.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 8 cars, 3 sports balls, 2 baseball gloves, 3 skateboards, 3 potted plants, 654.3ms\n",
      "Speed: 3.9ms preprocess, 654.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 146.3ms\n",
      "Speed: 2.7ms preprocess, 146.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 stop sign, 3 sports balls, 2 baseball gloves, 1 skateboard, 2 tennis rackets, 2 potted plants, 652.8ms\n",
      "Speed: 3.8ms preprocess, 652.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.5ms\n",
      "Speed: 4.3ms preprocess, 112.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 cars, 1 stop sign, 3 sports balls, 1 baseball glove, 2 potted plants, 580.9ms\n",
      "Speed: 2.6ms preprocess, 580.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.6ms\n",
      "Speed: 3.2ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 stop sign, 3 sports balls, 2 baseball gloves, 1 skateboard, 1 potted plant, 632.8ms\n",
      "Speed: 3.8ms preprocess, 632.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.7ms\n",
      "Speed: 3.2ms preprocess, 115.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 stop sign, 1 bench, 3 sports balls, 2 baseball gloves, 1 skateboard, 650.5ms\n",
      "Speed: 4.2ms preprocess, 650.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 156.6ms\n",
      "Speed: 3.8ms preprocess, 156.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 1 bench, 3 sports balls, 3 baseball gloves, 602.2ms\n",
      "Speed: 3.7ms preprocess, 602.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 133.5ms\n",
      "Speed: 2.5ms preprocess, 133.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 2 benchs, 4 sports balls, 2 baseball gloves, 773.9ms\n",
      "Speed: 3.1ms preprocess, 773.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.2ms\n",
      "Speed: 2.9ms preprocess, 124.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 3 sports balls, 2 baseball gloves, 626.3ms\n",
      "Speed: 2.9ms preprocess, 626.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 142.6ms\n",
      "Speed: 5.4ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 5 benchs, 4 sports balls, 2 baseball gloves, 1 tennis racket, 702.4ms\n",
      "Speed: 2.6ms preprocess, 702.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 145.0ms\n",
      "Speed: 3.5ms preprocess, 145.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 fire hydrant, 5 benchs, 3 sports balls, 3 baseball gloves, 1 skateboard, 592.9ms\n",
      "Speed: 5.2ms preprocess, 592.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 160.9ms\n",
      "Speed: 4.7ms preprocess, 160.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 4 benchs, 3 sports balls, 2 baseball gloves, 1 tennis racket, 706.6ms\n",
      "Speed: 3.9ms preprocess, 706.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 167.8ms\n",
      "Speed: 4.0ms preprocess, 167.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 5 benchs, 3 sports balls, 1 baseball glove, 1 tennis racket, 1 potted plant, 592.6ms\n",
      "Speed: 19.4ms preprocess, 592.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 141.0ms\n",
      "Speed: 3.8ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 1 fire hydrant, 4 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 578.8ms\n",
      "Speed: 2.4ms preprocess, 578.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 128.6ms\n",
      "Speed: 2.4ms preprocess, 128.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 fire hydrant, 4 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 611.8ms\n",
      "Speed: 4.6ms preprocess, 611.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.9ms\n",
      "Speed: 2.8ms preprocess, 121.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 1 fire hydrant, 4 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 576.7ms\n",
      "Speed: 5.0ms preprocess, 576.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 135.9ms\n",
      "Speed: 2.5ms preprocess, 135.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 fire hydrant, 4 benchs, 4 sports balls, 3 baseball bats, 3 baseball gloves, 587.0ms\n",
      "Speed: 2.7ms preprocess, 587.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 129.2ms\n",
      "Speed: 2.8ms preprocess, 129.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 fire hydrant, 3 benchs, 3 sports balls, 2 baseball bats, 4 baseball gloves, 1 skateboard, 608.3ms\n",
      "Speed: 3.0ms preprocess, 608.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.4ms\n",
      "Speed: 2.6ms preprocess, 116.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 1 fire hydrant, 1 stop sign, 2 benchs, 4 sports balls, 3 baseball bats, 3 baseball gloves, 1 potted plant, 564.0ms\n",
      "Speed: 3.4ms preprocess, 564.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.1ms\n",
      "Speed: 4.4ms preprocess, 117.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 fire hydrant, 1 stop sign, 3 benchs, 4 sports balls, 1 baseball bat, 3 baseball gloves, 1 potted plant, 547.6ms\n",
      "Speed: 2.6ms preprocess, 547.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.7ms\n",
      "Speed: 3.1ms preprocess, 111.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 fire hydrant, 1 stop sign, 2 benchs, 3 sports balls, 2 baseball gloves, 3 skateboards, 1 potted plant, 539.3ms\n",
      "Speed: 2.7ms preprocess, 539.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.5ms\n",
      "Speed: 2.6ms preprocess, 110.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 fire hydrant, 1 stop sign, 2 benchs, 3 sports balls, 1 baseball glove, 6 skateboards, 1 potted plant, 580.0ms\n",
      "Speed: 2.8ms preprocess, 580.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.7ms\n",
      "Speed: 3.0ms preprocess, 95.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 fire hydrant, 1 stop sign, 5 benchs, 4 sports balls, 2 baseball gloves, 2 potted plants, 367.4ms\n",
      "Speed: 1.4ms preprocess, 367.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 2.4ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 fire hydrant, 1 stop sign, 5 benchs, 1 sports ball, 2 baseball gloves, 3 skateboards, 2 potted plants, 307.7ms\n",
      "Speed: 1.9ms preprocess, 307.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 1.8ms preprocess, 67.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 2 sports balls, 3 baseball gloves, 3 skateboards, 3 potted plants, 328.8ms\n",
      "Speed: 1.7ms preprocess, 328.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 2.0ms preprocess, 72.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 stop sign, 4 benchs, 1 frisbee, 2 sports balls, 2 baseball gloves, 1 skateboard, 2 potted plants, 351.8ms\n",
      "Speed: 1.9ms preprocess, 351.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 1 frisbee, 2 sports balls, 1 baseball glove, 2 skateboards, 2 potted plants, 412.3ms\n",
      "Speed: 3.3ms preprocess, 412.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.4ms\n",
      "Speed: 1.8ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 2 potted plants, 317.1ms\n",
      "Speed: 1.8ms preprocess, 317.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.8ms preprocess, 67.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 fire hydrant, 1 stop sign, 4 benchs, 3 sports balls, 2 baseball gloves, 1 skateboard, 1 tennis racket, 2 potted plants, 308.0ms\n",
      "Speed: 1.8ms preprocess, 308.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 1.6ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 stop sign, 4 benchs, 4 sports balls, 2 baseball bats, 2 baseball gloves, 3 tennis rackets, 2 potted plants, 342.7ms\n",
      "Speed: 1.7ms preprocess, 342.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 2.1ms preprocess, 60.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 stop sign, 4 benchs, 5 sports balls, 1 baseball bat, 1 baseball glove, 3 tennis rackets, 3 potted plants, 316.6ms\n",
      "Speed: 1.6ms preprocess, 316.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 1.8ms preprocess, 65.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 2 skateboards, 4 tennis rackets, 4 potted plants, 321.3ms\n",
      "Speed: 1.5ms preprocess, 321.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 1.9ms preprocess, 68.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 1 stop sign, 4 benchs, 3 sports balls, 1 baseball glove, 4 skateboards, 3 potted plants, 328.0ms\n",
      "Speed: 1.5ms preprocess, 328.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.7ms preprocess, 72.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 4 benchs, 1 frisbee, 4 sports balls, 1 baseball glove, 2 potted plants, 306.8ms\n",
      "Speed: 1.9ms preprocess, 306.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 1.9ms preprocess, 68.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 3 benchs, 3 frisbees, 3 sports balls, 1 baseball glove, 2 potted plants, 319.7ms\n",
      "Speed: 1.7ms preprocess, 319.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.4ms\n",
      "Speed: 2.1ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 5 benchs, 5 sports balls, 1 baseball glove, 2 tennis rackets, 2 potted plants, 326.9ms\n",
      "Speed: 1.8ms preprocess, 326.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 2.1ms preprocess, 62.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 2 tennis rackets, 2 potted plants, 308.1ms\n",
      "Speed: 1.7ms preprocess, 308.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 skateboard, 4 potted plants, 291.3ms\n",
      "Speed: 1.5ms preprocess, 291.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.1ms\n",
      "Speed: 2.0ms preprocess, 66.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 4 potted plants, 293.4ms\n",
      "Speed: 1.6ms preprocess, 293.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.6ms\n",
      "Speed: 1.8ms preprocess, 61.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 3 potted plants, 290.4ms\n",
      "Speed: 1.6ms preprocess, 290.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.8ms\n",
      "Speed: 1.9ms preprocess, 56.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 2 fire hydrants, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 1 tennis racket, 2 potted plants, 277.2ms\n",
      "Speed: 1.6ms preprocess, 277.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.9ms\n",
      "Speed: 1.7ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 traffic light, 2 fire hydrants, 1 stop sign, 4 benchs, 4 sports balls, 1 baseball glove, 2 tennis rackets, 3 potted plants, 294.8ms\n",
      "Speed: 1.6ms preprocess, 294.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.8ms\n",
      "Speed: 1.6ms preprocess, 53.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 4 cars, 1 traffic light, 2 fire hydrants, 4 benchs, 5 sports balls, 1 baseball glove, 2 skateboards, 1 potted plant, 311.8ms\n",
      "Speed: 1.4ms preprocess, 311.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 1.8ms preprocess, 65.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 traffic light, 2 fire hydrants, 3 benchs, 4 sports balls, 1 baseball glove, 2 skateboards, 1 potted plant, 297.2ms\n",
      "Speed: 1.6ms preprocess, 297.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.7ms\n",
      "Speed: 1.7ms preprocess, 54.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 2 fire hydrants, 1 stop sign, 3 benchs, 4 sports balls, 1 baseball glove, 2 skateboards, 1 potted plant, 308.5ms\n",
      "Speed: 1.5ms preprocess, 308.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.9ms\n",
      "Speed: 2.0ms preprocess, 52.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 5 cars, 1 fire hydrant, 1 stop sign, 1 bench, 4 sports balls, 3 baseball gloves, 1 potted plant, 284.6ms\n",
      "Speed: 1.6ms preprocess, 284.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 2.0ms preprocess, 62.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 fire hydrant, 1 stop sign, 3 benchs, 5 sports balls, 1 baseball glove, 1 tennis racket, 1 potted plant, 294.9ms\n",
      "Speed: 1.6ms preprocess, 294.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.1ms\n",
      "Speed: 1.7ms preprocess, 61.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 6 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 3 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 306.1ms\n",
      "Speed: 1.5ms preprocess, 306.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.7ms\n",
      "Speed: 1.9ms preprocess, 66.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 9 cars, 1 traffic light, 2 fire hydrants, 3 benchs, 4 sports balls, 1 baseball glove, 1 potted plant, 315.2ms\n",
      "Speed: 1.6ms preprocess, 315.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.3ms\n",
      "Speed: 1.7ms preprocess, 49.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 8 cars, 1 traffic light, 3 fire hydrants, 3 benchs, 4 sports balls, 6 tennis rackets, 1 potted plant, 300.5ms\n",
      "Speed: 1.8ms preprocess, 300.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 8 cars, 1 traffic light, 2 fire hydrants, 1 stop sign, 4 benchs, 1 handbag, 4 sports balls, 6 tennis rackets, 284.1ms\n",
      "Speed: 1.8ms preprocess, 284.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.4ms\n",
      "Speed: 2.1ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 7 cars, 1 traffic light, 2 fire hydrants, 1 stop sign, 3 benchs, 4 sports balls, 1 baseball glove, 4 tennis rackets, 1 potted plant, 319.3ms\n",
      "Speed: 1.4ms preprocess, 319.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Speed: 1.7ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 6 cars, 1 traffic light, 1 fire hydrant, 1 stop sign, 3 benchs, 1 frisbee, 4 sports balls, 1 baseball glove, 1 tennis racket, 1 potted plant, 297.6ms\n",
      "Speed: 1.5ms preprocess, 297.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 74.1ms\n",
      "Speed: 1.7ms preprocess, 74.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 6 cars, 1 traffic light, 2 fire hydrants, 5 benchs, 4 sports balls, 1 baseball glove, 2 potted plants, 288.1ms\n",
      "Speed: 1.8ms preprocess, 288.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "def yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path=\"yolo_pose_football_output_yolov9.avi\"):\n",
    "    pose_model = YOLO(pose_model_path)      # yolov8n-pose.pt\n",
    "    detect_model = YOLO(detect_model_path)  # yolov8n.pt\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"❌ Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Get original video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Output writer (original resolution)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Create display window\n",
    "    display_width, display_height = 960, 540\n",
    "    cv2.namedWindow(\"YOLOv8 Pose + Football Detection\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"YOLOv8 Pose + Football Detection\", display_width, display_height)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # Pose Estimation\n",
    "        pose_results = pose_model(annotated_frame)[0]\n",
    "        annotated_frame = pose_results.plot()\n",
    "\n",
    "        # Object Detection (class 37 = sports ball in COCO)\n",
    "        detect_results = detect_model(frame, conf=0.01)[0]\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            if cls_id == 32:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                cv2.putText(annotated_frame, \"Football\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        # Save original-sized frame\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        # Resize for display\n",
    "        resized_frame = cv2.resize(annotated_frame, (display_width, display_height))\n",
    "        cv2.imshow(\"YOLOv8 Pose + Football Detection\", resized_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# === PATH SETUP ===\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "pose_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "# detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n.pt\"\n",
    "detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov9c.pt\"\n",
    "output_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolo_pose_football_output.avi\"\n",
    "\n",
    "# === RUN ===\n",
    "print(\"🎥 Running YOLOv8 Pose + Football Detection...\")\n",
    "yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4203e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov9c.pt to 'yolov9c.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49.4M/49.4M [00:49<00:00, 1.04MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov9c.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5decbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Running YOLOv9 Pose + Football Detection...\n",
      "\n",
      "0: 384x640 1 person, 117.5ms\n",
      "Speed: 8.3ms preprocess, 117.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 381.3ms\n",
      "Speed: 1.9ms preprocess, 381.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.2ms\n",
      "Speed: 1.2ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 351.8ms\n",
      "Speed: 1.3ms preprocess, 351.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.9ms\n",
      "Speed: 1.2ms preprocess, 70.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 300.8ms\n",
      "Speed: 1.2ms preprocess, 300.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.1ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 328.2ms\n",
      "Speed: 1.4ms preprocess, 328.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 2.1ms preprocess, 78.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 301.6ms\n",
      "Speed: 1.1ms preprocess, 301.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.9ms\n",
      "Speed: 1.4ms preprocess, 70.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 4 sports balls, 291.3ms\n",
      "Speed: 1.2ms preprocess, 291.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.4ms\n",
      "Speed: 1.5ms preprocess, 72.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 301.7ms\n",
      "Speed: 1.1ms preprocess, 301.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.5ms\n",
      "Speed: 1.2ms preprocess, 70.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 289.7ms\n",
      "Speed: 1.3ms preprocess, 289.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.7ms\n",
      "Speed: 1.1ms preprocess, 68.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 312.4ms\n",
      "Speed: 1.1ms preprocess, 312.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 335.4ms\n",
      "Speed: 1.6ms preprocess, 335.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.9ms\n",
      "Speed: 1.2ms preprocess, 72.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 1 baseball glove, 392.7ms\n",
      "Speed: 1.2ms preprocess, 392.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.1ms\n",
      "Speed: 2.1ms preprocess, 109.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 1 baseball glove, 520.6ms\n",
      "Speed: 1.9ms preprocess, 520.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.2ms\n",
      "Speed: 1.8ms preprocess, 113.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 1 baseball glove, 565.2ms\n",
      "Speed: 1.7ms preprocess, 565.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.0ms\n",
      "Speed: 2.2ms preprocess, 112.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 1 baseball glove, 594.0ms\n",
      "Speed: 1.7ms preprocess, 594.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.9ms\n",
      "Speed: 2.1ms preprocess, 105.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4 sports balls, 1 baseball glove, 517.3ms\n",
      "Speed: 1.9ms preprocess, 517.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 137.5ms\n",
      "Speed: 1.9ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 105\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# === RUN ===\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎥 Running YOLOv9 Pose + Football Detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m \u001b[43myolo_pose_and_football_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpose_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetect_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 45\u001b[0m, in \u001b[0;36myolo_pose_and_football_detection\u001b[1;34m(video_path, pose_model_path, detect_model_path, output_path)\u001b[0m\n\u001b[0;32m     42\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m pose_results\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# === Object Detection ===\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m detect_results \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.03\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m detect_results\u001b[38;5;241m.\u001b[39mboxes:\n\u001b[0;32m     48\u001b[0m     cls_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(box\u001b[38;5;241m.\u001b[39mcls[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\model.py:185\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    158\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    159\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:644\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 644\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:922\u001b[0m, in \u001b[0;36mRepNCSPELAN4.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    920\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    921\u001b[0m y\u001b[38;5;241m.\u001b[39mextend((m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3])\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "\n",
    "\n",
    "def yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path=\"yolo_pose_football_output_yolov9.avi\"):\n",
    "    pose_model = YOLO(pose_model_path)      # yolov8n-pose.pt\n",
    "    detect_model = YOLO(detect_model_path)  # yolov9c.pt or similar\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"❌ Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # Video properties\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Output writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Display settings\n",
    "    display_width, display_height = 960, 540\n",
    "    cv2.namedWindow(\"YOLOv9 Pose + Football Detection\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"YOLOv9 Pose + Football Detection\", display_width, display_height)\n",
    "\n",
    "    # Tracker for red dots (simplified by assigning random IDs to red balls)\n",
    "    ball_id_counter = 0\n",
    "    red_ball_positions = {}  # frame-wise dict of red dot positions\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # === Pose Estimation ===\n",
    "        pose_results = pose_model(annotated_frame,conf=0.65)[0]\n",
    "        annotated_frame = pose_results.plot()\n",
    "\n",
    "        # === Object Detection ===\n",
    "        detect_results = detect_model(frame, conf=0.03)[0]\n",
    "\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "\n",
    "            label = \"\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            # 1. Handle Human Labeling\n",
    "            if cls_id == 0:  # 'person' in COCO\n",
    "                label = \"human\"\n",
    "                color = (255, 255, 255)\n",
    "\n",
    "            # 2. Handle Ball Detection and Label Normalization\n",
    "            elif cls_id in [32, 37]:  # 32: sports ball, 37: baseball (COCO IDs)\n",
    "                label = \"football\"\n",
    "                color = (0, 255, 255)\n",
    "\n",
    "            # 3. Handle Red Dot as Ball Tracker (Optional)\n",
    "            elif (x2 - x1) < 15 and (y2 - y1) < 15 and conf > 0.5:\n",
    "                # Consider small red dots as ball trackers\n",
    "                ball_id_counter += 1\n",
    "                label = f\"ball_{ball_id_counter}\"\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            if label != \"\":\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 1)\n",
    "\n",
    "                # Smaller label text\n",
    "                cv2.putText(annotated_frame, label, (x1, y1 - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "\n",
    "        # Save original-sized frame\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        # Resize for display\n",
    "        resized_frame = cv2.resize(annotated_frame, (display_width, display_height))\n",
    "        cv2.imshow(\"YOLOv9 Pose + Football Detection\", resized_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# === PATH SETUP ===\n",
    "# video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test.mp4\"\n",
    "pose_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov9c.pt\"\n",
    "output_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolo_pose_football_output.avi\"\n",
    "\n",
    "# === RUN ===\n",
    "print(\"🎥 Running YOLOv9 Pose + Football Detection...\")\n",
    "yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc9251b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Running YOLOv9 Pose + Football Detection...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "def yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path=\"yolo_pose_football_output.avi\"):\n",
    "    pose_model = YOLO(pose_model_path)\n",
    "    detect_model = YOLO(detect_model_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"❌ Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    display_width, display_height = 960, 540\n",
    "    cv2.namedWindow(\"YOLOv9 Pose + Football Detection\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"YOLOv9 Pose + Football Detection\", display_width, display_height)\n",
    "\n",
    "    object_id_counter = 0\n",
    "    prev_positions = {}  # id: (x, y)\n",
    "\n",
    "    def calculate_velocity(p1, p2, dt):\n",
    "        dx = p2[0] - p1[0]\n",
    "        dy = p2[1] - p1[1]\n",
    "        velocity = (dx**2 + dy**2) ** 0.5 / dt\n",
    "        return velocity\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_idx += 1\n",
    "        dt = 1 / fps if fps > 0 else 1\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # === Pose Estimation ===\n",
    "        pose_results = pose_model.predict(annotated_frame, conf=0.65, verbose=False)[0]\n",
    "        if pose_results.keypoints is not None:\n",
    "            for keypoints in pose_results.keypoints.xy:\n",
    "                for x, y in keypoints:\n",
    "                    if x > 0 and y > 0:\n",
    "                        cv2.circle(annotated_frame, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # === Object Detection ===\n",
    "        detect_results = detect_model.predict(frame, conf=0.1, verbose=False)[0]\n",
    "\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            # === FOOTBALL TRACKING ===\n",
    "            if cls_id in [32, 37]:  # sports ball or baseball (COCO)\n",
    "                assigned_id = None\n",
    "                for obj_id, (px, py) in prev_positions.items():\n",
    "                    if np.linalg.norm([cx - px, cy - py]) < 50:\n",
    "                        assigned_id = obj_id\n",
    "                        break\n",
    "                if assigned_id is None:\n",
    "                    object_id_counter += 1\n",
    "                    assigned_id = object_id_counter\n",
    "\n",
    "                velocity = 0\n",
    "                status = \"STATIONARY\"\n",
    "                if assigned_id in prev_positions:\n",
    "                    velocity = calculate_velocity(prev_positions[assigned_id], (cx, cy), dt)\n",
    "                    if velocity > 100:\n",
    "                        status = \"ACTION\"\n",
    "\n",
    "                prev_positions[assigned_id] = (cx, cy)\n",
    "\n",
    "                # Draw blue bounding box\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "\n",
    "                # Red dot on football\n",
    "                cv2.circle(annotated_frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "\n",
    "                # Label with black text\n",
    "                info_text = f\"ID {assigned_id} | {status} | V={velocity:.1f} | Conf={conf:.2f}\"\n",
    "                cv2.putText(annotated_frame, info_text, (x1, y1 - 8),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "            # === HUMAN LABELING ===\n",
    "            elif cls_id == 0:  # person\n",
    "                # Draw blue bounding box\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "                label = f\"ACTION BOX | Conf={conf:.2f}\"\n",
    "                cv2.putText(annotated_frame, label, (x1, y1 - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "\n",
    "        # Write and display\n",
    "        out.write(annotated_frame)\n",
    "        resized_frame = cv2.resize(annotated_frame, (display_width, display_height))\n",
    "        cv2.imshow(\"YOLOv9 Pose + Football Detection\", resized_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# === PATH SETUP ===\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "pose_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov8n-pose.pt\"\n",
    "detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov9c.pt\"\n",
    "output_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolo_pose_football_output_2.avi\"\n",
    "\n",
    "# === RUN ===\n",
    "print(\"🎥 Running YOLOv9 Pose + Football Detection...\")\n",
    "yolo_pose_and_football_detection(video_path, pose_model_path, detect_model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068ddadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Running MediaPipe + YOLOv9 Football Detection...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "def yolo_mediapipe_football_detection(video_path, detect_model_path, output_path=\"mediapipe_yolo_output.avi\"):\n",
    "    # === Models ===\n",
    "    detect_model = YOLO(detect_model_path)\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        print(\"❌ Error: Could not access the video file.\")\n",
    "        return\n",
    "\n",
    "    # === Video Info ===\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    dt = 1 / fps if fps > 0 else 1\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    display_width, display_height = 960, 540\n",
    "    cv2.namedWindow(\"YOLO + MediaPipe Football Detection\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"YOLO + MediaPipe Football Detection\", display_width, display_height)\n",
    "\n",
    "    object_id_counter = 0\n",
    "    prev_positions = {}  # id: (x, y)\n",
    "\n",
    "    def calculate_velocity(p1, p2, dt):\n",
    "        dx = p2[0] - p1[0]\n",
    "        dy = p2[1] - p1[1]\n",
    "        return (dx ** 2 + dy ** 2) ** 0.5 / dt\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        # === MediaPipe Pose Estimation ===\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # === YOLO Football Detection ===\n",
    "        detect_results = detect_model.predict(frame, conf=0.1, verbose=False)[0]\n",
    "\n",
    "        for box in detect_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            if cls_id in [32, 37]:  # sports ball / baseball\n",
    "                assigned_id = None\n",
    "                for obj_id, (px, py) in prev_positions.items():\n",
    "                    if np.linalg.norm([cx - px, cy - py]) < 50:\n",
    "                        assigned_id = obj_id\n",
    "                        break\n",
    "                if assigned_id is None:\n",
    "                    object_id_counter += 1\n",
    "                    assigned_id = object_id_counter\n",
    "\n",
    "                velocity = 0\n",
    "                status = \"STATIONARY\"\n",
    "                if assigned_id in prev_positions:\n",
    "                    velocity = calculate_velocity(prev_positions[assigned_id], (cx, cy), dt)\n",
    "                    if velocity > 100:\n",
    "                        status = \"ACTION\"\n",
    "\n",
    "                prev_positions[assigned_id] = (cx, cy)\n",
    "\n",
    "                # Blue bounding box\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n",
    "                cv2.circle(annotated_frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "\n",
    "                # Info label (black text)\n",
    "                info_text = f\"ID {assigned_id} | {status} | V={velocity:.1f} | Conf={conf:.2f}\"\n",
    "                cv2.putText(annotated_frame, info_text, (x1, y1 - 8),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "        # Save and show\n",
    "        out.write(annotated_frame)\n",
    "        resized_frame = cv2.resize(annotated_frame, (display_width, display_height))\n",
    "        cv2.imshow(\"YOLO + MediaPipe Football Detection\", resized_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "\n",
    "\n",
    "# === PATH SETUP ===\n",
    "video_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\test2.mp4\"\n",
    "detect_model_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\yolov9c.pt\"\n",
    "output_path = r\"C:\\Users\\vaibh\\OneDrive\\Desktop\\New folder\\Folder Python\\Folder ML\\opencv_example\\mediapipe_yolo_output_2.avi\"\n",
    "\n",
    "# === RUN ===\n",
    "print(\"🎥 Running MediaPipe + YOLOv9 Football Detection...\")\n",
    "yolo_mediapipe_football_detection(video_path, detect_model_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f65768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
